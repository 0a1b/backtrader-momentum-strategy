{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Jupyter Extensions - convenience as an extension\n",
    "For Jupyter to bring more added value I recommend you to install extensions\n",
    "pip Commands:\n",
    "\n",
    "pip install jupyter_nbextensions_configurator jupyter_contrib_nbextensions\n",
    "jupyter contrib nbextension install --user\n",
    "jupyter nbextensions_configurator enable --user\n",
    "\n",
    "My Favorites are:\n",
    "* Collapsible headings\n",
    "* Code folding\n",
    "* Notify\n",
    "* Hinterland (can be nice, but I think I didn't come to use it correctly)\n",
    "              \n",
    "Thanks to https://becominghuman.ai/enhance-your-jupyter-experience-with-these-notebook-widgets-a2717921f678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stretch the code to 90% of the browser width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Downloading data from Yahoo\n",
    "Enter symbol, from , to, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport yahoofinance as yf\\n#\\nrow = \"TLT\"\\nfrom1 = \\'2005-10-31\\'\\nto = \\'2020-11-11\\'\\nstring = \\'\\'\\npath = r\\'C:\\\\Users\\\\MMD\\\\PycharmProjects\\\\Trading\\\\Data Mining\\\\Data\\\\NASDAQ2005/\\'\\nhist = yf.HistoricalPrices(string.join(row),  from1, to, frequency=\\'1d\\')\\nhist.to_csv(path + string.join(row) + \\'.csv\\')\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r'''\n",
    "import yahoofinance as yf\n",
    "from csv import reader\n",
    "# open file in read mode\n",
    "with open(r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\nasdaq_2017.csv', 'r') as read_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    csv_reader = reader(read_obj)\n",
    "    # Iterate over each row in the csv using reader object\n",
    "    for row in csv_reader:\n",
    "        # row variable is a list that represents a row in csv\n",
    "        from1 = '2005-10-31'\n",
    "        to = '2020-11-11'\n",
    "        string = ''\n",
    "        path = r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\NASDAQ2017/'\n",
    "        hist = yf.HistoricalPrices(string.join(row),  from1, to, frequency='1d')\n",
    "        hist.to_csv(path + string.join(row) + '.csv')\n",
    "'''\n",
    "\n",
    "r'''\n",
    "import yahoofinance as yf\n",
    "#\n",
    "row = \"TLT\"\n",
    "from1 = '2005-10-31'\n",
    "to = '2020-11-11'\n",
    "string = ''\n",
    "path = r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\NASDAQ2005/'\n",
    "hist = yf.HistoricalPrices(string.join(row),  from1, to, frequency='1d')\n",
    "hist.to_csv(path + string.join(row) + '.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mmd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas_datareader\\compat\\__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n",
      "c:\\users\\mmd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pyfolio\\pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e9df3f8a63f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinregress\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mquantstats\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mqs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptunity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mmd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\quantstats\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0m__author__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Ran Aroussi\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'stats'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'plots'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reports'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'utils'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'extend_pandas'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mmd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\quantstats\\plots.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mquantstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plotting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\mmd\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mmd\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mmd\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mmd\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mmd\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mmd\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mpath_stats\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mmd\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import webbrowser\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import backtrader as bt\n",
    "import backtrader.analyzers as btanal\n",
    "import pyfolio as pf\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.stats import linregress\n",
    "import quantstats as qs\n",
    "import seaborn as sns\n",
    "import optunity.metrics\n",
    "import math\n",
    "import cProfile\n",
    "from time import time\n",
    "import plotly.graph_objects as go\n",
    "import itertools\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (13,13)\n",
    "\n",
    "import warnings \n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#Imports for walkforward analysis\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.utils import indexable\n",
    "from sklearn.utils.validation import _num_samples\n",
    "import numpy as np\n",
    "import backtrader as bt\n",
    "import backtrader.indicators as btind\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "from pandas import Series, DataFrame\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import optunity.metrics\n",
    "import backtrader.analyzers as btanal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalparams = dict(path=r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\Momentum Stocks', # location of your csv files, downloaded from Yahoo\n",
    "                    fromdate=datetime.datetime(2018, 11, 3),\n",
    "                    todate=datetime.datetime(2020, 6, 18),\n",
    "                    strategy=\"St\", #HSt = Buy and Hold, St = Standard Strategy for non-survivorship free bias momentum                    \n",
    "                    \n",
    "                    # Momentum Strategy specifics(= St)        \n",
    "                    mperiod=200,  # lookback period for momentum - default 90 periods\n",
    "                    selcperc=1,  # number of stocks to select from the universe\n",
    "                    time_interval=\"Month\", # if it is not week then it is month\n",
    "                    time_between=1, # time between time interval, e.g. 1 means weekly, 2 means every 2 weeks etc. same for months\n",
    "                    \n",
    "                    roc = True,        # Whether the rate of change should be taken into consideration\n",
    "                    rocperiod=130,   # rate of change to make sure stock is increasing\n",
    "                    \n",
    "                    r_squared = False, # Whether volatility should be punished when calculating the momentum\n",
    "                    \n",
    "                    stoploss=False,     # Stop loss function (trailing stop loss)\n",
    "                    stoplossperc=0.15, # where to draw stop loss line\n",
    "                    \n",
    "                    #General optimization parameters\n",
    "                    params_combination= \"123\", #1=# of stocks picked from universe, 2=momentum period, 3=roc period\n",
    "                    optimization_target=\"VWR\", #Relevant for heatmap & optunity. \n",
    "                    #Potential Inputs: returns, Sharpe, Sortino, SQN (needs more than 30 trades!), VWR (variablility weighted returns)\n",
    "                    heatmap_yaxisr=np.arange(1, 3, 1), #y axis range of parameters for heatmap\n",
    "                    heatmap_xaxisr=np.arange(180, 210, 10), #x axis (mperiod) range of parameters for heatmap\n",
    "                    heatmap_zaxisr=np.arange(100, 150, 10), #z axis (ROC) range of parameters for 3d surfacemap                      \n",
    "                    \n",
    "                    #Heatmap section\n",
    "                    heatmap=False,  #Does not work with Hold and Buy                  \n",
    "                    \n",
    "                    #optimization with optunity (various algorithms e.g. Partical Swarm Optimization)\n",
    "                    optunity=False, # Either optunity or heatmap\n",
    "                    num_eval=2,   #how many evaluations optunity will try // also for Walk Forward Analysis                    \n",
    "                    \n",
    "                    #Walk-forward-analysis, either optunity or heatmap must be switched on\n",
    "                    walk=False,     \n",
    "                    fixed_length=True, # by setting it False the training data will will grow over time, otherwise it will keep the size given under train_splits\n",
    "                    n_splits=10,         # how many chunks the data should have\n",
    "                    \n",
    "                    cash=100000,      #amount of initial captal      \n",
    "                    commission=0.005, #broker fee/ask/bid spread\n",
    "                    reserve=0.05, #% of cash that won't be spent due to otherwise canceled orders\n",
    "                    printlog=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function section\n",
    "Momentum (with and without volatility correction) [thanks to Teddy Koker https://teddykoker.com/2019/05/momentum-strategy-from-stocks-on-the-move-in-python/] and heatmap for analysis of variable combinations and thanks to samwindham1 https://github.com/samwindham1/algo-trader/blob/master/backtest/util/analyzers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     19,
     36,
     53,
     103
    ]
   },
   "outputs": [],
   "source": [
    "#Momentum + ROC\n",
    "class Momentumplus(bt.Indicator):\n",
    "    lines = ('trend',)\n",
    "    params = (('period', 190), ('rperiod', 30))\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.addminperiod(self.params.period)\n",
    "        self.roc = bt.ind.ROC(self.data, period=self.p.rperiod)\n",
    "\n",
    "    def next(self):\n",
    "        returns = np.log(self.data.get(size=self.p.period))\n",
    "        x = np.arange(len(returns))\n",
    "        slope, _, rvalue, _, _ = linregress(x, returns)\n",
    "        annualized = (1 + slope) ** 252\n",
    "        test = math.ceil(self.roc[0])\n",
    "        rate = min(1, max(0, test)) if globalparams[\"roc\"] else 1\n",
    "        self.lines.trend[0] = annualized * rate * (rvalue ** 2) / (1 if globalparams[\"r_squared\"] else (rvalue ** 2))\n",
    "\n",
    "# Great Heatmap to analyse different combinations of parameters\n",
    "def my_heatmap(data):\n",
    "    data = np.array(data)\n",
    "    xs = np.unique(data[:, 0].astype(float))\n",
    "    ys = np.unique(data[:, 1].astype(int))\n",
    "    vals = data[:, 3].reshape(len(ys), len(xs))\n",
    "    min_val_ndx = np.unravel_index(np.argmin(vals, axis=None), vals.shape)\n",
    "    max_val_ndx = np.unravel_index(np.argmax(vals, axis=None), vals.shape)\n",
    "\n",
    "    cmap = LinearSegmentedColormap.from_list('', ['red', 'orange', 'yellow', 'chartreuse', 'limegreen'])\n",
    "    ax = sns.heatmap(vals, xticklabels=xs, yticklabels=ys, cmap='viridis', annot=True, fmt='.2f')\n",
    "\n",
    "    ax.add_patch(Rectangle(min_val_ndx[::-1], 1, 1, fill=False, edgecolor='blue', lw=3, clip_on=False))\n",
    "    ax.add_patch(Rectangle(max_val_ndx[::-1], 1, 1, fill=False, edgecolor='blue', lw=3, clip_on=False))\n",
    "    print(data)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def my_heatmap1(data):\n",
    "    data = np.array(data)\n",
    "    xs = np.unique(data[:, 1].astype(int))\n",
    "    ys = np.unique(data[:, 0].astype(int))\n",
    "    vals = data[:, 3].reshape(len(ys), len(xs))\n",
    "    min_val_ndx = np.unravel_index(np.argmin(vals, axis=None), vals.shape)\n",
    "    max_val_ndx = np.unravel_index(np.argmax(vals, axis=None), vals.shape)\n",
    "\n",
    "    cmap = LinearSegmentedColormap.from_list('', ['red', 'orange', 'yellow', 'chartreuse', 'limegreen'])\n",
    "    ax = sns.heatmap(vals, xticklabels=xs, yticklabels=ys, cmap='viridis', annot=True, fmt='.2f')\n",
    "\n",
    "    ax.add_patch(Rectangle(min_val_ndx[::-1], 1, 1, fill=False, edgecolor='blue', lw=3, clip_on=False))\n",
    "    ax.add_patch(Rectangle(max_val_ndx[::-1], 1, 1, fill=False, edgecolor='blue', lw=3, clip_on=False))\n",
    "    print(\"Average Return of all iterations\", [sum(i)/len(i) for i in zip(*data)][3])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def my_scatter_plot(data):\n",
    "    # create data\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for i in range(0, len(data)):\n",
    "        x.append(data[i][1])\n",
    "        y.append(data[i][0])\n",
    "        z.append(round(data[i][3],0))\n",
    "    '''\n",
    "    # Change color with c and alpha. I map the color to the X axis value.\n",
    "    sc = plt.scatter(x, y, s=z, c=z, cmap=\"viridis\", alpha=0.4)\n",
    "    plt.legend(*sc.legend_elements(\"sizes\", num=6), loc=4)\n",
    "    # Add titles (main and on axis)\n",
    "    plt.xlabel(\"the X axis\")\n",
    "    plt.ylabel(\"the Y axis\")\n",
    "    plt.title(\"A colored bubble plot\")\n",
    "    '''\n",
    "    df = pd.DataFrame(dict(x=x, y=y, z=z))\n",
    "    sns.set_context(\"talk\")\n",
    "    #plt.figure(figsize=(10,6))\n",
    "    pp=sns.scatterplot(x=x, \n",
    "                    y=y,\n",
    "                    size=z,\n",
    "                    sizes=(20,500),\n",
    "                    alpha=0.5,\n",
    "                    data=df)\n",
    "    \n",
    "    for line in range(0,df.shape[0]):\n",
    "        pp.text(df.x[line]+0.2, df.y[line], df.z[line], horizontalalignment='left', size='medium', color='black')\n",
    "    # Put the legend out of the figure\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1),borderaxespad=0)\n",
    "                      \n",
    "    plt.show()\n",
    "\n",
    "def plotly_4d(data):\n",
    "    df1 = pd.DataFrame.from_records(data, columns=['selcperc', 'mperiod', 'rocperiod', 'value'])\n",
    "    df = df1[~(df1['selcperc'].isin([2]))]\n",
    "    df= df.pivot_table(index=['mperiod'], columns=['rocperiod'], values='value').reset_index()\n",
    "    del df['mperiod']\n",
    "    df.drop(df.index[0])\n",
    "    print(df)\n",
    "    fig = go.Figure(data=[go.Surface(z=df.values)])\n",
    "    fig.update_traces(contours_z=dict(show=True, usecolormap=True,\n",
    "                                      highlightcolor=\"limegreen\", project_z=True))\n",
    "    fig.update_layout(title_text=\"Analysis of Strategy\", autosize=False, width=700, height=700,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90))\n",
    "    fig.show() \n",
    "  \n",
    "    \n",
    "class Sortino(bt.Analyzer):\n",
    "    params = (\n",
    "        ('timeframe', bt.TimeFrame.Years),\n",
    "        ('compression', 1),\n",
    "        ('riskfreerate', 0.01),\n",
    "        ('factor', None),\n",
    "        ('convertrate', True),\n",
    "        ('annualize', False),\n",
    "    )\n",
    "\n",
    "    RATEFACTORS = {\n",
    "        bt.TimeFrame.Days: 252,\n",
    "        bt.TimeFrame.Weeks: 52,\n",
    "        bt.TimeFrame.Months: 12,\n",
    "        bt.TimeFrame.Years: 1,\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Sortino, self).__init__()\n",
    "        self.ret = btanal.TimeReturn(\n",
    "            timeframe=self.p.timeframe,\n",
    "            compression=self.p.compression)\n",
    "        self.ratio = 0.0\n",
    "\n",
    "    def stop(self):\n",
    "        returns = list(self.ret.get_analysis().values())\n",
    "\n",
    "        rate = self.p.riskfreerate\n",
    "\n",
    "        factor = None\n",
    "        if self.p.timeframe in self.RATEFACTORS:\n",
    "            # Get the conversion factor from the default table\n",
    "            factor = self.RATEFACTORS[self.p.timeframe]\n",
    "\n",
    "        if factor is not None:\n",
    "            # A factor was found\n",
    "            if self.p.convertrate:\n",
    "                # Standard: downgrade annual returns to timeframe factor\n",
    "                rate = pow(1.0 + rate, 1.0 / factor) - 1.0\n",
    "            else:\n",
    "                # Else upgrade returns to yearly returns\n",
    "                returns = [pow(1.0 + x, factor) - 1.0 for x in returns]\n",
    "\n",
    "        if len(returns):\n",
    "            # Sortino Ratio = (R - T) / TDD\n",
    "            #   R = Avg Returns\n",
    "            #   T = Target (risk-free rate)\n",
    "            #   TDD = Downside Risk\n",
    "            ret_free_avg = np.mean(returns) - rate\n",
    "            tdd = math.sqrt(np.mean([min(0, r - rate)**2 for r in returns]))\n",
    "\n",
    "            try:\n",
    "                ratio = ret_free_avg / tdd\n",
    "\n",
    "                if factor is not None and \\\n",
    "                        self.p.convertrate and self.p.annualize:\n",
    "\n",
    "                    ratio = math.sqrt(factor) * ratio\n",
    "            except (ValueError, TypeError, ZeroDivisionError):\n",
    "                ratio = None\n",
    "\n",
    "        else:\n",
    "            # no returns\n",
    "            ratio = None\n",
    "\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def get_analysis(self):\n",
    "        return dict(sortino=self.ratio)\n",
    "\n",
    "# Picking optimization target and subsequent analyser functions for optimization\n",
    "def opta(i):\n",
    "    switcher={\n",
    "            \"VWR\":['cerebro.addanalyzer(btanal.VWR, _name=\"VWR\")','results1[0].analyzers.VWR.get_analysis()[\"vwr\"]'],\n",
    "            \"Sortino\":['cerebro.addanalyzer(Sortino, _name=\"sortino\")','results1[0].analyzers.sortino.get_analysis()[\"sortino\"]'],\n",
    "            \"returns\":['1==1','cerebro.broker.getvalue()'], #TODO must be tested separately\n",
    "            \"Sharpe\":['cerebro.addanalyzer(btanal.SharpeRatio, _name=\"sharpe\")','results1[0].analyzers.sharpe.get_analysis()[\"sharperatio\"]'],\n",
    "            \"SQN\":['cerebro.addanalyzer(btanal.SQN, _name=\"sqn\")','results1[0].analyzers.sqn.get_analysis()[\"sqn\"]'],\n",
    "         }\n",
    "    return switcher.get(i,\"Optimization Target not available\")\n",
    "\n",
    "def params_comb(i): \n",
    "    switcher={\n",
    "            \"12\":[['globalparams[\"heatmap_yaxisr\"]','globalparams[\"heatmap_xaxisr\"]','[globalparams[\"rocperiod\"],globalparams[\"rocperiod\"]*1.0001]'],['results_list.append([i, j, k, PnL])','0','1','2']], #p1, p2, p3 in optunity maximize\n",
    "            \"13\":[['globalparams[\"heatmap_yaxisr\"]','[globalparams[\"mperiod\"],globalparams[\"mperiod\"]*1.0001]','globalparams[\"heatmap_zaxisr\"]'],['results_list.append([i, k, j, PnL])','0','2','1']],\n",
    "            \"23\":[['[globalparams[\"selcperc\"],globalparams[\"selcperc\"]*1.0001]','globalparams[\"heatmap_xaxisr\"]','globalparams[\"heatmap_zaxisr\"]'],['results_list.append([j, k, i, PnL])','2','0','1']],\n",
    "            \"123\":[['globalparams[\"heatmap_yaxisr\"]','globalparams[\"heatmap_xaxisr\"]','globalparams[\"heatmap_zaxisr\"]'],['results_list.append([i, j, k, PnL])','0','1','2']],\n",
    "         }\n",
    "    return switcher.get(i,\"Optimization Target not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simple Buy and Hold Strategy\n",
    "Thanks to https://github.com/samuel281/qu-ant/blob/master/lib/strategies/hold_all_strategy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class HSt(bt.Strategy):\n",
    "    params = dict(\n",
    "        buy_date=datetime.datetime.today().isoformat(),\n",
    "    )\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stocks = self.datas[2:] #must filter out bond and spy \n",
    "                  \n",
    "    def next(self):\n",
    "        for d in self.stocks:\n",
    "            if self.getposition(data=d).size:\n",
    "                return\n",
    "        \n",
    "        if self.data.datetime.date(0).isoformat() < self.params.buy_date.isoformat(): #buydate must be determined by the first strategy, since it is the date of the first trade?\n",
    "            return\n",
    "\n",
    "        target_ratio = 1.0 - globalparams[\"reserve\"]\n",
    "        target_ratio_per_sec = target_ratio / len(self.stocks)            \n",
    "        for d in self.stocks:\n",
    "            self.order_target_percent(data=d, target=target_ratio_per_sec)            \n",
    "    \n",
    "    def log(self, arg):\n",
    "        print('{} {}'.format(self.datetime.date(), arg))            \n",
    "            \n",
    "    def on_order_executed(self, order):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Accepted]:\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "        if order.status in [order.Submitted]:\n",
    "            if order.isbuy():\n",
    "\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Buy {} {} {} Price {:.2f} Value {:.2f} Size {} Cash {:.2f} Broker {:.2f}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price , order.created.size, self.broker.getcash(), self.broker.getvalue()))\n",
    "            if order.issell():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Sell {} {} {} Price {:.2f} Value {:.2f} Size {} Broker {:.2f}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price, order.created.size, self.broker.getvalue()))\n",
    "\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "\n",
    "        # Check if an order has been completed\n",
    "        # Attention: broker could reject order if not enough cash\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Buy {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "\n",
    "            if order.issell():# Sell\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Sell {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fill in gaps of survivorship bias free data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r'''\n",
    "import pandas as pd\n",
    "import glob, os, datetime\n",
    "pathh = r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\data/'\n",
    "idx = pd.date_range('2013-02-28', '2018-02-28')\n",
    "for fname in glob.glob(os.path.join(pathh, '*')):\n",
    "    df = pd.read_csv(fname, index_col=0, parse_dates=True)\n",
    "    df1 = df.reindex(idx,fill_value=0)\n",
    "    df1.to_csv(r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\data2/' + os.path.basename(fname).replace(\".csv\", \"\") + '_1.csv')\n",
    "    #print(df1)\n",
    "    #break\n",
    "'''   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Survivor bias free momentum strategy\n",
    "Thanks to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Sur(bt.Strategy):\n",
    "    params = dict(\n",
    "            selcperc=0.50,  # percentage of stocks to select from the universe\n",
    "            rperiod=1,  # period for the returns calculation, default 1 period\n",
    "            vperiod=55,  # lookback period for volatility - default 36 periods\n",
    "            mperiod=155,  # lookback period for momentum - default 90 periods\n",
    "            momentum=Momentumplus, # parametrize the momentum and its period\n",
    "            reserve=globalparams[\"reserve\"],  # 5% reserve capital\n",
    "            monthdays=[1],\n",
    "            monthcarry=True,\n",
    "            when=bt.timer.SESSION_START,\n",
    "            benchmarkstop=False, # If true, no stocks will be bought and no rebalancing will be done if benchmark is below SMAperiod\n",
    "            SMAperiod=200,\n",
    "            benchmark_bond=True, # Sell all Stocks and buy Bonds\n",
    "            jump_momentum=True, # If true, after a time of jump_one (30 days x jump_one) in every month, all the money will be directed to the best performing stock. Rule for that:\n",
    "                                # In Excel, this is a 0.6 x month return of fund with best past 3 month return plus 0.4 x return of fund with best return, month to date.\n",
    "            jump_one=0.6,\n",
    "            printlog=True,\n",
    "        )\n",
    "\n",
    "    def __init__(self):\n",
    "        self.bench = self.data0\n",
    "        self.bond = self.data1\n",
    "        self.stocks = self.datas[2:]\n",
    "        # calculate 1st the amount of stocks that will be selected\n",
    "        self.selnum = int(len(self.stocks) * self.p.selcperc)\n",
    "\n",
    "        # allocation perc per stock\n",
    "        # reserve kept to make sure orders are not rejected due to\n",
    "        # margin. Prices are calculated when known (close), but orders can only\n",
    "        # be executed next day (opening price). Price can gap upwards\n",
    "        self.perctarget = (1.0 - self.p.reserve) / self.selnum\n",
    "        \n",
    "        # This is the set up of the timer that makes the strategy being executed at the given time\n",
    "        self.add_timer(\n",
    "            when=self.p.when,\n",
    "            monthdays=self.p.monthdays,\n",
    "            monthcarry=self.p.monthcarry\n",
    "        )\n",
    "        \n",
    "        self.stocks_len = []\n",
    "        \n",
    "        jump = True\n",
    "\n",
    "        # returns, volatilities and momentums\n",
    "        rs = [bt.ind.PctChange(d, period=self.p.rperiod) for d in self.stocks]\n",
    "        vs = [bt.ind.StdDev(ret, period=self.p.vperiod) for ret in rs]\n",
    "        #ms = [bt.ind.ROC(d, period=self.p.mperiod) for d in self.datas]\n",
    "        ms = [self.p.momentum(d, period=self.p.mperiod) for d in self.stocks]\n",
    "        \n",
    "        self.bench_sma = bt.ind.SMA(self.data0, period=self.p.SMAperiod)\n",
    "        \n",
    "        # simple rank formula: (momentum * net payout) / volatility\n",
    "        # the highest ranked: low vol, large momentum, large payout\n",
    "        self.ranks = {d: m / v for d, v, m in zip(self.stocks, vs, ms)}\n",
    "        #TODO: does it perform better without the volatility?\n",
    "\n",
    "        self.bench_filter = self.bench < self.bench_sma\n",
    "\n",
    "\n",
    "    def log(self, arg):\n",
    "        if self.p.printlog:\n",
    "            print('{} {}'.format(self.datetime.date(), arg))\n",
    "        \n",
    "    # This section is for logging of orders in greater detail to figure out whether the strategy is actually having no problem with orders\n",
    "    '''\n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Accepted]:\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "        if order.status in [order.Submitted]:\n",
    "            if order.isbuy():\n",
    "            \n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Buy {} {} {} Price {:.2f} Value {:.2f} Size {} Cash {:.2f}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price , order.created.size, self.broker.getcash()))\n",
    "            if order.issell():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Sell {} {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price, order.created.size))\n",
    "\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "\n",
    "        # Check if an order has been completed\n",
    "        # Attention: broker could reject order if not enough cash\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Buy {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "\n",
    "            if order.issell():# Sell\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Sell {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "\n",
    "\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "    '''       \n",
    "    \n",
    "    # This is the function using the timer to execute the rebalance \n",
    "    def notify_timer(self, timer, when, *args, **kwargs):\n",
    "        print('strategy notify_timer with tid {}, when {} _getminperstatus {}'.\n",
    "              format(timer.p.tid, when, int(self._getminperstatus())))\n",
    "        print(\"timer\")\n",
    "        if self._getminperstatus() < 0:\n",
    "            self.rebalance()\n",
    "    \n",
    "    def nextstart(self):\n",
    "        self.ranks_filter = self.ranks\n",
    "        print(\"nextstart\")\n",
    "        self.next()\n",
    "        \n",
    "    def prenext(self):\n",
    "        self.stocks_len = [d for d in self.stocks if len(d)]\n",
    "        self.ranks_filter = dict(zip(self.stocks_len, [self.ranks[k] for k in self.stocks_len]))        \n",
    "        self.next()\n",
    "        \n",
    "    def next(self):\n",
    "        print(\"next\")\n",
    "        pass # must be filled with a pass\n",
    "\n",
    "    \n",
    "    # Actual order giving by a ranking takes place here\n",
    "    def rebalance(self):\n",
    "        print(\"rebalance\")\n",
    "        #if jump == True:\n",
    "        # Enter Jump Code here    \n",
    "        \n",
    "        # sort data and current rank\n",
    "        ranks = sorted(\n",
    "            self.ranks_filter.items(),  # get the (d, rank), pair\n",
    "            key=lambda x: x[1][0],  # use rank (elem 1) and current time \"0\"\n",
    "            reverse=True,  # highest ranked 1st ... please\n",
    "        )\n",
    "        \n",
    "        # put top ranked in dict with data as key to test for presence\n",
    "        rtop = dict(ranks[:self.selnum])\n",
    "\n",
    "        # For logging purposes of stocks leaving the portfolio\n",
    "        rbot = dict(ranks[self.selnum:])\n",
    "\n",
    "        # prepare quick lookup list of stocks currently holding a position\n",
    "        posdata = [d for d, pos in self.getpositions().items() if pos]\n",
    "        \n",
    "\n",
    "        if self.p.benchmarkstop:\n",
    "            for d in (d for d in posdata):\n",
    "                if \"Bond\" == d._name and self.bench_filter:\n",
    "                    return\n",
    "                else:\n",
    "                    if \"Bond\" == d._name and not self.bench_filter:\n",
    "                        self.order_target_percent(\"Bond\", target=0.0)\n",
    "                        self.log('Leave {} due to end of down period'.format(d._name))\n",
    "                        return\n",
    "        \n",
    "        # Triple Momentum: If Benchmark index is below SMA, nothing will be bought or rebalanced\n",
    "        if self.p.benchmarkstop:\n",
    "            if self.bench_filter:\n",
    "                #print('SMA {} - Bench {}'.format(self.bench_sma[0], self.bench[0]))\n",
    "                if self.p.benchmark_bond:\n",
    "                    for d in posdata:\n",
    "                        self.log('Leave {} due to switch to Bonds'.format(d._name))\n",
    "                        self.order_target_percent(d, target=0.0)\n",
    "                    self.order_target_percent(\"Bond\", target=0.95)\n",
    "                    self.log('Buy Bond')\n",
    "                    bond_flag = True\n",
    "                    return #Code stops here and skips rebalancing und buying\n",
    "\n",
    "        # remove those no longer top ranked\n",
    "        # do this first to issue sell orders and free cash\n",
    "        for d in (d for d in posdata if d not in rtop):\n",
    "            self.log('Leave {} - Rank {:.2f}'.format(d._name, rbot[d][0]))\n",
    "            self.order_target_percent(d, target=0.0)\n",
    "        \n",
    "        # rebalance those already top ranked and still there\n",
    "        for d in (d for d in posdata if d in rtop):\n",
    "            self.log('Rebal {} - Rank {:.2f}'.format(d._name, rtop[d][0]))\n",
    "            self.order_target_percent(d, target=self.perctarget)\n",
    "            del rtop[d]  # remove it, to simplify next iteration\n",
    "\n",
    "        # issue a target order for the newly top ranked stocks\n",
    "        # do this last, as this will generate buy orders consuming cash\n",
    "        for d in rtop:\n",
    "            self.log('Enter {} - Rank {:.2f}'.format(d._name, rtop[d][0]))\n",
    "            self.order_target_percent(d, target=self.perctarget)\n",
    "            \n",
    "    def stop(self):\n",
    "        pnl = round(self.broker.getvalue() - globalparams[\"cash\"],2)\n",
    "        print('Final PnL: {}'.format(\n",
    "            pnl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum Strategy\n",
    "Originally it is a combination of the momentum strategy example given on the official website:\n",
    "https://www.backtrader.com/blog/2019-05-20-momentum-strategy/momentum-strategy/\n",
    "and  https://teddykoker.com/2019/05/momentum-strategy-from-stocks-on-the-move-in-python/\n",
    "Changes have been made:\n",
    "* Triple momentum, i.e. if benmarkstop is True, benchmark index is below SMAperiod no stocks will be bought anymore. \n",
    "If benchmark_bond is True all stocks will be sold and bond of choice will be bought\n",
    "* Sizer has been adapted to equal distribution of free cash and not equal share among all stocks\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     91,
     154,
     234
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class St(bt.Strategy):\n",
    "    params = dict(\n",
    "        selcperc=globalparams[\"selcperc\"],  # percentage of stocks to select from the universe\n",
    "        mperiod=globalparams[\"mperiod\"],  # lookback period for momentum - default 90 periods\n",
    "        rocperiod=globalparams[\"rocperiod\"],   # rate of change to make sure stock is increasing\n",
    "        momentumplus=Momentumplus, # parametrize the momentum and its period\n",
    "        reserve=globalparams[\"reserve\"],  # 5% reserve capital\n",
    "        monthdays=[1],\n",
    "        monthcarry=True,\n",
    "        weekdays=[5],\n",
    "        weekcarry=True,\n",
    "        benchmarkstop=False, # If true, no stocks will be bought and no rebalancing will be done if benchmark is below SMAperiod / Must be switched off in WFA\n",
    "        SMAperiod=100,\n",
    "        benchmark_bond=True, # Sell all Stocks and buy Bonds\n",
    "        jump_momentum=True, # If true, after a time of jump_one (30 days x jump_one) in every month, all the money will be directed to the best performing stock. Rule for that:\n",
    "                            # In Excel, this is a 0.6 x month return of fund with best past 3 month return plus 0.4 x return of fund with best return, month to date.\n",
    "        jump_one=0.6,\n",
    "        printlog=globalparams[\"printlog\"],\n",
    "        WFA=False,          #Switch for the last \"putting the fragments together run\" of the Walk Forward Analysis\n",
    "        start_dates=None,  # Starting days for trading periods (a list)\n",
    "        end_dates=None,\n",
    "        stoploss=globalparams[\"stoploss\"],   #activate stop loss\n",
    "        stop_loss=globalparams[\"stoplossperc\"],  # price is 10% less than the entry point\n",
    "        trail=True,\n",
    "        \n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        self.bench = self.data0\n",
    "        self.bond = self.data1\n",
    "        self.stocks = self.datas[2:]\n",
    "        # calculate 1st the amount of stocks that will be selected\n",
    "        \n",
    "        self.stoplossorders = {}\n",
    "        \n",
    "        # counter for time in between\n",
    "        self.timer_i = 0\n",
    "        self.posdata =[]\n",
    "        \n",
    "        # This is the set up of the timer that makes the strategy being executed at the given time\n",
    "        if globalparams[\"time_interval\"] == \"week\":\n",
    "            self.add_timer(\n",
    "                when=bt.timer.SESSION_START,\n",
    "                weekdays=self.p.weekdays,\n",
    "                weekcarry=self.p.weekcarry,\n",
    "            )  \n",
    "        else:\n",
    "            self.add_timer(\n",
    "                when=bt.timer.SESSION_START,\n",
    "                monthdays=self.p.monthdays,\n",
    "                monthcarry=self.p.monthcarry,\n",
    "            )\n",
    "\n",
    "        # preparation for Walk Forward Analysis\n",
    "        if self.p.WFA == True:\n",
    "            self.mperiod = dict()\n",
    "            self.vperiod = dict()\n",
    "            self.ms = dict()\n",
    "            self.selnum = dict()\n",
    "\n",
    "            self.date_combos = [c for c in zip(self.p.start_dates, self.p.end_dates)]\n",
    "\n",
    "            # Additional indexing, allowing for differing start/end dates\n",
    "            for sd, ed, f, s, t in zip(self.p.start_dates, self.p.end_dates, self.p.mperiod, self.p.rocperiod, self.p.selcperc):\n",
    "                self.selnum[(sd, ed)] = int(t) # of stocks bought\n",
    "                \n",
    "                # returns, volatilities and momentums\n",
    "                self.ms[(sd, ed)] = [self.p.momentumplus(d, period=int(f), rperiod=int(s)) for d in self.stocks] #toDo how to implement it with two parameters\n",
    "        \n",
    "        #Non walk forward analysis\n",
    "        else:\n",
    "            self.selnum = int(self.p.selcperc)\n",
    "            # allocation perc per stock\n",
    "            #momentums\n",
    "            ms = [self.p.momentumplus(d, period=int(self.p.mperiod), rperiod=int(self.p.rocperiod)) for d in self.stocks]\n",
    "            self.bench_sma = bt.ind.SMA(self.data0, period=self.p.SMAperiod)\n",
    "\n",
    "            # simple rank formula: (momentum * net payout) / volatility\n",
    "            # the highest ranked: low vol, large momentum, large payout\n",
    "            self.ranks = {d: m for d, m in zip(self.stocks, ms)}\n",
    "            \n",
    "            self.bench_filter = self.bench < self.bench_sma\n",
    "                \n",
    "    def log(self, arg):\n",
    "        if self.p.printlog:\n",
    "            print('{} {}'.format(self.datetime.date(), arg))\n",
    "        \n",
    "    # This section is for logging of orders in greater detail to figure out whether the strategy is actually having no problem with orders\n",
    "    \n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Accepted]:\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "        if order.status in [order.Submitted]:\n",
    "            if order.isbuy():\n",
    "            \n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                self.log('Buy {} {} {} Price {:.2f} Value {:.2f} Size {} Cash {:.2f}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price , order.created.size, self.broker.getcash()))\n",
    "            if order.issell():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                self.log('Sell {} {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price, order.created.size))\n",
    "\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "\n",
    "        # Check if an order has been completed\n",
    "        # Attention: broker could reject order if not enough cash\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                self.log('Buy {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "                \n",
    "                if self.p.stoploss:\n",
    "                    if not self.p.trail:\n",
    "                        stop_price = order.executed.price * (1.0 - self.p.stop_loss)\n",
    "                        storder = self.sell(data=order.data, exectype=bt.Order.Stop, price=stop_price, size=order.executed.size)\n",
    "                        self.stoplossorders[order.data._name] = storder\n",
    "                    else:\n",
    "                        storder = self.sell(data=order.data, exectype=bt.Order.StopTrail, trailpercent=self.p.stop_loss, size=order.executed.size)\n",
    "                        self.stoplossorders[order.data._name] = storder\n",
    "\n",
    "            if order.issell():# Sell\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                self.log('Sell {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.price*order.executed.size, order.executed.size))\n",
    "                if self.p.stoploss:\n",
    "                    del self.stoplossorders[order.data._name]\n",
    "                    for d in (d for d in self.posdata if d in [order.data]):\n",
    "                        self.posdata.remove(d)  \n",
    "\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "           \n",
    "    \n",
    "    # This is the function using the timer to execute the rebalance \n",
    "    def notify_timer(self, timer, when, *args, **kwargs):\n",
    "        #print('strategy notify_timer with tid {}, when {} _getminperstatus {}'.\n",
    "        #      format(timer.p.tid, when, int(self._getminperstatus())))\n",
    "        if self._getminperstatus() < 0:\n",
    "            self.timer_i += 1\n",
    "            if self.timer_i == globalparams[\"time_between\"]:\n",
    "                self.timer_i = 0\n",
    "                self.rebalance()\n",
    "  \n",
    "    def next(self):\n",
    "        pass # must be filled with a pass\n",
    "\n",
    "    \n",
    "    # Actual order giving by a ranking takes place here\n",
    "    def rebalance(self):\n",
    "        \n",
    "        # Walkforward Analysis Section (no triple momentum possible)\n",
    "        if self.p.WFA == True:\n",
    "            # Determine which set of moving averages to use\n",
    "            curdate = self.datetime.date(0)\n",
    "            dtidx = None  # Will be index\n",
    "            # Determine which period (if any) we are in\n",
    "            for sd, ed in self.date_combos:\n",
    "                if sd <= curdate and curdate <= ed:\n",
    "                    dtidx = (sd, ed)\n",
    "                    self.ranks = {d: m for d, m in zip(self.stocks, self.ms[dtidx])}\n",
    "                    \n",
    "                    # sort data and current rank\n",
    "                    ranks = sorted(\n",
    "                        self.ranks.items(),  # get the (d, rank), pair\n",
    "                        key=lambda x: x[1][0],  # use rank (elem 1) and current time \"0\"\n",
    "                        reverse=True,  # highest ranked 1st ... please\n",
    "                    )\n",
    "\n",
    "                    # put top ranked in dict with data as key to test for presence\n",
    "                    rtop = dict(ranks[:self.selnum[dtidx]])\n",
    "\n",
    "                    # For logging purposes of stocks leaving the portfolio\n",
    "                    rbot = dict(ranks[self.selnum[dtidx]:])\n",
    "\n",
    "                    # prepare quick lookup list of stocks currently holding a position\n",
    "                    self.posdata = [d for d, pos in self.getpositions().items() if pos]\n",
    "                    \n",
    "            if dtidx is None:  # Not in any window\n",
    "                pass # Don't engage in trades\n",
    "            else:\n",
    "                self.momentum_core(self.posdata, rtop, rbot)                \n",
    "                #test whether momentums differ over time\n",
    "                #print(self.ms[dtidx][0][0], dtidx, \" vs \", self.ms[datetime.date(2019, 8, 30), datetime.date(2020, 11, 10)][0][0])\n",
    "        \n",
    "        # Non walk forward section\n",
    "        else:\n",
    "            # sort data and current rank\n",
    "            ranks = sorted(\n",
    "                self.ranks.items(),  # get the (d, rank), pair\n",
    "                key=lambda x: x[1][0],  # use rank (elem 1) and current time \"0\"\n",
    "                reverse=True,  # highest ranked 1st ... please\n",
    "            )\n",
    "            \n",
    "            # put top ranked in dict with data as key to test for presence\n",
    "            rtop = dict(ranks[:self.selnum])\n",
    "\n",
    "            # For logging purposes of stocks leaving the portfolio\n",
    "            rbot = dict(ranks[self.selnum:])\n",
    "            \n",
    "            # prepare quick lookup list of stocks currently holding a position\n",
    "            self.posdata = [d for d, pos in self.getpositions().items() if pos]\n",
    "            \n",
    "            \n",
    "            if self.p.benchmarkstop:\n",
    "                for d in (d for d in self.posdata):\n",
    "                    if \"Bond\" == d._name and self.bench_filter:\n",
    "                        return\n",
    "                    else:\n",
    "                        if \"Bond\" == d._name and not self.bench_filter:\n",
    "                            self.order_target_percent(\"Bond\", target=0.0)\n",
    "                            self.log('Leave {} due to end of down period'.format(d._name))\n",
    "                            return\n",
    "\n",
    "            # Triple Momentum: If Benchmark index is below SMA, nothing will be bought or rebalanced\n",
    "            if self.p.benchmarkstop:\n",
    "                if self.bench_filter:\n",
    "                    #print('SMA {} - Bench {}'.format(self.bench_sma[0], self.bench[0]))\n",
    "                    if self.p.benchmark_bond:\n",
    "                        for d in self.posdata:\n",
    "                            self.log('Leave {} due to switch to Bonds'.format(d._name))\n",
    "                            self.order_target_percent(d, target=0.0)\n",
    "                        self.order_target_percent(\"Bond\", target=0.95)\n",
    "                        self.log('Buy Bond')\n",
    "                        bond_flag = True\n",
    "                    return #Code stops here and skips rebalancing und buying\n",
    "                \n",
    "            self.momentum_core(self.posdata, rtop, rbot)\n",
    "            \n",
    "    def momentum_core(self, posdata, rtop, rbot):\n",
    "        # remove those no longer top ranked\n",
    "        # do this first to issue sell orders and free cash\n",
    "        for d in (d for d in posdata if d not in rtop):\n",
    "            self.log('Leave {} - Rank {:.2f}'.format(d._name, rbot[d][0]))\n",
    "            self.order_target_percent(d, target=0.0)\n",
    "            \n",
    "            if self.p.stoploss:\n",
    "                self.cancel(self.stoplossorders[d._name])\n",
    "\n",
    "        sum_stocks = 0\n",
    "        # rebalance those already top ranked and still there\n",
    "        for d in (d for d in posdata if d in rtop):\n",
    "            #self.log('Rebal {} - Rank {:.2f}'.format(d._name, rtop[d][0]))\n",
    "            #self.order_target_percent(d, target=self.perctarget)\n",
    "            #Rebalances are just pricy operations which are needed for the buying part ... since it was based on equal weights...\n",
    "            del rtop[d]  # remove it, to simplify next iteration\n",
    "            sum_stocks += self.broker.getposition(d).size * self.broker.getposition(d).adjbase # Calulate the value of the stocks owned\n",
    "\n",
    "\n",
    "        if len(rtop):\n",
    "            sizer_perc = (0.95 - sum_stocks / self.broker.get_value()) / len(rtop) # Have a equal sizer for the cash (you want to invest in)\n",
    "            sum_stocks = 0\n",
    "\n",
    "        # issue a target order for the newly top ranked stocks\n",
    "        # do this last, as this will generate buy orders consuming cash\n",
    "        for d in rtop:\n",
    "            self.log('Enter {} - Rank {:.2f}'.format(d._name, rtop[d][0]))\n",
    "            self.order_target_percent(d, target=sizer_perc)\n",
    "            \n",
    "    def stop(self):\n",
    "        pnl = round(self.broker.getvalue() - globalparams[\"cash\"],2)\n",
    "        self.log('Final PnL: {}'.format(\n",
    "            pnl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Walk forward analysis\n",
    "Thanks to https://ntguardian.wordpress.com/2017/06/19/walk-forward-analysis-demonstration-backtrader/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     18,
     91
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def walk_forward_analysis(datafeeds):\n",
    "\n",
    "    # display dataframes more orderly\n",
    "    pd.set_option('display.max_rows', 10)\n",
    "    pd.set_option('display.max_columns', 10)\n",
    "    pd.set_option('display.width', 1000)\n",
    "\n",
    "    globalparameters = dict(strategy=globalparams['strategy'],            # if a different strategy is used\n",
    "                        n_splits=globalparams[\"n_splits\"],                # how many chunks the data should have\n",
    "                        fixed_length=globalparams[\"fixed_length\"],         # by setting it False the training data will will grow over time, otherwise it will keep the size given under train_splits\n",
    "                        train_splits=1,             # how many splits should be used to train the model (be aware of these two variables may not work with your strategy, i.e. SMA100 but two training splits are just 110 days or less than 100 days)\n",
    "                        test_splits=1,              # how many splits should the data be tested on?\n",
    "                        cash=globalparams[\"cash\"],\n",
    "                        commission=globalparams[\"commission\"],\n",
    "                        num_evals=globalparams[\"num_eval\"],               # how often should the optimizer try to optimize\n",
    "                        )\n",
    "\n",
    "\n",
    "    class TimeSeriesSplitImproved(TimeSeriesSplit):\n",
    "        \"\"\"Time Series cross-validator\n",
    "        Provides train/test indices to split time series data samples\n",
    "        that are observed at fixed time intervals, in train/test sets.\n",
    "        In each split, test indices must be higher than before, and thus shuffling\n",
    "        in cross validator is inappropriate.\n",
    "        This cross-validation object is a variation of :class:`KFold`.\n",
    "        In the kth split, it returns first k folds as train set and the\n",
    "        (k+1)th fold as test set.\n",
    "        Note that unlike standard cross-validation methods, successive\n",
    "        training sets are supersets of those that come before them.\n",
    "        \"\"\"\n",
    "\n",
    "        def split(self, X, y=None, groups=None, fixed_length=False,\n",
    "                  train_splits=1, test_splits=1):\n",
    "            \"\"\"Generate indices to split data into training and test set.\n",
    "            Parameters\n",
    "            ----------\n",
    "            X : array-like, shape (n_samples, n_features)\n",
    "                Training data, where n_samples is the number of samples\n",
    "                and n_features is the number of features.\n",
    "            y : array-like, shape (n_samples,)\n",
    "                Always ignored, exists for compatibility.\n",
    "            groups : array-like, with shape (n_samples,), optional\n",
    "                Always ignored, exists for compatibility.\n",
    "            fixed_length : bool, whether training sets should always have\n",
    "                common length\n",
    "            train_splits : positive int, for the minimum number of\n",
    "                splits to include in training sets\n",
    "            test_splits : positive int, for the number of splits to\n",
    "                include in the test set\n",
    "            Returns\n",
    "            -------\n",
    "            train : ndarray\n",
    "                The training set indices for that split.\n",
    "            test : ndarray\n",
    "                The testing set indices for that split.\n",
    "            \"\"\"\n",
    "            X, y, groups = indexable(X, y, groups)\n",
    "            n_samples = _num_samples(X)\n",
    "            n_splits = self.n_splits\n",
    "            n_folds = n_splits + 1\n",
    "            train_splits, test_splits = int(train_splits), int(test_splits)\n",
    "            if n_folds > n_samples:\n",
    "                raise ValueError(\n",
    "                    (\"Cannot have number of folds ={0} greater\"\n",
    "                     \" than the number of samples: {1}.\").format(n_folds,\n",
    "                                                                 n_samples))\n",
    "            if ((n_folds - train_splits - test_splits) == 0 and test_splits > 0):\n",
    "                raise ValueError(\n",
    "                    (\"Both train_splits and test_splits must be positive\"\n",
    "                     \" integers.\"))\n",
    "            indices = np.arange(n_samples)\n",
    "            split_size = (n_samples // n_folds)\n",
    "            test_size = split_size * test_splits\n",
    "            train_size = split_size * train_splits\n",
    "            test_starts = range(train_size + n_samples % n_folds,\n",
    "                                n_samples - (test_size - split_size),\n",
    "                                split_size)\n",
    "\n",
    "            if fixed_length:\n",
    "                for i, test_start in zip(range(len(test_starts)),\n",
    "                                         test_starts):\n",
    "                    rem = 0\n",
    "                    if i == 0:\n",
    "                        rem = n_samples % n_folds\n",
    "                    yield (indices[(test_start - train_size - rem):test_start],\n",
    "                           indices[test_start:test_start + test_size])\n",
    "            else:\n",
    "                for test_start in test_starts:\n",
    "                    yield (indices[:test_start],\n",
    "                           indices[test_start:test_start + test_size])\n",
    "\n",
    "    class AcctStats(bt.Analyzer):\n",
    "        \"\"\"A simple analyzer that gets the gain in the value of the account; should be self-explanatory\"\"\"\n",
    "\n",
    "        def __init__(self):\n",
    "            self.start_val = self.strategy.broker.get_value()\n",
    "            self.end_val = None\n",
    "\n",
    "        def stop(self):\n",
    "            self.end_val = self.strategy.broker.get_value()\n",
    "\n",
    "        def get_analysis(self):\n",
    "            return {\"start\": self.start_val, \"end\": self.end_val,\n",
    "                    \"growth\": self.end_val - self.start_val, \"return\": self.end_val / self.start_val}\n",
    "\n",
    "    for df in datafeeds.values():\n",
    "        df[\"OpenInterest\"] = 0  # PandasData reader expects an OpenInterest column;\n",
    "\n",
    "    tscv = TimeSeriesSplitImproved(globalparameters['n_splits'])\n",
    "    split = tscv.split(datafeeds[list(datafeeds.keys())[2]], fixed_length=globalparameters['fixed_length'], train_splits=globalparameters['train_splits'], test_splits=globalparameters['test_splits'])\n",
    "    walk_forward_results = list()\n",
    "    \n",
    "    heatmap_data = []\n",
    "    # Be prepared: this will take a while\n",
    "    i = 0\n",
    "    for train, test in split:\n",
    "        i += 1\n",
    "        # TRAINING\n",
    "        # Optimize with optunity\n",
    "        def runstrat(p1=globalparams[\"selcperc\"], p2=globalparams[\"mperiod\"], p3=globalparams[\"rocperiod\"],printlog=True , WFA=False):\n",
    "            cerebro = bt.Cerebro(maxcpus=0,stdstats=True)\n",
    "            cerebro.addstrategy(St, selcperc=p1, mperiod=p2, rocperiod=p3) #change the parameters that should be depicted in heatmap\n",
    "            cerebro.broker.setcash(globalparams[\"cash\"])\n",
    "            cerebro.broker.setcommission(commission=globalparams[\"commission\"])\n",
    "            eval(opta(globalparams[\"optimization_target\"])[0])\n",
    "            for s, df in datafeeds.items():\n",
    "                data = bt.feeds.PandasData(dataname=df.iloc[train], name=s)  # Add a subset of data\n",
    "                cerebro.adddata(data)     \n",
    "            cerebro.broker.set_coc(True)\n",
    "            results1 = cerebro.run()\n",
    "            print(p1, p2, p3, eval(opta(globalparams[\"optimization_target\"])[1]))\n",
    "            return eval(opta(globalparams[\"optimization_target\"])[1])\n",
    "\n",
    "        #Either use Optunity for quick search of optimum\n",
    "        if globalparams[\"optunity\"]:\n",
    "            opt = optunity.maximize(runstrat, num_evals=globalparams[\"num_eval\"], p1=eval(params_comb(globalparams[\"params_combination\"])[0][0]), \n",
    "                                    p2=eval(params_comb(globalparams[\"params_combination\"])[0][1]), \n",
    "                                    p3=eval(params_comb(globalparams[\"params_combination\"])[0][2]))\n",
    "            optimal_pars, details, _ = opt\n",
    "            optimal_pars['var1'] = int(optimal_pars['p1'])\n",
    "            optimal_pars['var2'] = int(optimal_pars['p2'])\n",
    "            optimal_pars['var3'] = int(optimal_pars['p3'])\n",
    "\n",
    "        # or heatmap showing how variables i = (y axis/ p1) and j = (x axis /p2) impact strategy outcome\n",
    "        if globalparams[\"heatmap\"]:\n",
    "            results_list = []\n",
    "            noduplicates = []\n",
    "            runt = 1\n",
    "            for i in eval(params_comb(globalparams[\"params_combination\"])[0][0]):\n",
    "                i = int(i)\n",
    "                for j in eval(params_comb(globalparams[\"params_combination\"])[0][1]):\n",
    "                    j = int(j)\n",
    "                    for k in eval(params_comb(globalparams[\"params_combination\"])[0][2]):  \n",
    "                        k = int(k)\n",
    "                        if runt == 1:\n",
    "                            noduplicates.append([i, j, k])\n",
    "                            # counter incl. time estimation\n",
    "                            if globalparams[\"params_combination\"] == \"returns\":\n",
    "                                PnL = runstrat(p1=i, p2=j, p3=k)/globalparams[\"cash\"] - 1\n",
    "                            else:\n",
    "                                PnL = runstrat(p1=i, p2=j, p3=k)\n",
    "                        else:\n",
    "                            if [i, j, k] in noduplicates:\n",
    "                                continue\n",
    "                            else:\n",
    "                                noduplicates.append([i, j, k])\n",
    "                            if globalparams[\"params_combination\"] == \"returns\":\n",
    "                                PnL = runstrat(p1=i, p2=j, p3=k)/globalparams[\"cash\"] - 1\n",
    "                            else:\n",
    "                                PnL = runstrat(p1=i, p2=j, p3=k)                            \n",
    "\n",
    "                        #add results to list for heatmap function to process\n",
    "                        eval(params_comb(globalparams[\"params_combination\"])[1][0]) #must be adapted\n",
    "                        runt += 1\n",
    "            print(\"start:\", datafeeds[list(datafeeds.keys())[2]].iloc[train[0]].name, \" End: \", datafeeds[list(datafeeds.keys())[2]].iloc[train[-1]].name)\n",
    "            if len(globalparams[\"params_combination\"]) == 2:\n",
    "                my_heatmap1(results_list)\n",
    "            else:\n",
    "                plotly_4d(results_list)\n",
    "                      \n",
    "        if globalparams[\"heatmap\"]:\n",
    "            optimal_pars = {}\n",
    "            #print(results_list)\n",
    "            #best return from the heatmap loop\n",
    "            #print(max(results_list, key=lambda x: x[3]), max(results_list, key=lambda x: x[3])[0], datafeeds[list(datafeeds.keys())[2]].iloc[test[0]].name)\n",
    "            optimal_pars['var1'] = max(results_list, key=lambda x: x[3])[eval(params_comb(globalparams[\"params_combination\"])[1][1])]\n",
    "            optimal_pars['var2'] = max(results_list, key=lambda x: x[3])[eval(params_comb(globalparams[\"params_combination\"])[1][2])]\n",
    "            optimal_pars['var3'] = max(results_list, key=lambda x: x[3])[eval(params_comb(globalparams[\"params_combination\"])[1][3])]\n",
    "            print(\"Optimal vars 1/2/3 \",optimal_pars['var1'], optimal_pars['var2'], optimal_pars['var3'])\n",
    "        \n",
    "        # TESTING\n",
    "        tester = bt.Cerebro(stdstats=False, maxcpus=None)\n",
    "        tester.broker.set_cash(globalparameters['cash'])\n",
    "        tester.broker.set_coc(True)\n",
    "        tester.broker.setcommission(globalparameters['commission'])\n",
    "        tester.addanalyzer(AcctStats)\n",
    "        tester.addanalyzer(bt.analyzers.SharpeRatio, riskfreerate=0.0)\n",
    "\n",
    "        tester.addstrategy(eval(globalparameters['strategy']), selcperc=optimal_pars['var1'], mperiod=optimal_pars['var2'], rocperiod=optimal_pars['var3'], \n",
    "                           WFA=False, printlog=False)  # Test with optimal combination toDO like above int vs float\n",
    "        for s, df in datafeeds.items():\n",
    "            data = bt.feeds.PandasData(dataname=df.iloc[test], name=s)  # Add a subset of data\n",
    "            tester.adddata(data)\n",
    "\n",
    "        res = tester.run()\n",
    "        res_dict = res[0].analyzers.acctstats.get_analysis()\n",
    "        res_dict[\"var1\"] = optimal_pars['var1']\n",
    "        res_dict[\"var2\"] = optimal_pars['var2']\n",
    "        res_dict[\"var3\"] = optimal_pars['var3']\n",
    "        res_dict[\"sharpe\"] = res[0].analyzers.sharperatio.get_analysis()['sharperatio']\n",
    "        res_dict[\"start_date\"] = datafeeds[list(datafeeds.keys())[2]].iloc[test[0]].name\n",
    "        res_dict[\"end_date\"] = datafeeds[list(datafeeds.keys())[2]].iloc[test[-1]].name\n",
    "        walk_forward_results.append(res_dict)\n",
    "    \n",
    "    \n",
    "    wfdf = DataFrame(walk_forward_results)\n",
    "    print(wfdf.loc[:, wfdf.columns != 'start'])\n",
    "\n",
    "    cerebro_wf = bt.Cerebro(stdstats=False, maxcpus=None)\n",
    "\n",
    "    for s, df in datafeeds.items():\n",
    "        data = bt.feeds.PandasData(dataname=df, name=s, fromdate=wfdf.iloc[0, wfdf.columns.get_loc('start_date')], todate=wfdf.iloc[-1, wfdf.columns.get_loc('end_date')])\n",
    "        \n",
    "        cerebro_wf.adddata(data)  # Give the data to cerebro\n",
    "\n",
    "    cerebro_wf.broker.setcash(globalparameters['cash'])\n",
    "    cerebro_wf.broker.setcommission(globalparameters['commission'])\n",
    "    cerebro_wf.broker.set_coc(True)\n",
    "\n",
    "    cerebro_wf.addstrategy(eval(globalparams['strategy']),\n",
    "                           # Give the results of the above optimization to SMACWalkForward (NOT OPTIONAL)\n",
    "                           selcperc=[f for f in wfdf.var1],\n",
    "                           mperiod=[s for s in wfdf.var2],\n",
    "                           rocperiod=[t for t in wfdf.var3],\n",
    "                           start_dates=[sd.date() for sd in wfdf.start_date],\n",
    "                           end_dates=[ed.date() for ed in wfdf.end_date],\n",
    "                           WFA=True,\n",
    "                           )\n",
    "\n",
    "    cerebro_wf.addobservermulti(bt.observers.BuySell)  # Plots up/down arrows\n",
    "    cerebro_wf.addanalyzer(bt.analyzers.SharpeRatio, riskfreerate=0.0)\n",
    "    cerebro_wf.addanalyzer(btanal.PyFolio)\n",
    "\n",
    "    results = cerebro_wf.run()\n",
    "    print(f\"Sharpe: {results[0].analyzers.sharperatio.get_analysis()['sharperatio']:.3f}\")\n",
    "    \n",
    "    # Quantstats thanks to https://algotrading101.com/learn/backtrader-for-backtesting/\n",
    "    returns, positions, transactions, gross_lev = results[0].analyzers.pyfolio.get_pf_items()\n",
    "    returns.index = returns.index.tz_convert(None)\n",
    "    qs.reports.html(returns, output='stats.html', title='Walkforward '+ globalparams[\"strategy\"])\n",
    "    webbrowser.open('stats.html')\n",
    "        \n",
    "    cerebro_wf.plot(iplot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exection section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run(args=None):\n",
    "    #optreturn=False otherwise the heatmap doesn't work\n",
    "    cerebro = bt.Cerebro(maxcpus=1,\n",
    "                         preload=False,\n",
    "\t\t                 optdatas=False,\n",
    "\t\t                 optreturn=False,\n",
    "\t\t                 stdstats=True) \n",
    "\n",
    "    \n",
    "# <<<Data loading section>>>\n",
    "    \n",
    "    # Parse from/to-date\n",
    "    fromdate = globalparams[\"fromdate\"]\n",
    "    todate = globalparams[\"todate\"]\n",
    "    \n",
    "    datafeeds = {}\n",
    "    \n",
    "    # Add SPY/QQQ as \"Benchmark\"\n",
    "    df0 = pd.read_csv(r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\QQQ.csv', index_col=0, parse_dates=True)\n",
    "    benchdata = bt.feeds.PandasData(dataname=df0,name=\"QQQ\",fromdate=fromdate, todate=todate,  plot=False)\n",
    "    cerebro.adddata(benchdata)\n",
    "    df0 = df0.loc[fromdate : todate]\n",
    "    datafeeds.update({\"QQQ\": df0})\n",
    "    \n",
    "    # Add TMF as \"Bond\"\n",
    "    df1 = pd.read_csv(r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\TLT.csv', index_col=0, parse_dates=True)\n",
    "    bonddata = bt.feeds.PandasData(dataname=df1,name=\"Bond\",fromdate=fromdate, todate=todate, plot=False)\n",
    "    cerebro.adddata(bonddata)\n",
    "    df1 = df1.loc[fromdate : todate]\n",
    "    datafeeds.update({\"Bond\": df1})\n",
    "    \n",
    "    \n",
    "    # add all the data files available in the directory datadir\n",
    "    for fname in glob.glob(os.path.join(globalparams[\"path\"], '*')):\n",
    "        df = pd.read_csv(fname, index_col=0, parse_dates=True)\n",
    "        # Add dataframes to a dictionary for walkforward analysis\n",
    "        if len(df)>210:\n",
    "            cerebro.adddata(bt.feeds.PandasData(dataname=df,name=os.path.basename(fname).replace(\".csv\", \"\"),fromdate=fromdate, todate=todate, plot=False))\n",
    "            #print(os.path.basename(fname).replace(\".csv\", \"\")) #prints the name of the added csv file\n",
    "        df = df.loc[fromdate : todate]\n",
    "        datafeeds.update({os.path.basename(fname).replace(\".csv\", \"\"): df})\n",
    "            \n",
    "       \n",
    "    # <<<Cerebro loading section>>>\n",
    "    if globalparams[\"walk\"]:\n",
    "        walk_forward_analysis(datafeeds)\n",
    "    else:   \n",
    "        # Optimization by Optunity (usually partical swarm if i remember correctly)\n",
    "        def runstrat(p1=globalparams[\"selcperc\"], p2=globalparams[\"mperiod\"], p3=globalparams[\"rocperiod\"]):\n",
    "            cerebro = bt.Cerebro(maxcpus=0,stdstats=True)\n",
    "            cerebro.addstrategy(St, selcperc=p1, mperiod=p2, rocperiod=p3, printlog=False) #change the parameters that should be depicted in heatmap\n",
    "            cerebro.broker.setcash(globalparams[\"cash\"])\n",
    "            cerebro.broker.setcommission(commission=globalparams[\"commission\"])\n",
    "            eval(opta(globalparams[\"optimization_target\"])[0])\n",
    "            cerebro.adddata(benchdata)\n",
    "            cerebro.adddata(bonddata)  \n",
    "            for fname in glob.glob(os.path.join(globalparams[\"path\"], '*')):\n",
    "                df = pd.read_csv(fname, index_col=0, parse_dates=True)\n",
    "                if len(df)>200:\n",
    "                    cerebro.adddata(bt.feeds.PandasData(dataname=df,name=os.path.basename(fname).replace(\".csv\", \"\"),fromdate=fromdate, todate=todate, plot=False))        \n",
    "\n",
    "            cerebro.broker.set_coc(True)\n",
    "            results1 = cerebro.run()\n",
    "            print(p1, p2, p3, eval(opta(globalparams[\"optimization_target\"])[1]))\n",
    "            return eval(opta(globalparams[\"optimization_target\"])[1])\n",
    "\n",
    "        #Either use Optunity for quick search of optimum\n",
    "        if globalparams[\"optunity\"]:\n",
    "            opt = optunity.maximize(runstrat, num_evals=globalparams[\"num_eval\"], p1=eval(params_comb(globalparams[\"params_combination\"])[0][0]), \n",
    "                                    p2=eval(params_comb(globalparams[\"params_combination\"])[0][1]), \n",
    "                                    p3=eval(params_comb(globalparams[\"params_combination\"])[0][2]))\n",
    "            optimal_pars, details, _ = opt\n",
    "            print('Optimal Parameters:')\n",
    "            print('selcperc = %.4f' % optimal_pars['p1'])\n",
    "            print('mperiod = %.4f' % optimal_pars['p2'])\n",
    "            print('rocperiod = %.4f' % optimal_pars['p3'])\n",
    "\n",
    "        # or heatmap showing how variables i = (y axis/ p1) and j = (x axis /p2) impact strategy outcome\n",
    "        if globalparams[\"heatmap\"]:\n",
    "            results_list = []\n",
    "            noduplicates = []\n",
    "            runt = 1\n",
    "            for i in eval(params_comb(globalparams[\"params_combination\"])[0][0]):\n",
    "                i = int(i)\n",
    "                for j in eval(params_comb(globalparams[\"params_combination\"])[0][1]):\n",
    "                    j = int(j)\n",
    "                    for k in eval(params_comb(globalparams[\"params_combination\"])[0][2]):  \n",
    "                        k = int(k)\n",
    "                        if runt == 1:\n",
    "                            noduplicates.append([i, j, k])\n",
    "                            # counter incl. time estimation\n",
    "                            start = time()\n",
    "                            if globalparams[\"params_combination\"] == \"returns\":\n",
    "                                PnL = runstrat(p1=i, p2=j, p3=k)/globalparams[\"cash\"] - 1\n",
    "                            else:\n",
    "                                PnL = runstrat(p1=i, p2=j, p3=k)\n",
    "                            end = time()    \n",
    "                            print(runt, \" of \", len(eval(params_comb(globalparams[\"params_combination\"])[0][0]))\n",
    "                                  *len(eval(params_comb(globalparams[\"params_combination\"])[0][1]))\n",
    "                                  *len(eval(params_comb(globalparams[\"params_combination\"])[0][2])), \n",
    "                                  \" In total approx. \", \n",
    "                                  (end-start)*(len(eval(params_comb(globalparams[\"params_combination\"])[0][0]))\n",
    "                                  *len(eval(params_comb(globalparams[\"params_combination\"])[0][1]))\n",
    "                                  *len(eval(params_comb(globalparams[\"params_combination\"])[0][2]))-1))\n",
    "                        else:\n",
    "                            if [i, j, k] in noduplicates:\n",
    "                                continue\n",
    "                            else:\n",
    "                                noduplicates.append([i, j, k])\n",
    "                            if globalparams[\"params_combination\"] == \"returns\":\n",
    "                                PnL = runstrat(p1=i, p2=j, p3=k)/globalparams[\"cash\"] - 1\n",
    "                            else:\n",
    "                                PnL = runstrat(p1=i, p2=j, p3=k)\n",
    "                                \n",
    "                            print(runt, \" of \", len(eval(params_comb(globalparams[\"params_combination\"])[0][0]))\n",
    "                                  *len(eval(params_comb(globalparams[\"params_combination\"])[0][1]))\n",
    "                                  *len(eval(params_comb(globalparams[\"params_combination\"])[0][2]))) # counter how many loops are done of total loops this might take...\n",
    "\n",
    "                        #add results to list for heatmap function to process\n",
    "                        eval(params_comb(globalparams[\"params_combination\"])[1][0]) #must be adapted\n",
    "                        runt += 1\n",
    "            print(results_list)\n",
    "            if len(globalparams[\"params_combination\"]) == 2:\n",
    "                my_heatmap1(results_list)\n",
    "            else:\n",
    "                plotly_4d(results_list)\n",
    "            return\n",
    "\n",
    "        # add strategy\n",
    "        if globalparams[\"optunity\"]: #Pick other than Buy and Hold Strategy for optunity optimziation\n",
    "            cerebro.addstrategy(eval(globalparams[\"strategy\"]), selcperc=optimal_pars['p1'], mperiod=int(optimal_pars['p2']), rocperiod=int(optimal_pars['p3']))\n",
    "        elif globalparams[\"strategy\"] == \"HSt\": #Buy and Hold Strategy\n",
    "            cerebro.addstrategy(HSt, buy_date=globalparams[\"fromdate\"])\n",
    "        else:    \n",
    "            cerebro.addstrategy(eval(globalparams[\"strategy\"]))\n",
    "\n",
    "\n",
    "        # set the cash, cheat on close and commission\n",
    "        cerebro.broker.setcash(globalparams[\"cash\"])\n",
    "        cerebro.broker.set_coc(True)\n",
    "        cerebro.broker.setcommission(commission=globalparams[\"commission\"])\n",
    "\n",
    "        # Adding Analysers\n",
    "        #cerebro.addanalyzer(bt.analyzers.SharpeRatio, riskfreerate=0.0, _name='sharpe')\n",
    "        #cerebro.addanalyzer(bt.analyzers.AnnualReturn, _name='annual_return')\n",
    "        cerebro.addanalyzer(btanal.PyFolio)                # Needed to use PyFolio & Quanstat\n",
    "        #cerebro.addanalyzer(btanal.TradeAnalyzer)          # Analyzes individual trades\n",
    "\n",
    "        # If you want to have all data written into a log file\n",
    "        #cerebro.addwriter(bt.WriterFile, csv=True, out='log.csv')\n",
    "\n",
    "        cerebro.addobserver(bt.observers.Benchmark,\n",
    "                            data=benchdata,\n",
    "                            timeframe=bt.TimeFrame.NoTimeFrame)\n",
    "\n",
    "        results = cerebro.run(maxcpus=1)#maxcpu=1 otherwise pickling multiprocessing errors\n",
    "\n",
    "        # <<<Performance analysing section section>>>\n",
    "        cerebro.plot()\n",
    "\n",
    "        # Basic performance evaluation ... final value ... minus starting cash\n",
    "        pnl = cerebro.broker.get_value() - globalparams[\"cash\"]\n",
    "        print('Profit ... or Loss: {:.2f}'.format(pnl))\n",
    "\n",
    "        # Quantstats thanks to https://algotrading101.com/learn/backtrader-for-backtesting/\n",
    "        # Does not work with optstrategy\n",
    "        returns, positions, transactions, gross_lev = results[0].analyzers.pyfolio.get_pf_items()\n",
    "        returns.index = returns.index.tz_convert(None)\n",
    "        qs.reports.html(returns, output='stats.html', title='Momentum '+ globalparams[\"strategy\"] + \" \" + str(int(globalparams[\"selcperc\"])) + \" # of stocks picked\")\n",
    "        webbrowser.open('stats.html')\n",
    "\n",
    "        # Pyfolio if needed\n",
    "        #returns, positions, transactions, gross_lev = results[0].analyzers.pyfolio.get_pf_items()\n",
    "        #benchmark_rets = pd.Series([0.00004] * len(returns.index), index=returns.index)     \n",
    "        #pf.create_full_tear_sheet(returns, positions, transactions, benchmark_rets=benchmark_rets)\n",
    "    \n",
    "# <<<Execute starting section>>>    \n",
    "if __name__ == '__main__':\n",
    "    #cProfile.run(\"run()\") # speed of all parts of the code\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# how do the single stocks perform over the time frame\n",
    "r'''\n",
    "fdate = datetime.datetime(2015, 8, 31)\n",
    "tdate = datetime.datetime(2020, 6, 18)\n",
    "for fname in glob.glob(os.path.join(r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\DAX', '*')):\n",
    "    df = pd.read_csv(fname, index_col=0, parse_dates=True)\n",
    "    a = df.at[fdate,\"Close\"]\n",
    "    b = df.at[tdate,\"Close\"]\n",
    "    print(b/a-1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
