{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Jupyter Extensions - convenience as an extension\n",
    "For Jupyter to bring more added value I recommend you to install extensions\n",
    "pip Commands:\n",
    "\n",
    "pip install jupyter_nbextensions_configurator jupyter_contrib_nbextensions\n",
    "jupyter contrib nbextension install --user\n",
    "jupyter nbextensions_configurator enable --user\n",
    "\n",
    "My Favorites are:\n",
    "* Collapsible headings\n",
    "* Code folding\n",
    "* Notify\n",
    "* Hinterland (can be nice, but I think I didn't come to use it correctly)\n",
    "              \n",
    "Thanks to https://becominghuman.ai/enhance-your-jupyter-experience-with-these-notebook-widgets-a2717921f678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# stretch the code to 90% of the browser width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Potential error messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Indexing errors, i.e. ValueError: Length of values (3519) does not match length of index (3529)\n",
    "    #There are actually 3 data input:\n",
    "    #1. The folder with all the stocks, 2. the benchmark (I tend to use QQQ), 3. the bond (I used TLT)\n",
    "    #These errors are in my experience due to one or several of the input csvs do not cover the time span inserted in the \"fromdate\" / \"todate\" fields in globalparams, \n",
    "    #i.e. the todate goes to 2021 althogh the csvs only cover until mid 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Downloading data from Yahoo\n",
    "Enter symbol, from , to, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r'''\n",
    "import yahoofinance as yf\n",
    "from csv import reader\n",
    "# open file in read mode\n",
    "with open(r'/home/mmd/Data/NASDAQ2021.csv', 'r') as read_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    csv_reader = reader(read_obj)\n",
    "    # Iterate over each row in the csv using reader object\n",
    "    for row in csv_reader:\n",
    "        # row variable is a list that represents a row in csv\n",
    "        from1 = '2020-01-03'\n",
    "        to = '2021-03-13'\n",
    "        string = ''\n",
    "        path = r'/home/mmd/Data/NASDAQ2021/'\n",
    "        hist = yf.HistoricalPrices(string.join(row),  from1, to, frequency='1d')\n",
    "        hist.to_csv(path + string.join(row) + '.csv')\n",
    "'''\n",
    "\n",
    "r'''\n",
    "import yahoofinance as yf\n",
    "#\n",
    "row = \"TLT\"\n",
    "from1 = '2005-10-31'\n",
    "to = '2021-02-26'\n",
    "string = ''\n",
    "path = '/home/mmd/Data/'\n",
    "hist = yf.HistoricalPrices(string.join(row),  from1, to, frequency='1d')\n",
    "hist.to_csv(path + string.join(row) + '.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import webbrowser\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import backtrader as bt\n",
    "import backtrader.analyzers as btanal\n",
    "import pyfolio as pf\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.stats import linregress\n",
    "import quantstats as qs\n",
    "import seaborn as sns\n",
    "import optunity.metrics\n",
    "import math\n",
    "import cProfile\n",
    "from time import time\n",
    "import plotly.graph_objects as go\n",
    "import multiprocess #can pickle when multiprocessing can't\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.rcParams['figure.figsize'] = [20, 20]\n",
    "#plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "\n",
    "import warnings \n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "#Imports for walkforward analysis\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.utils import indexable\n",
    "from sklearn.utils.validation import _num_samples\n",
    "import backtrader.indicators as btind\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "from pandas import Series, DataFrame\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import optunity.metrics\n",
    "import backtrader.analyzers as btanal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalparams = dict(path='/home/mmd/Data/NASDAQ2005/',      # location of your csv files, downloaded from Yahoo.\n",
    "                    fromdate=datetime.datetime(2015, 1, 5),\n",
    "                    todate=datetime.datetime(2020, 3, 12),\n",
    "                    strategy=\"St\",                          # HSt = Buy and Hold, St = Standard Strategy for non-survivorship free bias momentum                    \n",
    "                    \n",
    "                    # Momentum Strategy specifics(= St)        \n",
    "                    mperiod=180,           # lookback period for momentum - default 90 periods\n",
    "                    selcperc=2,            # number of stocks to select from the universe\n",
    "                    time_interval=\"week\", # if it is not \"week\" then it is month\n",
    "                    time_between=1,        # time between time interval, e.g. 1 means weekly, 2 means every 2 weeks etc. same for months\n",
    "                    \n",
    "                    roc = True,        # Whether the rate of change should be taken into consideration\n",
    "                    rocperiod=140,     # rate of change to make sure stock is increasing\n",
    "                    \n",
    "                    r_squared = False, # Whether volatility should be punished when calculating the momentum\n",
    "                    \n",
    "                    stoploss=False,     # Stop loss function (trailing stop loss) (probably is broken since rebalancing was reactivated)\n",
    "                    stoplossperc=0.3,   # where to draw stop loss line\n",
    "                    \n",
    "                    ma = False,      # if stock price below moving average, the stock will not be considered\n",
    "                    maperiod=75,     # moving average period\n",
    "                    \n",
    "                    rebal=True,            # apply proper rebalancing when stocks are sold than have a share above the equal weights\n",
    "                    ranking_weights=False, # instead of equal weights use the rankings, hence a strong performer will be weighted higher\n",
    "                    \n",
    "                    sos=False,              #slope of slope instead if momentum (might not work with walk forward)\n",
    "                    sos_d=60,              #how many days the second slope is based on\n",
    "                    \n",
    "                    ranking_stoploss = False,  # if the rankings drop in the last x days by more than y %, the stock will be sold\n",
    "                    ranking_stoploss_d = 10,   # number of days that the maximum will be calculated from\n",
    "                    ranking_stoploss_p = 0.1,  # percentage between the maximum and the last ranking. If the latter drops below, it will be sold\n",
    "                    \n",
    "                    #fundamental screening (needs data in form of pickle, search for 'pickle' in the code...)\n",
    "                    fundamental=False, # switches on the fundamental screening\n",
    "                    RG_years=3,        # how many years of revenue growth are relevant\n",
    "                    RG_min=0.10,       # minimum revenue growth for RG indicator\n",
    "                    indicator=\"RG\",    # either  RG  (revenue growth) or PSG (Price/Sales Ratio divided by revenue growth (in % * 100)), \n",
    "                                       # P/S Data start for GOOG in 2015, hence when PSG is chosen, the fromdate has to be adjusted\n",
    "                    \n",
    "                    #General optimization parameters\n",
    "                    params_combination= \"23\",               # 1: # of stocks picked from universe, 2: momentum period, 3: roc period\n",
    "                    optimization_target=\"SQN\",          # Relevant for heatmap & optunity. \n",
    "                                                            # Potential Inputs: returns, Sharpe, Sortino, SQN (needs more than 30 trades!), VWR (variablility weighted returns)\n",
    "                    heatmap_yaxisr=np.arange(1, 7, 3),      # y axis range of parameters for heatmap\n",
    "                    heatmap_xaxisr=np.arange(100, 210, 20), # x axis (mperiod) range of parameters for heatmap\n",
    "                    heatmap_zaxisr=np.arange(100, 210, 40), # z axis (ROC) range of parameters for heatmap                    \n",
    "                    \n",
    "                    #Heatmap section\n",
    "                    heatmap=False,  # Does not work with Hold and Buy, Multiprocessing only here implemented (works in normal and walkforward runs)                  \n",
    "                    \n",
    "                    #optimization with optunity (various algorithms e.g. Partical Swarm Optimization)\n",
    "                    optunity=True, # Either optunity or heatmap, Multiprocessing not implemented\n",
    "                    num_eval=1,    # how many evaluations optunity will try // also for Walk Forward Analysis                    \n",
    "                    \n",
    "                    #Walk-forward-analysis, either optunity or heatmap must be switched on\n",
    "                    walk=True,\n",
    "                    fixed_length=False, # by setting it False the training data will will grow over time, otherwise it will keep the size given under train_splits\n",
    "                    n_splits=10,         # how many chunks the data should have\n",
    "                    \n",
    "                    cash=1000000,               # amount of initial captal      \n",
    "                    commission=0.005,           # broker fee/ask/bid spread\n",
    "                    reserve=0.05,               # % of cash that won't be spent due to otherwise canceled orders\n",
    "                    printlog=True,\n",
    "                    ranking_timeanalysis=True, # excel file with rankings of all stocks over time, only works in \"normal\" run (no heatmap/Walk-forward/optunity), \n",
    "                                                # if it doesn't work, shorten the time period in fromdate\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Function section\n",
    "Momentum (with and without volatility correction) [thanks to Teddy Koker https://teddykoker.com/2019/05/momentum-strategy-from-stocks-on-the-move-in-python/ ]  and heatmap for analysis of variable combinations and [thanks to samwindham1 https://github.com/samwindham1/algo-trader/blob/master/backtest/util/analyzers.py ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     24,
     151
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Momentum + ROC + fundamental screening (revenue increases or P/S / revenue growth) + SMA on price\n",
    "class MomentumEnhanced(bt.Indicator):\n",
    "    lines = ('trend', 'momentum')\n",
    "    params = (('period', 190), ('rperiod', 200), ('years', 3), ('RG_min', 0.15), ('PSG_max', 1), ('unpickled_df', 1), ('maperiod', 50))\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.addminperiod(self.params.period)\n",
    "        if globalparams[\"roc\"]:\n",
    "            self.roc = bt.ind.ROC(self.data, period=self.p.rperiod)\n",
    "        if globalparams[\"ma\"]:\n",
    "            self.MA = bt.ind.EMA(self.data, period=self.p.maperiod)\n",
    "            self.crossover = bt.ind.CrossOver(self.data, self.MA) \n",
    "                \n",
    "    def next(self):\n",
    "        #fundamental screening\n",
    "        if globalparams[\"fundamental\"]:\n",
    "            one = self.p.unpickled_df[(self.p.unpickled_df.indicator == \"revenue\") & (self.p.unpickled_df.ticker == self.data._name) & (self.p.unpickled_df.date < np.datetime64(self.data.datetime.date(0)))]\n",
    "            growth = round(((one['value'].iloc[0:4].sum() / one['value'].iloc[self.p.years*4:self.p.years*4 + 4].sum())**(1/float(self.p.years))-1)*100,2)\n",
    "            \n",
    "            if globalparams[\"indicator\"] == \"PSG\":\n",
    "                ps = self.p.unpickled_df[(self.p.unpickled_df.indicator == \"PS\") & (self.p.unpickled_df.ticker == self.data._name) & (self.p.unpickled_df.date < np.datetime64(self.data.datetime.date(0)))]\n",
    "                if growth <= 0:\n",
    "                    growth = 0.00000001\n",
    "                psg = ps[ps.date==ps.date.max()][\"value\"].iloc[0] / growth\n",
    "                if psg > self.p.PSG_max:\n",
    "                    psg = 1\n",
    "                else:\n",
    "                    psg = 0\n",
    "            \n",
    "            if growth > self.p.RG_min:\n",
    "                growth = 0\n",
    "            else:\n",
    "                growth = 1\n",
    "        \n",
    "        #stop loss applied on momentum et al rankings\n",
    "        rsl = 1\n",
    "        if globalparams[\"ranking_stoploss\"]:\n",
    "            #for the first x days there is no ranking that can be used, hence catch errors here\n",
    "            try:\n",
    "                rank_len = len(self.lines.trend.get(ago=-1, size=globalparams[\"ranking_stoploss_d\"]))\n",
    "            except:\n",
    "                rank_len = 1\n",
    "\n",
    "            if rank_len > globalparams[\"ranking_stoploss_d\"]-1:\n",
    "                ranking_SL = max(self.lines.trend.get(ago=-1, size=globalparams[\"ranking_stoploss_d\"])) * (1-globalparams[\"ranking_stoploss_p\"])\n",
    "\n",
    "                if self.lines.trend.get(ago=-1, size=1)[0] < ranking_SL and ranking_SL != \"nan\":\n",
    "                    rsl = 0\n",
    "                else:\n",
    "                    rsl = 1\n",
    "        \n",
    "        #Momentum\n",
    "        returns = np.log(self.data.get(size=self.p.period))\n",
    "        x = np.arange(len(returns))\n",
    "        slope, _, rvalue, _, _ = linregress(x, returns)\n",
    "        momentum_annualized = (1 + slope) ** 252\n",
    "        \n",
    "        #Momentum of Momentum\n",
    "        self.lines.momentum[0] = momentum_annualized\n",
    "        if globalparams[\"sos\"]:\n",
    "            \n",
    "            returns = np.log(self.lines.momentum.get(ago=-1, size=globalparams[\"sos_d\"]))\n",
    "            x = np.arange(len(returns))\n",
    "            slope, _, rvalue, _, _ = linregress(x, returns)\n",
    "            momentum_annualized = (1 + slope) ** 252\n",
    "        \n",
    "        #ROC\n",
    "        rocround = math.ceil(self.roc[0]) if globalparams[\"roc\"] else 1\n",
    "        roc_final = min(1, max(0, rocround)) if globalparams[\"roc\"] else 1\n",
    "        \n",
    "        #Moving average on prices\n",
    "        ma_final = (0 if self.crossover < 0 else 1) if globalparams[\"ma\"] else 1\n",
    "\n",
    "        #final line formula\n",
    "        self.lines.trend[0] = momentum_annualized * roc_final * rsl * ma_final * (rvalue ** 2) / (1 if globalparams[\"r_squared\"] else (rvalue ** 2)) * (1 if not globalparams[\"fundamental\"] else (growth if globalparams[\"indicator\"] == \"RG\" else psg))\n",
    "\n",
    "# Great Heatmap to analyse different combinations of parameters\n",
    "def my_heatmap1(data):\n",
    "    data = np.array(data)\n",
    "    xs = np.unique(data[:, 1].astype(int))\n",
    "    ys = np.unique(data[:, 0].astype(int))\n",
    "    vals = data[:, 2].reshape(len(ys), len(xs))\n",
    "    \n",
    "    #I tried to have texts in the heatmap cells to display more information...\n",
    "    '''\n",
    "    vals1 = data[:, 3].reshape(len(ys), len(xs))\n",
    "    vals2 =[]\n",
    "    for a_, b_ in zip(vals, vals1):\n",
    "        for a1_, b1_ in zip(a_,b_):\n",
    "            vals2.append([\"{},{}\".format(a1_, b1_)])\n",
    "    '''\n",
    "    min_val_ndx = np.unravel_index(np.argmin(vals, axis=None), vals.shape)\n",
    "    max_val_ndx = np.unravel_index(np.argmax(vals, axis=None), vals.shape)\n",
    "    \n",
    "    cmap = LinearSegmentedColormap.from_list('', ['red', 'orange', 'yellow', 'chartreuse', 'limegreen'])\n",
    "    ax = sns.heatmap(vals, xticklabels=xs, yticklabels=ys, cmap='viridis', annot=True, fmt='.2f')\n",
    "\n",
    "    ax.add_patch(Rectangle(min_val_ndx[::-1], 1, 1, fill=False, edgecolor='blue', lw=3, clip_on=False))\n",
    "    ax.add_patch(Rectangle(max_val_ndx[::-1], 1, 1, fill=False, edgecolor='blue', lw=3, clip_on=False))\n",
    "    print(\"Average of all iterations\", [sum(i)/len(i) for i in zip(*data)][2])\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def my_scatter_plot(data):\n",
    "    # create data\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for i in range(0, len(data)):\n",
    "        x.append(data[i][1])\n",
    "        y.append(data[i][0])\n",
    "        z.append(round(data[i][3],0))\n",
    "    '''\n",
    "    # Change color with c and alpha. I map the color to the X axis value.\n",
    "    sc = plt.scatter(x, y, s=z, c=z, cmap=\"viridis\", alpha=0.4)\n",
    "    plt.legend(*sc.legend_elements(\"sizes\", num=6), loc=4)\n",
    "    # Add titles (main and on axis)\n",
    "    plt.xlabel(\"the X axis\")\n",
    "    plt.ylabel(\"the Y axis\")\n",
    "    plt.title(\"A colored bubble plot\")\n",
    "    '''\n",
    "    df = pd.DataFrame(dict(x=x, y=y, z=z))\n",
    "    sns.set_context(\"talk\")\n",
    "    #plt.figure(figsize=(10,6))\n",
    "    pp=sns.scatterplot(x=x, \n",
    "                    y=y,\n",
    "                    size=z,\n",
    "                    sizes=(20,500),\n",
    "                    alpha=0.5,\n",
    "                    data=df)\n",
    "    \n",
    "    for line in range(0,df.shape[0]):\n",
    "        pp.text(df.x[line]+0.2, df.y[line], df.z[line], horizontalalignment='left', size='medium', color='black')\n",
    "    # Put the legend out of the figure\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1),borderaxespad=0)\n",
    "                      \n",
    "    plt.show()\n",
    "\n",
    "def plotly_4d(data):\n",
    "    df1 = pd.DataFrame.from_records(data, columns=['selcperc', 'mperiod', 'rocperiod', 'value'])\n",
    "    df = df1[~(df1['selcperc'].isin([2]))]\n",
    "    df= df.pivot_table(index=['mperiod'], columns=['rocperiod'], values='value').reset_index()\n",
    "    del df['mperiod']\n",
    "    df.drop(df.index[0])\n",
    "    print(df)\n",
    "    fig = go.Figure(data=[go.Surface(z=df.values)])\n",
    "    fig.update_traces(contours_z=dict(show=True, usecolormap=True,\n",
    "                                      highlightcolor=\"limegreen\", project_z=True))\n",
    "    fig.update_layout(title_text=\"Analysis of Strategy\", autosize=False, width=700, height=700,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90))\n",
    "    fig.show() \n",
    "  \n",
    "    \n",
    "class Sortino(bt.Analyzer):\n",
    "    params = (\n",
    "        ('timeframe', bt.TimeFrame.Days),\n",
    "        ('compression', 1),\n",
    "        ('riskfreerate', 0.00),\n",
    "        ('factor', None),\n",
    "        ('convertrate', True),\n",
    "        ('annualize', True),\n",
    "    )\n",
    "\n",
    "    RATEFACTORS = {\n",
    "        bt.TimeFrame.Days: 252,\n",
    "        bt.TimeFrame.Weeks: 52,\n",
    "        bt.TimeFrame.Months: 12,\n",
    "        bt.TimeFrame.Years: 1,\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Sortino, self).__init__()\n",
    "        self.ret = btanal.TimeReturn(\n",
    "            timeframe=self.p.timeframe,\n",
    "            compression=self.p.compression)\n",
    "        self.ratio = 0.0\n",
    "\n",
    "    def stop(self):\n",
    "        returns = list(self.ret.get_analysis().values())\n",
    "\n",
    "        rate = self.p.riskfreerate\n",
    "\n",
    "        factor = None\n",
    "        if self.p.timeframe in self.RATEFACTORS:\n",
    "            # Get the conversion factor from the default table\n",
    "            factor = self.RATEFACTORS[self.p.timeframe]\n",
    "\n",
    "        if factor is not None:\n",
    "            # A factor was found\n",
    "            if self.p.convertrate:\n",
    "                # Standard: downgrade annual returns to timeframe factor\n",
    "                rate = pow(1.0 + rate, 1.0 / factor) - 1.0\n",
    "            else:\n",
    "                # Else upgrade returns to yearly returns\n",
    "                returns = [pow(1.0 + x, factor) - 1.0 for x in returns]\n",
    "\n",
    "        if len(returns):\n",
    "            # Sortino Ratio = (R - T) / TDD\n",
    "            #   R = Avg Returns\n",
    "            #   T = Target (risk-free rate)\n",
    "            #   TDD = Downside Risk\n",
    "            ret_free_avg = np.mean(returns) - rate\n",
    "            tdd = math.sqrt(np.mean([min(0, r - rate)**2 for r in returns]))\n",
    "\n",
    "            try:\n",
    "                ratio = ret_free_avg / tdd\n",
    "\n",
    "                if factor is not None and \\\n",
    "                        self.p.convertrate and self.p.annualize:\n",
    "\n",
    "                    ratio = math.sqrt(factor) * ratio\n",
    "            except (ValueError, TypeError, ZeroDivisionError):\n",
    "                ratio = None\n",
    "\n",
    "        else:\n",
    "            # no returns\n",
    "            ratio = None\n",
    "\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def get_analysis(self):\n",
    "        return dict(sortino=self.ratio)\n",
    "\n",
    "# Picking optimization target and subsequent analyser functions for optimization\n",
    "def opta(i):\n",
    "    switcher={\n",
    "            \"VWR\":['cerebro.addanalyzer(btanal.VWR, _name=\"VWR\")','results1[0].analyzers.VWR.get_analysis()[\"vwr\"]'],\n",
    "            \"Sortino\":['cerebro.addanalyzer(Sortino, _name=\"sortino\")','results1[0].analyzers.sortino.get_analysis()[\"sortino\"]'],\n",
    "            \"returns\":['1==1','cerebro.broker.getvalue()'], #TODO must be tested separately\n",
    "            \"Sharpe\":['cerebro.addanalyzer(btanal.SharpeRatio, _name=\"sharpe\")','results1[0].analyzers.sharpe.get_analysis()[\"sharperatio\"]'],\n",
    "            \"SQN\":['cerebro.addanalyzer(btanal.SQN, _name=\"sqn\")','results1[0].analyzers.sqn.get_analysis()[\"sqn\"]'],\n",
    "         }\n",
    "    return switcher.get(i,\"Optimization Target not available\")\n",
    "\n",
    "def params_comb(i): \n",
    "    switcher={\n",
    "            \"12\":[['globalparams[\"heatmap_yaxisr\"]','globalparams[\"heatmap_xaxisr\"]','[globalparams[\"rocperiod\"],globalparams[\"rocperiod\"]*1.0001]'],['results_list.append([i, j, k, PnL])','2','1','2']], #p1, p2, p3 in optunity maximize\n",
    "            \"13\":[['globalparams[\"heatmap_yaxisr\"]','[globalparams[\"mperiod\"],globalparams[\"mperiod\"]*1.0001]','globalparams[\"heatmap_zaxisr\"]'],['results_list.append([i, k, j, PnL])','1','2','1']],\n",
    "            \"23\":[['[globalparams[\"selcperc\"],globalparams[\"selcperc\"]*1.0001]','globalparams[\"heatmap_xaxisr\"]','globalparams[\"heatmap_zaxisr\"]'],['results_list.append([j, k, i, PnL])','0','0','1']],\n",
    "            \"123\":[['globalparams[\"heatmap_yaxisr\"]','globalparams[\"heatmap_xaxisr\"]','globalparams[\"heatmap_zaxisr\"]'],['results_list.append([i, j, k, PnL])','0','1','2']],\n",
    "         }\n",
    "    return switcher.get(i,\"Optimization Target not available\")\n",
    "\n",
    "def params_comb_optunity(i): \n",
    "    switcher={\n",
    "            \"12\":[['[globalparams[\"heatmap_yaxisr\"][0],globalparams[\"heatmap_yaxisr\"][-1]]','[globalparams[\"heatmap_xaxisr\"][0],globalparams[\"heatmap_xaxisr\"][-1]]','[globalparams[\"rocperiod\"],globalparams[\"rocperiod\"]*1.0001]'],['results_list.append([i, j, k, PnL])','0','1','2']], #p1, p2, p3 in optunity maximize\n",
    "            \"13\":[['[globalparams[\"heatmap_yaxisr\"][0],globalparams[\"heatmap_yaxisr\"][-1]]','[globalparams[\"mperiod\"],globalparams[\"mperiod\"]*1.0001]','[globalparams[\"heatmap_zaxisr\"][0],globalparams[\"heatmap_zaxisr\"][-1]]'],['results_list.append([i, k, j, PnL])','0','2','1']],\n",
    "            \"23\":[['[globalparams[\"selcperc\"],globalparams[\"selcperc\"]*1.0001]','[globalparams[\"heatmap_xaxisr\"][0],globalparams[\"heatmap_xaxisr\"][-1]]','[globalparams[\"heatmap_zaxisr\"][0],globalparams[\"heatmap_zaxisr\"][-1]]'],['results_list.append([j, k, i, PnL])','2','0','1']],\n",
    "            \"123\":[['[globalparams[\"heatmap_yaxisr\"][0],globalparams[\"heatmap_yaxisr\"][-1]]','[globalparams[\"heatmap_xaxisr\"][0],globalparams[\"heatmap_xaxisr\"][-1]]','[globalparams[\"heatmap_zaxisr\"][0],globalparams[\"heatmap_zaxisr\"][-1]]'],['results_list.append([i, j, k, PnL])','0','1','2']],\n",
    "         }\n",
    "    return switcher.get(i,\"Optimization Target not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simple Buy and Hold Strategy\n",
    "Thanks to https://github.com/samuel281/qu-ant/blob/master/lib/strategies/hold_all_strategy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class HSt(bt.Strategy):\n",
    "    params = dict(\n",
    "        buy_date=datetime.datetime.today().isoformat(),\n",
    "    )\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stocks = self.datas[2:] #must filter out bond and spy \n",
    "                  \n",
    "    def next(self):\n",
    "        for d in self.stocks:\n",
    "            if self.getposition(data=d).size:\n",
    "                return\n",
    "        \n",
    "        if self.data.datetime.date(0).isoformat() < self.params.buy_date.isoformat(): #buydate must be determined by the first strategy, since it is the date of the first trade?\n",
    "            return\n",
    "\n",
    "        target_ratio = 1.0 - globalparams[\"reserve\"]\n",
    "        target_ratio_per_sec = target_ratio / len(self.stocks)            \n",
    "        for d in self.stocks:\n",
    "            self.order_target_percent(data=d, target=target_ratio_per_sec)            \n",
    "    \n",
    "    def log(self, arg):\n",
    "        print('{} {}'.format(self.datetime.date(), arg))            \n",
    "            \n",
    "    def on_order_executed(self, order):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Accepted]:\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "        if order.status in [order.Submitted]:\n",
    "            if order.isbuy():\n",
    "\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Buy {} {} {} Price {:.2f} Value {:.2f} Size {} Cash {:.2f} Broker {:.2f}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price , order.created.size, self.broker.getcash(), self.broker.getvalue()))\n",
    "            if order.issell():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Sell {} {} {} Price {:.2f} Value {:.2f} Size {} Broker {:.2f}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price, order.created.size, self.broker.getvalue()))\n",
    "\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "\n",
    "        # Check if an order has been completed\n",
    "        # Attention: broker could reject order if not enough cash\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Buy {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "\n",
    "            if order.issell():# Sell\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Sell {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fill in gaps of survivorship bias free data\n",
    "This was a desparate try to manipulate the data to get survivorship bias free data to work in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r'''\n",
    "import pandas as pd\n",
    "import glob, os, datetime\n",
    "pathh = r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\data/'\n",
    "idx = pd.date_range('2013-02-28', '2018-02-28')\n",
    "for fname in glob.glob(os.path.join(pathh, '*')):\n",
    "    df = pd.read_csv(fname, index_col=0, parse_dates=True)\n",
    "    df1 = df.reindex(idx,fill_value=0)\n",
    "    df1.to_csv(r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\data2/' + os.path.basename(fname).replace(\".csv\", \"\") + '_1.csv')\n",
    "    #print(df1)\n",
    "    #break\n",
    "'''   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Survivor bias free momentum strategy\n",
    "Currently not working strategy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Sur(bt.Strategy):\n",
    "    params = dict(\n",
    "            selcperc=0.50,  # percentage of stocks to select from the universe\n",
    "            rperiod=1,  # period for the returns calculation, default 1 period\n",
    "            vperiod=55,  # lookback period for volatility - default 36 periods\n",
    "            mperiod=155,  # lookback period for momentum - default 90 periods\n",
    "            momentum=MomentumEnhanced, # parametrize the momentum and its period\n",
    "            reserve=globalparams[\"reserve\"],  # 5% reserve capital\n",
    "            monthdays=[1],\n",
    "            monthcarry=True,\n",
    "            when=bt.timer.SESSION_START,\n",
    "            benchmarkstop=False, # If true, no stocks will be bought and no rebalancing will be done if benchmark is below SMAperiod\n",
    "            SMAperiod=200,\n",
    "            benchmark_bond=True, # Sell all Stocks and buy Bonds\n",
    "            jump_momentum=True, # If true, after a time of jump_one (30 days x jump_one) in every month, all the money will be directed to the best performing stock. Rule for that:\n",
    "                                # In Excel, this is a 0.6 x month return of fund with best past 3 month return plus 0.4 x return of fund with best return, month to date.\n",
    "            jump_one=0.6,\n",
    "            printlog=True,\n",
    "        )\n",
    "\n",
    "    def __init__(self):\n",
    "        self.bench = self.data0\n",
    "        self.bond = self.data1\n",
    "        self.stocks = self.datas[2:]\n",
    "        # calculate 1st the amount of stocks that will be selected\n",
    "        self.selnum = int(len(self.stocks) * self.p.selcperc)\n",
    "\n",
    "        # allocation perc per stock\n",
    "        # reserve kept to make sure orders are not rejected due to\n",
    "        # margin. Prices are calculated when known (close), but orders can only\n",
    "        # be executed next day (opening price). Price can gap upwards\n",
    "        self.perctarget = (1.0 - self.p.reserve) / self.selnum\n",
    "        \n",
    "        # This is the set up of the timer that makes the strategy being executed at the given time\n",
    "        self.add_timer(\n",
    "            when=self.p.when,\n",
    "            monthdays=self.p.monthdays,\n",
    "            monthcarry=self.p.monthcarry\n",
    "        )\n",
    "        \n",
    "        self.stocks_len = []\n",
    "        \n",
    "        jump = True\n",
    "\n",
    "        # returns, volatilities and momentums\n",
    "        rs = [bt.ind.PctChange(d, period=self.p.rperiod) for d in self.stocks]\n",
    "        vs = [bt.ind.StdDev(ret, period=self.p.vperiod) for ret in rs]\n",
    "        #ms = [bt.ind.ROC(d, period=self.p.mperiod) for d in self.datas]\n",
    "        ms = [self.p.momentum(d, period=self.p.mperiod) for d in self.stocks]\n",
    "        \n",
    "        self.bench_sma = bt.ind.SMA(self.data0, period=self.p.SMAperiod)\n",
    "        \n",
    "        # simple rank formula: (momentum * net payout) / volatility\n",
    "        # the highest ranked: low vol, large momentum, large payout\n",
    "        self.ranks = {d: m / v for d, v, m in zip(self.stocks, vs, ms)}\n",
    "        #TODO: does it perform better without the volatility?\n",
    "\n",
    "        self.bench_filter = self.bench < self.bench_sma\n",
    "\n",
    "\n",
    "    def log(self, arg):\n",
    "        if self.p.printlog:\n",
    "            print('{} {}'.format(self.datetime.date(), arg))\n",
    "        \n",
    "    # This section is for logging of orders in greater detail to figure out whether the strategy is actually having no problem with orders\n",
    "    '''\n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Accepted]:\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "        if order.status in [order.Submitted]:\n",
    "            if order.isbuy():\n",
    "            \n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Buy {} {} {} Price {:.2f} Value {:.2f} Size {} Cash {:.2f}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price , order.created.size, self.broker.getcash()))\n",
    "            if order.issell():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Sell {} {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price, order.created.size))\n",
    "\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "\n",
    "        # Check if an order has been completed\n",
    "        # Attention: broker could reject order if not enough cash\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Buy {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "\n",
    "            if order.issell():# Sell\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Sell {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "\n",
    "\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "    '''       \n",
    "    \n",
    "    # This is the function using the timer to execute the rebalance \n",
    "    def notify_timer(self, timer, when, *args, **kwargs):\n",
    "        print('strategy notify_timer with tid {}, when {} _getminperstatus {}'.\n",
    "              format(timer.p.tid, when, int(self._getminperstatus())))\n",
    "        print(\"timer\")\n",
    "        if self._getminperstatus() < 0:\n",
    "            self.rebalance()\n",
    "    \n",
    "    def nextstart(self):\n",
    "        self.ranks_filter = self.ranks\n",
    "        print(\"nextstart\")\n",
    "        self.next()\n",
    "        \n",
    "    def prenext(self):\n",
    "        self.stocks_len = [d for d in self.stocks if len(d)]\n",
    "        self.ranks_filter = dict(zip(self.stocks_len, [self.ranks[k] for k in self.stocks_len]))        \n",
    "        self.next()\n",
    "        \n",
    "    def next(self):\n",
    "        print(\"next\")\n",
    "        pass # must be filled with a pass\n",
    "\n",
    "    \n",
    "    # Actual order giving by a ranking takes place here\n",
    "    def rebalance(self):\n",
    "        print(\"rebalance\")\n",
    "        #if jump == True:\n",
    "        # Enter Jump Code here    \n",
    "        \n",
    "        # sort data and current rank\n",
    "        ranks = sorted(\n",
    "            self.ranks_filter.items(),  # get the (d, rank), pair\n",
    "            key=lambda x: x[1][0],  # use rank (elem 1) and current time \"0\"\n",
    "            reverse=True,  # highest ranked 1st ... please\n",
    "        )\n",
    "        \n",
    "        # put top ranked in dict with data as key to test for presence\n",
    "        rtop = dict(ranks[:self.selnum])\n",
    "\n",
    "        # For logging purposes of stocks leaving the portfolio\n",
    "        rbot = dict(ranks[self.selnum:])\n",
    "\n",
    "        # prepare quick lookup list of stocks currently holding a position\n",
    "        posdata = [d for d, pos in self.getpositions().items() if pos]\n",
    "        \n",
    "\n",
    "        if self.p.benchmarkstop:\n",
    "            for d in (d for d in posdata):\n",
    "                if \"Bond\" == d._name and self.bench_filter:\n",
    "                    return\n",
    "                else:\n",
    "                    if \"Bond\" == d._name and not self.bench_filter:\n",
    "                        self.order_target_percent(\"Bond\", target=0.0)\n",
    "                        self.log('Leave {} due to end of down period'.format(d._name))\n",
    "                        return\n",
    "        \n",
    "        # Triple Momentum: If Benchmark index is below SMA, nothing will be bought or rebalanced\n",
    "        if self.p.benchmarkstop:\n",
    "            if self.bench_filter:\n",
    "                #print('SMA {} - Bench {}'.format(self.bench_sma[0], self.bench[0]))\n",
    "                if self.p.benchmark_bond:\n",
    "                    for d in posdata:\n",
    "                        self.log('Leave {} due to switch to Bonds'.format(d._name))\n",
    "                        self.order_target_percent(d, target=0.0)\n",
    "                    self.order_target_percent(\"Bond\", target=0.95)\n",
    "                    self.log('Buy Bond')\n",
    "                    bond_flag = True\n",
    "                    return #Code stops here and skips rebalancing und buying\n",
    "\n",
    "        # remove those no longer top ranked\n",
    "        # do this first to issue sell orders and free cash\n",
    "        for d in (d for d in posdata if d not in rtop):\n",
    "            self.log('Leave {} - Rank {:.2f}'.format(d._name, rbot[d][0]))\n",
    "            self.order_target_percent(d, target=0.0)\n",
    "        \n",
    "        # rebalance those already top ranked and still there\n",
    "        for d in (d for d in posdata if d in rtop):\n",
    "            self.log('Rebal {} - Rank {:.2f}'.format(d._name, rtop[d][0]))\n",
    "            self.order_target_percent(d, target=self.perctarget)\n",
    "            del rtop[d]  # remove it, to simplify next iteration\n",
    "\n",
    "        # issue a target order for the newly top ranked stocks\n",
    "        # do this last, as this will generate buy orders consuming cash\n",
    "        for d in rtop:\n",
    "            self.log('Enter {} - Rank {:.2f}'.format(d._name, rtop[d][0]))\n",
    "            self.order_target_percent(d, target=self.perctarget)\n",
    "            \n",
    "    def stop(self):\n",
    "        pnl = round(self.broker.getvalue() - globalparams[\"cash\"],2)\n",
    "        print('Final PnL: {}'.format(\n",
    "            pnl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum Strategy\n",
    "Originally it is a combination of the momentum strategy example given on the official website:\n",
    "https://www.backtrader.com/blog/2019-05-20-momentum-strategy/momentum-strategy/\n",
    "and  https://teddykoker.com/2019/05/momentum-strategy-from-stocks-on-the-move-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     93
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class St(bt.Strategy):\n",
    "    params = dict(\n",
    "        selcperc=globalparams[\"selcperc\"],  # percentage of stocks to select from the universe\n",
    "        mperiod=globalparams[\"mperiod\"],  # lookback period for momentum - default 90 periods\n",
    "        rocperiod=globalparams[\"rocperiod\"],   # rate of change to make sure stock is increasing\n",
    "        maperiod=globalparams[\"maperiod\"],  # lookback period for momentum - default 90 periods\n",
    "        momentumplus=MomentumEnhanced, # choose which momentum function is used\n",
    "        reserve=globalparams[\"reserve\"],  # 5% reserve capital\n",
    "        monthdays=[1],\n",
    "        monthcarry=True,\n",
    "        weekdays=[5],\n",
    "        weekcarry=True,\n",
    "        benchmarkstop=False, # If true, no stocks will be bought and no rebalancing will be done if benchmark is below SMAperiod / Must be switched off in WFA\n",
    "        SMAperiod=100,\n",
    "        benchmark_bond=True, # Sell all Stocks and buy Bonds\n",
    "        jump_momentum=True, # If true, after a time of jump_one (30 days x jump_one) in every month, all the money will be directed to the best performing stock. Rule for that:\n",
    "                            # In Excel, this is a 0.6 x month return of fund with best past 3 month return plus 0.4 x return of fund with best return, month to date.\n",
    "        jump_one=0.6,\n",
    "        printlog=globalparams[\"printlog\"],\n",
    "        WFA=False,          #Switch for the last \"putting the fragments together run\" of the Walk Forward Analysis\n",
    "        start_dates=None,  # Starting days for trading periods (a list)\n",
    "        end_dates=None,\n",
    "        stoploss=globalparams[\"stoploss\"],   #activate stop loss\n",
    "        stop_loss=globalparams[\"stoplossperc\"],  # price is 10% less than the entry point\n",
    "        trail=True,\n",
    "        \n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        self.bench = self.data0\n",
    "        self.bond = self.data1\n",
    "        self.stocks = self.datas[2:]\n",
    "        # calculate 1st the amount of stocks that will be selected\n",
    "        \n",
    "        self.stoplossorders = {}\n",
    "        if globalparams[\"fundamental\"]:\n",
    "            df_pickle1 = pd.read_pickle(\"/home/mmd/Downloads/BIG.pkl\") #if read_pickle gives you some error with \"_data\" then pip install pandas -U \n",
    "            #data in dropbox, thx to RomanKoshkin: https://github.com/RomanKoshkin/StockScraperMacroTrends2\n",
    "            df_pickle = df_pickle1[(df_pickle1.indicator == \"revenue\") | (df_pickle1.indicator == \"PS\")]\n",
    "            list_stocks = []\n",
    "            for d in self.stocks:\n",
    "                list_stocks.append(d._name)\n",
    "            #df_pickle[\"index\"] = df_pickle['indicator'] + df_pickle['ticker'] + df_pickle['date'].astype(str)\n",
    "            #df_pickle.set_index('date', inplace=True)\n",
    "            df_pickle.drop([\"comp_name\", \"industry\"], axis=1, inplace=True)\n",
    "            df_pickle1 = df_pickle[df_pickle.ticker.isin(list_stocks)]\n",
    "            df_pickle1.sort_values(['indicator', 'ticker', 'date'], ascending=[True, True, False])\n",
    "            #print(df_pickle.to_dict())\n",
    "            self.unpickled_df = df_pickle1\n",
    "\n",
    "        # counter for time in between\n",
    "        self.timer_i = 0\n",
    "        self.posdata =[]\n",
    "        \n",
    "        # This is the set up of the timer that makes the strategy being executed at the given time\n",
    "        if globalparams[\"time_interval\"] == \"week\":\n",
    "            self.add_timer(\n",
    "                when=bt.timer.SESSION_START,\n",
    "                weekdays=self.p.weekdays,\n",
    "                weekcarry=self.p.weekcarry,\n",
    "            )  \n",
    "        else:\n",
    "            self.add_timer(\n",
    "                when=bt.timer.SESSION_START,\n",
    "                monthdays=self.p.monthdays,\n",
    "                monthcarry=self.p.monthcarry,\n",
    "            )\n",
    "\n",
    "        # preparation for Walk Forward Analysis\n",
    "        if self.p.WFA == True:\n",
    "            self.mperiod = dict()\n",
    "            self.vperiod = dict()\n",
    "            self.ms = dict()\n",
    "            self.selnum = dict()\n",
    "\n",
    "            self.date_combos = [c for c in zip(self.p.start_dates, self.p.end_dates)]\n",
    "\n",
    "            # Additional indexing, allowing for differing start/end dates\n",
    "            for sd, ed, f, s, t in zip(self.p.start_dates, self.p.end_dates, self.p.mperiod, self.p.rocperiod, self.p.selcperc):\n",
    "                self.selnum[(sd, ed)] = int(t) # of stocks bought\n",
    "                \n",
    "                # returns, volatilities and momentums\n",
    "                self.ms[(sd, ed)] = [self.p.momentumplus(d, period=int(f), rperiod=int(s)) for d in self.stocks] #toDo how to implement it with two parameters\n",
    "        \n",
    "        #Non walk forward analysis\n",
    "        else:\n",
    "            self.selnum = int(self.p.selcperc)\n",
    "            # allocation perc per stock\n",
    "            #momentums\n",
    "            if globalparams[\"fundamental\"]:\n",
    "                ms = [self.p.momentumplus(d,period=int(self.p.mperiod), rperiod=int(self.p.rocperiod), maperiod=int(self.p.maperiod), unpickled_df=self.unpickled_df) for d in self.stocks]\n",
    "            else:\n",
    "                ms = [self.p.momentumplus(d,period=int(self.p.mperiod), rperiod=int(self.p.rocperiod), maperiod=int(self.p.maperiod)) for d in self.stocks]\n",
    "            self.bench_sma = bt.ind.SMA(self.data0, period=self.p.SMAperiod)\n",
    "\n",
    "            # simple rank formula: (momentum * net payout) / volatility\n",
    "            # the highest ranked: low vol, large momentum, large payout\n",
    "            self.ranks = {d: m for d, m in zip(self.stocks, ms)}\n",
    "            \n",
    "            self.bench_filter = self.bench < self.bench_sma\n",
    "                \n",
    "    def log(self, arg):\n",
    "        if self.p.printlog:\n",
    "            print('{} {}'.format(self.datetime.date(), arg))\n",
    "        \n",
    "    # This section is for logging of orders in greater detail to figure out whether the strategy is actually having no problem with orders\n",
    "    \n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Accepted]:\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "        if order.status in [order.Submitted]:\n",
    "            if order.isbuy():\n",
    "            \n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                self.log('Buy {} {} {} Price {:.2f} Value {:.2f} Size {} Cash {:.2f}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price , order.created.size, self.broker.getcash()))\n",
    "            if order.issell():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                self.log('Sell {} {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price, order.created.size))\n",
    "\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "\n",
    "        # Check if an order has been completed\n",
    "        # Attention: broker could reject order if not enough cash\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                self.log('Buy {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "                \n",
    "                if self.p.stoploss:\n",
    "                    if not self.p.trail:\n",
    "                        stop_price = order.executed.price * (1.0 - self.p.stop_loss)\n",
    "                        storder = self.sell(data=order.data, exectype=bt.Order.Stop, price=stop_price, size=order.executed.size)\n",
    "                        self.stoplossorders[order.data._name] = storder\n",
    "                    else:\n",
    "                        storder = self.sell(data=order.data, exectype=bt.Order.StopTrail, trailpercent=self.p.stop_loss, size=order.executed.size)\n",
    "                        self.stoplossorders[order.data._name] = storder\n",
    "\n",
    "            if order.issell():# Sell\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                self.log('Sell {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.price*order.executed.size, order.executed.size))\n",
    "                if self.p.stoploss:\n",
    "                    del self.stoplossorders[order.data._name]\n",
    "                    for d in (d for d in self.posdata if d in [order.data]):\n",
    "                        self.posdata.remove(d)  \n",
    "\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "           \n",
    "    \n",
    "    # This is the function using the timer to execute the rebalance \n",
    "    def notify_timer(self, timer, when, *args, **kwargs):\n",
    "        #print('strategy notify_timer with tid {}, when {} _getminperstatus {}'.\n",
    "        #      format(timer.p.tid, when, int(self._getminperstatus())))\n",
    "        if self._getminperstatus() < 0:\n",
    "            self.timer_i += 1\n",
    "            if self.timer_i == globalparams[\"time_between\"]:\n",
    "                self.timer_i = 0\n",
    "                self.rebalance()\n",
    "  \n",
    "    def next(self):\n",
    "        pass # must be filled with a pass\n",
    "\n",
    "    \n",
    "    # Actual order giving by a ranking takes place here\n",
    "    def rebalance(self):\n",
    "        \n",
    "        # Walkforward Analysis Section (no triple momentum possible)\n",
    "        if self.p.WFA == True:\n",
    "            # Determine which set of moving averages to use\n",
    "            curdate = self.datetime.date(0)\n",
    "            dtidx = None  # Will be index\n",
    "            # Determine which period (if any) we are in\n",
    "            for sd, ed in self.date_combos:\n",
    "                if sd <= curdate and curdate <= ed:\n",
    "                    dtidx = (sd, ed)\n",
    "                    self.ranks = {d: m for d, m in zip(self.stocks, self.ms[dtidx])}\n",
    "                    \n",
    "                    # sort data and current rank\n",
    "                    ranks = sorted(\n",
    "                        self.ranks.items(),  # get the (d, rank), pair\n",
    "                        key=lambda x: x[1][0],  # use rank (elem 1) and current time \"0\"\n",
    "                        reverse=True,  # highest ranked 1st ... please\n",
    "                    )\n",
    "\n",
    "                    # put top ranked in dict with data as key to test for presence\n",
    "                    rtop = dict(ranks[:self.selnum[dtidx]])\n",
    "\n",
    "                    # For logging purposes of stocks leaving the portfolio\n",
    "                    rbot = dict(ranks[self.selnum[dtidx]:])\n",
    "\n",
    "                    # prepare quick lookup list of stocks currently holding a position\n",
    "                    self.posdata = [d for d, pos in self.getpositions().items() if pos]\n",
    "                    \n",
    "            if dtidx is None:  # Not in any window\n",
    "                pass # Don't engage in trades\n",
    "            else:\n",
    "                self.momentum_core(self.posdata, rtop, rbot, dtidx)             \n",
    "                #test whether momentums differ over time\n",
    "                #print(self.ms[dtidx][0][0], dtidx, \" vs \", self.ms[datetime.date(2019, 8, 30), datetime.date(2020, 11, 10)][0][0])\n",
    "        \n",
    "        # Non walk forward section\n",
    "        else:\n",
    "            # sort data and current rank\n",
    "            ranks = sorted(\n",
    "                self.ranks.items(),  # get the (d, rank), pair\n",
    "                key=lambda x: x[1][0],  # use rank (elem 1) and current time \"0\"\n",
    "                reverse=True,  # highest ranked 1st ... please\n",
    "            )\n",
    "            \n",
    "            # put top ranked in dict with data as key to test for presence\n",
    "            rtop = dict(ranks[:self.selnum])\n",
    "\n",
    "            # For logging purposes of stocks leaving the portfolio\n",
    "            rbot = dict(ranks[self.selnum:])\n",
    "            \n",
    "            # prepare quick lookup list of stocks currently holding a position\n",
    "            self.posdata = [d for d, pos in self.getpositions().items() if pos]\n",
    "            \n",
    "            \n",
    "            if self.p.benchmarkstop:\n",
    "                for d in (d for d in self.posdata):\n",
    "                    if \"Bond\" == d._name and self.bench_filter:\n",
    "                        return\n",
    "                    else:\n",
    "                        if \"Bond\" == d._name and not self.bench_filter:\n",
    "                            self.order_target_percent(\"Bond\", target=0.0)\n",
    "                            self.log('Leave {} due to end of down period'.format(d._name))\n",
    "                            return\n",
    "\n",
    "            # Triple Momentum: If Benchmark index is below SMA, nothing will be bought or rebalanced\n",
    "            if self.p.benchmarkstop:\n",
    "                if self.bench_filter:\n",
    "                    #print('SMA {} - Bench {}'.format(self.bench_sma[0], self.bench[0]))\n",
    "                    if self.p.benchmark_bond:\n",
    "                        for d in self.posdata:\n",
    "                            self.log('Leave {} due to switch to Bonds'.format(d._name))\n",
    "                            self.order_target_percent(d, target=0.0)\n",
    "                        self.order_target_percent(\"Bond\", target=0.95)\n",
    "                        self.log('Buy Bond')\n",
    "                        bond_flag = True\n",
    "                    return #Code stops here and skips rebalancing und buying\n",
    "                \n",
    "            self.momentum_core(self.posdata, rtop, rbot, 0)\n",
    "            \n",
    "    def momentum_core(self, posdata, rtop, rbot, dtidx):\n",
    "        # remove those no longer top ranked\n",
    "        # do this first to issue sell orders and free cash\n",
    "        sell = False\n",
    "        for d in (d for d in posdata if d not in rtop):\n",
    "            self.log('Leave {} - Rank {:.2f}'.format(d._name, rbot[d][0]))\n",
    "            self.order_target_percent(d, target=0.0)\n",
    "            if self.p.WFA == True:\n",
    "                if (0.95 / self.selnum[dtidx]) < self.broker.getposition(d).size * self.broker.getposition(d).adjbase / self.broker.get_value():\n",
    "                    sell = globalparams[\"rebal\"]\n",
    "            else:\n",
    "                if (0.95 / self.selnum) < self.broker.getposition(d).size * self.broker.getposition(d).adjbase / self.broker.get_value():\n",
    "                    sell = globalparams[\"rebal\"]\n",
    "            if self.p.stoploss:\n",
    "                self.cancel(self.stoplossorders[d._name])\n",
    "\n",
    "        sum_stocks = 0\n",
    "        sum_ranking = 0\n",
    "        for d in rtop:\n",
    "            sum_ranking += rtop[d][0]\n",
    "        #catch exceptions:\n",
    "        if sum_ranking == 0:\n",
    "            sum_ranking = 1\n",
    "        # rebalance those already top ranked and still there\n",
    "        for d in (d for d in posdata if d in rtop):\n",
    "            if sell and ((0.95 / self.selnum[dtidx]) if self.p.WFA else (0.95 / self.selnum) < self.broker.getposition(d).size * self.broker.getposition(d).adjbase / self.broker.get_value()):\n",
    "                self.log('Rebal {} - Rank {:.2f}'.format(d._name, rtop[d][0]))\n",
    "                if self.p.WFA == True:\n",
    "                    self.order_target_percent(d, target=0.95 * rtop[d][0]/sum_ranking if globalparams[\"ranking_weights\"] else (0.95 / self.selnum[dtidx]))\n",
    "                else:\n",
    "                    self.order_target_percent(d, target=0.95 * rtop[d][0]/sum_ranking if globalparams[\"ranking_weights\"] else (0.95 / self.selnum))\n",
    "            #Rebalances are just pricy operations which are needed for the buying part ... since it was based on equal weights...\n",
    "            del rtop[d]  # remove it, to simplify next iteration\n",
    "            sum_stocks += self.broker.getposition(d).size * self.broker.getposition(d).adjbase # Calulate the value of the stocks owned\n",
    "\n",
    "\n",
    "        if len(rtop):\n",
    "            sizer_perc = (0.95 - sum_stocks / self.broker.get_value()) / len(rtop) # Have a equal sizer for the cash (you want to invest in)\n",
    "            sum_stocks = 0\n",
    "\n",
    "        # issue a target order for the newly top ranked stocks\n",
    "        # do this last, as this will generate buy orders consuming cash\n",
    "        for d in rtop:\n",
    "            self.log('Enter {} - Rank {:.2f}'.format(d._name, rtop[d][0]))\n",
    "            self.order_target_percent(d, target=0.95 * rtop[d][0]/sum_ranking if globalparams[\"ranking_weights\"] else sizer_perc)\n",
    "           \n",
    "    def stop(self):\n",
    "        #myrankings = self.ranks.Momentumplus.get(size=len(self.ranks))\n",
    "        #print(type(myrankings), myrankings)\n",
    "        \n",
    "        if globalparams[\"ranking_timeanalysis\"]:\n",
    "            t = 1\n",
    "            for k,v in self.ranks.items():\n",
    "                if t == 1:\n",
    "                    time = [k.num2date(x) for x in (k.datetime).get(ago=0, size=len(k))]\n",
    "                    myrankings = pd.DataFrame(columns=[k._name], index=time)\n",
    "                    t +=1\n",
    "                else:\n",
    "                    myrankings[k._name] = 1\n",
    "                list = []\n",
    "                for i in v.get(size=len(v)):\n",
    "                    list.append(i)\n",
    "                myrankings[k._name] = list \n",
    "            myrankings.to_excel(\"output.xlsx\")\n",
    "        pnl = round(self.broker.getvalue() - globalparams[\"cash\"],2)\n",
    "        self.log('Final PnL: {}'.format(\n",
    "            pnl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Walk forward analysis\n",
    "Thanks to https://ntguardian.wordpress.com/2017/06/19/walk-forward-analysis-demonstration-backtrader/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     18,
     91
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def walk_forward_analysis(datafeeds):\n",
    "    # display dataframes more orderly\n",
    "    pd.set_option('display.max_rows', 10)\n",
    "    pd.set_option('display.max_columns', 10)\n",
    "    pd.set_option('display.width', 1000)\n",
    "\n",
    "    globalparameters = dict(strategy=globalparams['strategy'],            # if a different strategy is used\n",
    "                        n_splits=globalparams[\"n_splits\"],                # how many chunks the data should have\n",
    "                        fixed_length=globalparams[\"fixed_length\"],         # by setting it False the training data will will grow over time, otherwise it will keep the size given under train_splits\n",
    "                        train_splits=1,             # how many splits should be used to train the model (be aware of these two variables may not work with your strategy, i.e. SMA100 but two training splits are just 110 days or less than 100 days)\n",
    "                        test_splits=1,              # how many splits should the data be tested on?\n",
    "                        cash=globalparams[\"cash\"],\n",
    "                        commission=globalparams[\"commission\"],\n",
    "                        num_evals=globalparams[\"num_eval\"],               # how often should the optimizer try to optimize\n",
    "                        )\n",
    "\n",
    "\n",
    "    class TimeSeriesSplitImproved(TimeSeriesSplit):\n",
    "        \"\"\"Time Series cross-validator\n",
    "        Provides train/test indices to split time series data samples\n",
    "        that are observed at fixed time intervals, in train/test sets.\n",
    "        In each split, test indices must be higher than before, and thus shuffling\n",
    "        in cross validator is inappropriate.\n",
    "        This cross-validation object is a variation of :class:`KFold`.\n",
    "        In the kth split, it returns first k folds as train set and the\n",
    "        (k+1)th fold as test set.\n",
    "        Note that unlike standard cross-validation methods, successive\n",
    "        training sets are supersets of those that come before them.\n",
    "        \"\"\"\n",
    "\n",
    "        def split(self, X, y=None, groups=None, fixed_length=False,\n",
    "                  train_splits=1, test_splits=1):\n",
    "            \"\"\"Generate indices to split data into training and test set.\n",
    "            Parameters\n",
    "            ----------\n",
    "            X : array-like, shape (n_samples, n_features)\n",
    "                Training data, where n_samples is the number of samples\n",
    "                and n_features is the number of features.\n",
    "            y : array-like, shape (n_samples,)\n",
    "                Always ignored, exists for compatibility.\n",
    "            groups : array-like, with shape (n_samples,), optional\n",
    "                Always ignored, exists for compatibility.\n",
    "            fixed_length : bool, whether training sets should always have\n",
    "                common length\n",
    "            train_splits : positive int, for the minimum number of\n",
    "                splits to include in training sets\n",
    "            test_splits : positive int, for the number of splits to\n",
    "                include in the test set\n",
    "            Returns\n",
    "            -------\n",
    "            train : ndarray\n",
    "                The training set indices for that split.\n",
    "            test : ndarray\n",
    "                The testing set indices for that split.\n",
    "            \"\"\"\n",
    "            X, y, groups = indexable(X, y, groups)\n",
    "            n_samples = _num_samples(X)\n",
    "            n_splits = self.n_splits\n",
    "            n_folds = n_splits + 1\n",
    "            train_splits, test_splits = int(train_splits), int(test_splits)\n",
    "            if n_folds > n_samples:\n",
    "                raise ValueError(\n",
    "                    (\"Cannot have number of folds ={0} greater\"\n",
    "                     \" than the number of samples: {1}.\").format(n_folds,\n",
    "                                                                 n_samples))\n",
    "            if ((n_folds - train_splits - test_splits) == 0 and test_splits > 0):\n",
    "                raise ValueError(\n",
    "                    (\"Both train_splits and test_splits must be positive\"\n",
    "                     \" integers.\"))\n",
    "            indices = np.arange(n_samples)\n",
    "            split_size = (n_samples // n_folds)\n",
    "            test_size = split_size * test_splits\n",
    "            train_size = split_size * train_splits\n",
    "            test_starts = range(train_size + n_samples % n_folds,\n",
    "                                n_samples - (test_size - split_size),\n",
    "                                split_size)\n",
    "\n",
    "            if fixed_length:\n",
    "                for i, test_start in zip(range(len(test_starts)),\n",
    "                                         test_starts):\n",
    "                    rem = 0\n",
    "                    if i == 0:\n",
    "                        rem = n_samples % n_folds\n",
    "                    yield (indices[(test_start - train_size - rem):test_start],\n",
    "                           indices[test_start:test_start + test_size])\n",
    "            else:\n",
    "                for test_start in test_starts:\n",
    "                    yield (indices[:test_start],\n",
    "                           indices[test_start:test_start + test_size])\n",
    "\n",
    "    class AcctStats(bt.Analyzer):\n",
    "        \"\"\"A simple analyzer that gets the gain in the value of the account; should be self-explanatory\"\"\"\n",
    "\n",
    "        def __init__(self):\n",
    "            self.start_val = self.strategy.broker.get_value()\n",
    "            self.end_val = None\n",
    "\n",
    "        def stop(self):\n",
    "            self.end_val = self.strategy.broker.get_value()\n",
    "\n",
    "        def get_analysis(self):\n",
    "            return {\"start\": self.start_val, \"end\": self.end_val,\n",
    "                    \"growth\": self.end_val - self.start_val, \"return\": self.end_val / self.start_val}\n",
    "\n",
    "    for df in datafeeds.values():\n",
    "        df[\"OpenInterest\"] = 0  # PandasData reader expects an OpenInterest column;\n",
    "\n",
    "    tscv = TimeSeriesSplitImproved(globalparameters['n_splits'])\n",
    "    split = tscv.split(datafeeds[list(datafeeds.keys())[2]], fixed_length=globalparameters['fixed_length'], train_splits=globalparameters['train_splits'], test_splits=globalparameters['test_splits'])\n",
    "    walk_forward_results = list()\n",
    "    \n",
    "    heatmap_data = []\n",
    "    # Be prepared: this will take a while\n",
    "    i = 0\n",
    "    for train, test in split:\n",
    "        i += 1\n",
    "        # TRAINING\n",
    "        # Optimize with optunity\n",
    "        def runstrat(p1=globalparams[\"selcperc\"], p2=globalparams[\"mperiod\"], p3=globalparams[\"rocperiod\"], WFA=False):\n",
    "            cerebro = bt.Cerebro(maxcpus=0,stdstats=False, runonce=False)\n",
    "            cerebro.addstrategy(eval(globalparameters['strategy']), selcperc=p1, mperiod=p2, rocperiod=p3, printlog=False) #change the parameters that should be depicted in heatmap\n",
    "            cerebro.broker.setcash(globalparams[\"cash\"])\n",
    "            cerebro.broker.setcommission(commission=globalparams[\"commission\"])\n",
    "            eval(opta(globalparams[\"optimization_target\"])[0])\n",
    "            for s, df in datafeeds.items():\n",
    "                data = bt.feeds.PandasData(dataname=df.iloc[train], name=s)  # Add a subset of data\n",
    "                cerebro.adddata(data)     \n",
    "            cerebro.broker.set_coc(True)\n",
    "            results1 = cerebro.run()\n",
    "            print(round(p1,0), round(p2,0), round(p3,0), round(eval(opta(globalparams[\"optimization_target\"])[1]),2), round(cerebro.broker.getvalue(),0))\n",
    "            if globalparams[\"heatmap\"]: \n",
    "                return [round(p1,0), round(p2,0), round(p3,0), round(eval(opta(globalparams[\"optimization_target\"])[1]),2), round(cerebro.broker.getvalue()/globalparams[\"cash\"],2)]\n",
    "            if globalparams[\"optunity\"]:\n",
    "                return round(eval(opta(globalparams[\"optimization_target\"])[1]),2)\n",
    "\n",
    "        #Either use Optunity for quick search of optimum\n",
    "        if globalparams[\"optunity\"]:\n",
    "            opt = optunity.maximize(runstrat, num_evals=globalparams[\"num_eval\"], pmap=optunity.pmap, p1=eval(params_comb_optunity(globalparams[\"params_combination\"])[0][0]), \n",
    "                                    p2=eval(params_comb_optunity(globalparams[\"params_combination\"])[0][1]), \n",
    "                                    p3=eval(params_comb_optunity(globalparams[\"params_combination\"])[0][2]))\n",
    "            optimal_pars, details, _ = opt\n",
    "            optimal_pars['var1'] = int(optimal_pars['p1'])\n",
    "            optimal_pars['var2'] = int(optimal_pars['p2'])\n",
    "            optimal_pars['var3'] = int(optimal_pars['p3'])\n",
    "        \n",
    "        # or heatmap showing how variables i = (y axis/ p1) and j = (x axis /p2) impact strategy outcome\n",
    "        if globalparams[\"heatmap\"]:     \n",
    "            pool = multiprocess.Pool(processes=7, maxtasksperchild=1)  \n",
    "            noduplicates = []\n",
    "            runt = 1\n",
    "            for i in eval(params_comb(globalparams[\"params_combination\"])[0][0]):\n",
    "                i = int(i)\n",
    "                for j in eval(params_comb(globalparams[\"params_combination\"])[0][1]):\n",
    "                    j = int(j)\n",
    "                    for k in eval(params_comb(globalparams[\"params_combination\"])[0][2]):  \n",
    "                        k = int(k)\n",
    "                        if runt == 1:\n",
    "                            noduplicates.append([i, j, k])\n",
    "                        else:\n",
    "                            if [i, j, k] in noduplicates:\n",
    "                                continue\n",
    "                            else:\n",
    "                                noduplicates.append([i, j, k])                            \n",
    "                        runt += 1\n",
    "                        \n",
    "            def Convert(lst):\n",
    "                lst2 = [[\"p1\",\"p2\",\"p3\"] for x in range(len(lst))]\n",
    "                res_dct = []\n",
    "                for x in range(len(lst)):\n",
    "                    res_dct.append(dict(zip(lst2[x],lst[x])))\n",
    "                return res_dct\n",
    "            \n",
    "            Convert(noduplicates)\n",
    "\n",
    "            results_list = pool.starmap_async(runstrat, noduplicates,chunksize=1)\n",
    "            pool.close()            \n",
    "            pool.join()\n",
    "            \n",
    "            #sort list since multiprocessing messes up the order\n",
    "            results_list = sorted(results_list.get(), key = lambda x:(x[0], x[1], x[2]))\n",
    "            \n",
    "            if globalparams[\"heatmap\"]:\n",
    "                optimal_pars = {}\n",
    "                #print(results_list)\n",
    "                #best return from the heatmap loop\n",
    "                #print(max(results_list, key=lambda x: x[3]), max(results_list, key=lambda x: x[3])[0], datafeeds[list(datafeeds.keys())[2]].iloc[test[0]].name)\n",
    "                optimal_pars['var1'] = max(results_list, key=lambda x: x[3])[0]\n",
    "                optimal_pars['var2'] = max(results_list, key=lambda x: x[3])[1]\n",
    "                optimal_pars['var3'] = max(results_list, key=lambda x: x[3])[2]\n",
    "                print(\"Optimal vars 1/2/3 \",optimal_pars['var1'], optimal_pars['var2'], optimal_pars['var3'])\n",
    "            \n",
    "            if len(globalparams[\"params_combination\"]) == 2:\n",
    "                for i in range(len(results_list)):\n",
    "                    results_list[i].pop(eval(params_comb(globalparams[\"params_combination\"])[1][1]))\n",
    "                my_heatmap1(results_list)\n",
    "                for i in range(len(results_list)):\n",
    "                    results_list[i].pop(2)\n",
    "                my_heatmap1(results_list)\n",
    "            else:\n",
    "                plotly_4d(results_list)\n",
    "            \n",
    "        \n",
    "        results_list = []\n",
    "        \n",
    "        # TESTING\n",
    "        tester = bt.Cerebro(stdstats=False, maxcpus=None, runonce=False)\n",
    "        tester.broker.set_cash(globalparameters['cash'])\n",
    "        tester.broker.set_coc(True)\n",
    "        tester.broker.setcommission(globalparameters['commission'])\n",
    "        tester.addanalyzer(AcctStats)\n",
    "        tester.addanalyzer(bt.analyzers.SharpeRatio, riskfreerate=0.0)\n",
    "\n",
    "        tester.addstrategy(eval(globalparameters['strategy']), selcperc=optimal_pars['var1'], mperiod=optimal_pars['var2'], rocperiod=optimal_pars['var3'], \n",
    "                           WFA=False, printlog=False)  # Test with optimal combination toDO like above int vs float\n",
    "        for s, df in datafeeds.items():\n",
    "            data = bt.feeds.PandasData(dataname=df.iloc[test], name=s)  # Add a subset of data\n",
    "            tester.adddata(data)\n",
    "\n",
    "        res = tester.run()\n",
    "        res_dict = res[0].analyzers.acctstats.get_analysis()\n",
    "        res_dict[\"var1\"] = optimal_pars['var1']\n",
    "        res_dict[\"var2\"] = optimal_pars['var2']\n",
    "        res_dict[\"var3\"] = optimal_pars['var3']\n",
    "        res_dict[\"sharpe\"] = res[0].analyzers.sharperatio.get_analysis()['sharperatio']\n",
    "        res_dict[\"start_date\"] = datafeeds[list(datafeeds.keys())[2]].iloc[test[0]].name\n",
    "        res_dict[\"end_date\"] = datafeeds[list(datafeeds.keys())[2]].iloc[test[-1]].name\n",
    "        walk_forward_results.append(res_dict)\n",
    "    \n",
    "    \n",
    "    wfdf = DataFrame(walk_forward_results)\n",
    "    print(wfdf.loc[:, wfdf.columns != 'start'])\n",
    "\n",
    "    cerebro_wf = bt.Cerebro(stdstats=False, maxcpus=None, runonce=False)\n",
    "\n",
    "    for s, df in datafeeds.items():\n",
    "        data = bt.feeds.PandasData(dataname=df, name=s, fromdate=wfdf.iloc[0, wfdf.columns.get_loc('start_date')], todate=wfdf.iloc[-1, wfdf.columns.get_loc('end_date')])\n",
    "        cerebro_wf.adddata(data)  # Give the data to cerebro\n",
    "\n",
    "    cerebro_wf.broker.setcash(globalparameters['cash'])\n",
    "    cerebro_wf.broker.setcommission(globalparameters['commission'])\n",
    "    cerebro_wf.broker.set_coc(True)\n",
    "\n",
    "    cerebro_wf.addstrategy(eval(globalparams['strategy']),\n",
    "                           # Give the results of the above optimization to SMACWalkForward (NOT OPTIONAL)\n",
    "                           selcperc=[f for f in wfdf.var1],\n",
    "                           mperiod=[s for s in wfdf.var2],\n",
    "                           rocperiod=[t for t in wfdf.var3],\n",
    "                           start_dates=[sd.date() for sd in wfdf.start_date],\n",
    "                           end_dates=[ed.date() for ed in wfdf.end_date],\n",
    "                           WFA=True,\n",
    "                           )\n",
    "\n",
    "    cerebro_wf.addobservermulti(bt.observers.BuySell)  # Plots up/down arrows\n",
    "    cerebro_wf.addanalyzer(bt.analyzers.SharpeRatio, riskfreerate=0.0)\n",
    "    cerebro_wf.addanalyzer(btanal.PyFolio)\n",
    "\n",
    "    results = cerebro_wf.run()\n",
    "    print(f\"Sharpe: {results[0].analyzers.sharperatio.get_analysis()['sharperatio']:.3f}\")\n",
    "    \n",
    "    # Quantstats thanks to https://algotrading101.com/learn/backtrader-for-backtesting/\n",
    "    returns, positions, transactions, gross_lev = results[0].analyzers.pyfolio.get_pf_items()\n",
    "    returns.index = returns.index.tz_convert(None)\n",
    "    qs.reports.html(returns, output='stats.html', title='Walkforward '+ globalparams[\"strategy\"])\n",
    "    webbrowser.open('stats.html')\n",
    "        \n",
    "    #cerebro_wf.plot(iplot=True) #takes ages to be loaded..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exection section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run(args=None):\n",
    "    #optreturn=False otherwise the heatmap doesn't work\n",
    "    cerebro = bt.Cerebro(maxcpus=1,\n",
    "                         preload=False,\n",
    "\t\t                 optdatas=False,\n",
    "\t\t                 optreturn=False,\n",
    "\t\t                 stdstats=True) \n",
    "    \n",
    "    #plotsize\n",
    "    plt.rcParams['figure.figsize'] = [3, 3]\n",
    "    plt.rcParams['figure.dpi'] = 200\n",
    "        \n",
    "    # <<<Data loading section>>>\n",
    "    \n",
    "    # Parse from/to-date\n",
    "    fromdate = globalparams[\"fromdate\"]\n",
    "    todate = globalparams[\"todate\"]\n",
    "    \n",
    "    datafeeds = {}\n",
    "    \n",
    "    # Add SPY/QQQ as \"Benchmark\"\n",
    "    df0 = pd.read_csv('/home/mmd/Data/QQQ.csv', index_col=0, parse_dates=True)\n",
    "    benchdata = bt.feeds.PandasData(dataname=df0,name=\"QQQ\",fromdate=fromdate, todate=todate,  plot=False)\n",
    "    cerebro.adddata(benchdata)\n",
    "    df0 = df0.loc[fromdate : todate]\n",
    "    datafeeds.update({\"QQQ\": df0})\n",
    "    \n",
    "    # Add TMF as \"Bond\"\n",
    "    df1 = pd.read_csv('/home/mmd/Data/TLT.csv', index_col=0, parse_dates=True)\n",
    "    bonddata = bt.feeds.PandasData(dataname=df1,name=\"Bond\",fromdate=fromdate, todate=todate, plot=False)\n",
    "    cerebro.adddata(bonddata)\n",
    "    df1 = df1.loc[fromdate : todate]\n",
    "    datafeeds.update({\"Bond\": df1})\n",
    "    \n",
    "    \n",
    "    # add all the data files available in the directory datadir\n",
    "    for fname in glob.glob(os.path.join(globalparams[\"path\"], '*')):\n",
    "        df = pd.read_csv(fname, index_col=0, parse_dates=True)\n",
    "        # Add dataframes to a dictionary for walkforward analysis\n",
    "        if len(df)>210:\n",
    "            cerebro.adddata(bt.feeds.PandasData(dataname=df,name=os.path.basename(fname).replace(\".csv\", \"\"),fromdate=fromdate, todate=todate, plot=False))\n",
    "            #print(os.path.basename(fname).replace(\".csv\", \"\")) #prints the name of the added csv file\n",
    "        df = df.loc[fromdate : todate]\n",
    "        datafeeds.update({os.path.basename(fname).replace(\".csv\", \"\"): df})\n",
    "            \n",
    "    results_list = []\n",
    "    # <<<Cerebro loading section>>>\n",
    "    if globalparams[\"walk\"]:\n",
    "        walk_forward_analysis(datafeeds)\n",
    "    else:\n",
    "        ready_list = []\n",
    "        def dummy_func(index):\n",
    "            global ready_list\n",
    "            ready_list.append(index)\n",
    "            \n",
    "        # Optimization by Optunity/Heatmap (must be stated outside of other classes/functions)\n",
    "        def runstrat(p1=globalparams[\"selcperc\"], p2=globalparams[\"mperiod\"], p3=globalparams[\"rocperiod\"]):\n",
    "            cerebro = bt.Cerebro(maxcpus=0,stdstats=True)\n",
    "            cerebro.addstrategy(St, selcperc=p1, mperiod=p2, rocperiod=p3, printlog=False) #change the parameters that should be depicted in heatmap\n",
    "            cerebro.broker.setcash(globalparams[\"cash\"])\n",
    "            cerebro.broker.setcommission(commission=globalparams[\"commission\"])\n",
    "            eval(opta(globalparams[\"optimization_target\"])[0])\n",
    "            cerebro.adddata(benchdata)\n",
    "            cerebro.adddata(bonddata)  \n",
    "            for fname in glob.glob(os.path.join(globalparams[\"path\"], '*')):\n",
    "                df = pd.read_csv(fname, index_col=0, parse_dates=True)\n",
    "                if len(df)>200:\n",
    "                    cerebro.adddata(bt.feeds.PandasData(dataname=df,name=os.path.basename(fname).replace(\".csv\", \"\"),fromdate=fromdate, todate=todate, plot=False))        \n",
    "\n",
    "            cerebro.broker.set_coc(True)\n",
    "            results1 = cerebro.run()\n",
    "            #add results to list for heatmap function to process\n",
    "            #eval(params_comb(globalparams[\"params_combination\"])[1][0])\n",
    "            #print results\n",
    "            print(round(p1,0), round(p2,0), round(p3,0), round(eval(opta(globalparams[\"optimization_target\"])[1]),2), round(cerebro.broker.getvalue()/globalparams[\"cash\"],2))\n",
    "\n",
    "            #the return is as far as I can see just legacy since the line above will be used\n",
    "            if globalparams[\"heatmap\"]: \n",
    "                return [round(p1,0), round(p2,0), round(p3,0), round(eval(opta(globalparams[\"optimization_target\"])[1]),1), round(cerebro.broker.getvalue()/globalparams[\"cash\"],1)]\n",
    "            if globalparams[\"optunity\"]:\n",
    "                return round(eval(opta(globalparams[\"optimization_target\"])[1]),2)\n",
    "            \n",
    "        #Either use Optunity for quick search of optimum\n",
    "        if globalparams[\"optunity\"]:\n",
    "            opt = optunity.maximize(runstrat, num_evals=globalparams[\"num_eval\"], pmap=optunity.pmap, p1=eval(params_comb_optunity(globalparams[\"params_combination\"])[0][0]), \n",
    "                                    p2=eval(params_comb_optunity(globalparams[\"params_combination\"])[0][1]), \n",
    "                                    p3=eval(params_comb_optunity(globalparams[\"params_combination\"])[0][2]))\n",
    "            optimal_pars, details, _ = opt\n",
    "            print('Optimal Parameters:')\n",
    "            print('selcperc = %.4f' % optimal_pars['p1'])\n",
    "            print('mperiod = %.4f' % optimal_pars['p2'])\n",
    "            print('rocperiod = %.4f' % optimal_pars['p3'])\n",
    "\n",
    "\n",
    "        # or heatmap showing how variables i = (y axis/ p1) and j = (x axis /p2) impact strategy outcome\n",
    "        if globalparams[\"heatmap\"]:     \n",
    "            pool = multiprocess.Pool(processes=7, maxtasksperchild=1)  \n",
    "            noduplicates = []\n",
    "            runt = 1\n",
    "            for i in eval(params_comb(globalparams[\"params_combination\"])[0][0]):\n",
    "                i = int(i)\n",
    "                for j in eval(params_comb(globalparams[\"params_combination\"])[0][1]):\n",
    "                    j = int(j)\n",
    "                    for k in eval(params_comb(globalparams[\"params_combination\"])[0][2]):  \n",
    "                        k = int(k)\n",
    "                        if runt == 1:\n",
    "                            noduplicates.append([i, j, k])\n",
    "                        else:\n",
    "                            if [i, j, k] in noduplicates:\n",
    "                                continue\n",
    "                            else:\n",
    "                                noduplicates.append([i, j, k])                            \n",
    "                        runt += 1\n",
    "                        \n",
    "            def Convert(lst):\n",
    "                lst2 = [[\"p1\",\"p2\",\"p3\"] for x in range(len(lst))]\n",
    "                res_dct = []\n",
    "                for x in range(len(lst)):\n",
    "                    res_dct.append(dict(zip(lst2[x],lst[x])))\n",
    "                return res_dct\n",
    "            \n",
    "            Convert(noduplicates)\n",
    "\n",
    "            results_list = pool.starmap_async(runstrat, noduplicates,chunksize=1)\n",
    "            pool.close()            \n",
    "            pool.join()\n",
    "            \n",
    "            #sort list since multiprocessing messes up the order\n",
    "            results_list = sorted(results_list.get(), key = lambda x:(x[0], x[1], x[2]))\n",
    "            \n",
    "            if len(globalparams[\"params_combination\"]) == 2:\n",
    "                for i in range(len(results_list)):\n",
    "                    results_list[i].pop(eval(params_comb(globalparams[\"params_combination\"])[1][1]))\n",
    "                my_heatmap1(results_list)\n",
    "                for i in range(len(results_list)):\n",
    "                    results_list[i].pop(2)\n",
    "                my_heatmap1(results_list)\n",
    "            else:\n",
    "                plotly_4d(results_list)\n",
    "            return\n",
    "\n",
    "        # add strategy\n",
    "        if globalparams[\"optunity\"]: #Pick other than Buy and Hold Strategy for optunity optimziation\n",
    "            cerebro.addstrategy(eval(gmatplotliblobalparams[\"strategy\"]), selcperc=optimal_pars['p1'], mperiod=int(optimal_pars['p2']), rocperiod=int(optimal_pars['p3']))\n",
    "        elif globalparams[\"strategy\"] == \"HSt\": #Buy and Hold Strategy\n",
    "            cerebro.addstrategy(HSt, buy_date=globalparams[\"fromdate\"])\n",
    "        else:    \n",
    "            cerebro.addstrategy(eval(globalparams[\"strategy\"]))\n",
    "\n",
    "        # set the cash, cheat on close and commission\n",
    "        cerebro.broker.setcash(globalparams[\"cash\"])\n",
    "        cerebro.broker.set_coc(True)\n",
    "        cerebro.broker.setcommission(commission=globalparams[\"commission\"])\n",
    "\n",
    "        # Adding Analysers\n",
    "        #cerebro.addanalyzer(bt.analyzers.SharpeRatio, riskfreerate=0.0, _name='sharpe')\n",
    "        #cerebro.addanalyzer(bt.analyzers.AnnualReturn, _name='annual_return')\n",
    "        cerebro.addanalyzer(btanal.PyFolio)                # Needed to use PyFolio & Quanstat\n",
    "        cerebro.addanalyzer(Sortino, _name=\"sortino\") \n",
    "        #cerebro.addanalyzer(btanal.TradeAnalyzer)          # Analyzes individual trades\n",
    "\n",
    "        # If you want to have all data written into a log file\n",
    "        #cerebro.addwriter(bt.WriterFile, csv=True, out='log.csv')\n",
    "\n",
    "        cerebro.addobserver(bt.observers.Benchmark,\n",
    "                            data=benchdata,\n",
    "                            timeframe=bt.TimeFrame.NoTimeFrame)\n",
    "\n",
    "        results = cerebro.run(maxcpus=0)#maxcpu=1 otherwise pickling multiprocessing errors\n",
    "\n",
    "        # <<<Performance analysing section section>>>\n",
    "        cerebro.plot()\n",
    "\n",
    "        # Basic performance evaluation ... final value ... minus starting cash\n",
    "        pnl = cerebro.broker.get_value() - globalparams[\"cash\"]\n",
    "        print(\"Sortino Ratio : \", results[0].analyzers.sortino.get_analysis()[\"sortino\"])\n",
    "        print('Profit ... or Loss: {:.2f}'.format(pnl))\n",
    "\n",
    "        # Quantstats thanks to https://algotrading101.com/learn/backtrader-for-backtesting/\n",
    "        # Does not work with optstrategy\n",
    "        returns, positions, transactions, gross_lev = results[0].analyzers.pyfolio.get_pf_items()\n",
    "        returns.index = returns.index.tz_convert(None)\n",
    "        qs.reports.html(returns, output='stats.html', title='Momentum '+ globalparams[\"strategy\"] + \" \" + str(int(globalparams[\"selcperc\"])) + \" # of stocks picked\")\n",
    "        webbrowser.open('stats.html')\n",
    "\n",
    "        # Pyfolio if needed\n",
    "        #returns, positions, transactions, gross_lev = results[0].analyzers.pyfolio.get_pf_items()\n",
    "        #benchmark_rets = pd.Series([0.00004] * len(returns.index), index=returns.index)     \n",
    "        #pf.create_full_tear_sheet(returns, positions, transactions, benchmark_rets=benchmark_rets)\n",
    "    \n",
    "# <<<Execute starting section>>>    \n",
    "if __name__ == '__main__':\n",
    "    #cProfile.run(\"run()\") # speed of all parts of the code\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# how do the single stocks perform over the time frame\n",
    "r'''\n",
    "fdate = datetime.datetime(2019, 1, 7)\n",
    "tdate = datetime.datetime(2021, 2, 25)\n",
    "for fname in glob.glob(os.path.join(r'/home/mmd/Data/NASDAQ2021/', '*')):\n",
    "    df = pd.read_csv(fname, index_col=0, parse_dates=True)\n",
    "    a = df.at[fdate,\"Close\"]\n",
    "    b = df.at[tdate,\"Close\"]\n",
    "    print(b/a-1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
