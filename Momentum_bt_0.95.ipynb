{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Jupyter Extensions - convenience as an extension\n",
    "For Jupyter to bring more added value I recommend you to install extensions\n",
    "pip Commands:\n",
    "\n",
    "pip install jupyter_nbextensions_configurator jupyter_contrib_nbextensions\n",
    "jupyter contrib nbextension install --user\n",
    "jupyter nbextensions_configurator enable --user\n",
    "\n",
    "My Favorites are:\n",
    "* Collapsible headings\n",
    "* Code folding\n",
    "* Notify\n",
    "* Hinterland (can be nice, but I think I didn't come to use it correctly)\n",
    "              \n",
    "Thanks to https://becominghuman.ai/enhance-your-jupyter-experience-with-these-notebook-widgets-a2717921f678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stretch the code to 90% of the browser width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Downloading data from Yahoo\n",
    "Enter symbol, from , to, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport yahoofinance as yf\\n#\\nrow = \"TLT\"\\nfrom1 = \\'2005-10-31\\'\\nto = \\'2020-11-11\\'\\nstring = \\'\\'\\npath = r\\'C:\\\\Users\\\\MMD\\\\PycharmProjects\\\\Trading\\\\Data Mining\\\\Data\\\\NASDAQ2005/\\'\\nhist = yf.HistoricalPrices(string.join(row),  from1, to, frequency=\\'1d\\')\\nhist.to_csv(path + string.join(row) + \\'.csv\\')\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r'''\n",
    "import yahoofinance as yf\n",
    "from csv import reader\n",
    "# open file in read mode\n",
    "with open(r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\nasdaq_2010.csv', 'r') as read_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    csv_reader = reader(read_obj)\n",
    "    # Iterate over each row in the csv using reader object\n",
    "    for row in csv_reader:\n",
    "        # row variable is a list that represents a row in csv\n",
    "        from1 = '2005-10-31'\n",
    "        to = '2020-11-11'\n",
    "        string = ''\n",
    "        path = r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\NASDAQ2005/'\n",
    "        hist = yf.HistoricalPrices(string.join(row),  from1, to, frequency='1d')\n",
    "        hist.to_csv(path + string.join(row) + '.csv')\n",
    "'''\n",
    "\n",
    "r'''\n",
    "import yahoofinance as yf\n",
    "#\n",
    "row = \"TLT\"\n",
    "from1 = '2005-10-31'\n",
    "to = '2020-11-11'\n",
    "string = ''\n",
    "path = r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\NASDAQ2005/'\n",
    "hist = yf.HistoricalPrices(string.join(row),  from1, to, frequency='1d')\n",
    "hist.to_csv(path + string.join(row) + '.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mmd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas_datareader\\compat\\__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n",
      "c:\\users\\mmd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pyfolio\\pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import webbrowser\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import backtrader as bt\n",
    "import backtrader.analyzers as btanal\n",
    "import pyfolio as pf\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.stats import linregress\n",
    "import quantstats as qs\n",
    "import seaborn as sns\n",
    "import optunity.metrics\n",
    "import math\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (13,13)\n",
    "\n",
    "import warnings \n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#Imports for walkforward analysis\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.utils import indexable\n",
    "from sklearn.utils.validation import _num_samples\n",
    "import numpy as np\n",
    "import backtrader as bt\n",
    "import backtrader.indicators as btind\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "from pandas import Series, DataFrame\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import optunity.metrics\n",
    "import backtrader.analyzers as btanal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fill in gaps of survivorship bias free data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nimport glob, os, datetime\\npathh = r\\'C:\\\\Users\\\\MMD\\\\PycharmProjects\\\\Trading\\\\Data Mining\\\\Data\\\\data/\\'\\nidx = pd.date_range(\\'2013-02-28\\', \\'2018-02-28\\')\\nfor fname in glob.glob(os.path.join(pathh, \\'*\\')):\\n    df = pd.read_csv(fname, index_col=0, parse_dates=True)\\n    df1 = df.reindex(idx,fill_value=0)\\n    df1.to_csv(r\\'C:\\\\Users\\\\MMD\\\\PycharmProjects\\\\Trading\\\\Data Mining\\\\Data\\\\data2/\\' + os.path.basename(fname).replace(\".csv\", \"\") + \\'_1.csv\\')\\n    #print(df1)\\n    #break\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r'''\n",
    "import pandas as pd\n",
    "import glob, os, datetime\n",
    "pathh = r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\data/'\n",
    "idx = pd.date_range('2013-02-28', '2018-02-28')\n",
    "for fname in glob.glob(os.path.join(pathh, '*')):\n",
    "    df = pd.read_csv(fname, index_col=0, parse_dates=True)\n",
    "    df1 = df.reindex(idx,fill_value=0)\n",
    "    df1.to_csv(r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\data2/' + os.path.basename(fname).replace(\".csv\", \"\") + '_1.csv')\n",
    "    #print(df1)\n",
    "    #break\n",
    "'''   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalparams = dict(path=r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\NASDAQ2005', # location of your csv files downloaded from Yahoo\n",
    "                    fromdate=datetime.datetime(2005, 11, 3),\n",
    "                    todate=datetime.datetime(2020, 6, 18),\n",
    "                    cash=100000,            \n",
    "                    commission=0.005,\n",
    "                    reserve=0.05,\n",
    "                    selcperc=0.02,  # percentage of stocks to select from the universe\n",
    "                    strategy=\"St\", #HSt = Buy and Hold, St = Standard Strategy for non-survivorship free bias momentum\n",
    "                    heatmap=True,  #Does not work with Hold and Buy\n",
    "                    optunity=False,\n",
    "                    printlog=True,\n",
    "                    walk=False,     #switch on Walk-forward-analysis\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function section\n",
    "Momentum (with and without volatility correction) [thanks to Teddy Koker https://teddykoker.com/2019/05/momentum-strategy-from-stocks-on-the-move-in-python/] and heatmap for analysis of variable combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     51
    ]
   },
   "outputs": [],
   "source": [
    "def momentum_func(self, the_array):\n",
    "    r = np.log(the_array)\n",
    "    slope, _, rvalue, _, _ = linregress(np.arange(len(r)), r)\n",
    "    annualized = (1 + slope) ** 252\n",
    "    return annualized * (rvalue ** 2)\n",
    "\n",
    "def momentum_func1(self, the_array):\n",
    "    r = np.log(the_array)\n",
    "    slope, _, rvalue, _, _ = linregress(np.arange(len(r)), r)\n",
    "    annualized = (1 + slope) ** 252\n",
    "    return annualized\n",
    "\n",
    "class Momentum(bt.ind.OperationN):\n",
    "    lines = ('trend',)\n",
    "    func = momentum_func1\n",
    "\n",
    "# Great Heatmap to analyse Output of opstrategy\n",
    "def my_heatmap(data):\n",
    "    data = np.array(data)\n",
    "    xs = np.unique(data[:, 0].astype(float))\n",
    "    ys = np.unique(data[:, 1].astype(int))\n",
    "    vals = data[:, 3].reshape(len(ys), len(xs))\n",
    "    min_val_ndx = np.unravel_index(np.argmin(vals, axis=None), vals.shape)\n",
    "    max_val_ndx = np.unravel_index(np.argmax(vals, axis=None), vals.shape)\n",
    "\n",
    "    cmap = LinearSegmentedColormap.from_list('', ['red', 'orange', 'yellow', 'chartreuse', 'limegreen'])\n",
    "    ax = sns.heatmap(vals, xticklabels=xs, yticklabels=ys, cmap='viridis', annot=True, fmt='.2f')\n",
    "\n",
    "    ax.add_patch(Rectangle(min_val_ndx[::-1], 1, 1, fill=False, edgecolor='blue', lw=3, clip_on=False))\n",
    "    ax.add_patch(Rectangle(max_val_ndx[::-1], 1, 1, fill=False, edgecolor='blue', lw=3, clip_on=False))\n",
    "    print(data)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def my_heatmap1(data):\n",
    "    data = np.array(data)\n",
    "    xs = np.unique(data[:, 1].astype(int))\n",
    "    ys = np.unique(data[:, 0].astype(float))\n",
    "    vals = data[:, 3].reshape(len(ys), len(xs))\n",
    "    min_val_ndx = np.unravel_index(np.argmin(vals, axis=None), vals.shape)\n",
    "    max_val_ndx = np.unravel_index(np.argmax(vals, axis=None), vals.shape)\n",
    "\n",
    "    cmap = LinearSegmentedColormap.from_list('', ['red', 'orange', 'yellow', 'chartreuse', 'limegreen'])\n",
    "    ax = sns.heatmap(vals, xticklabels=xs, yticklabels=ys, cmap='viridis', annot=True, fmt='.2f')\n",
    "\n",
    "    ax.add_patch(Rectangle(min_val_ndx[::-1], 1, 1, fill=False, edgecolor='blue', lw=3, clip_on=False))\n",
    "    ax.add_patch(Rectangle(max_val_ndx[::-1], 1, 1, fill=False, edgecolor='blue', lw=3, clip_on=False))\n",
    "    print(data)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def my_scatter_plot(data):\n",
    "    # create data\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for i in range(0, len(data)):\n",
    "        x.append(data[i][1])\n",
    "        y.append(data[i][0])\n",
    "        z.append(round(data[i][3],0))\n",
    "    '''\n",
    "    # Change color with c and alpha. I map the color to the X axis value.\n",
    "    sc = plt.scatter(x, y, s=z, c=z, cmap=\"viridis\", alpha=0.4)\n",
    "    plt.legend(*sc.legend_elements(\"sizes\", num=6), loc=4)\n",
    "    # Add titles (main and on axis)\n",
    "    plt.xlabel(\"the X axis\")\n",
    "    plt.ylabel(\"the Y axis\")\n",
    "    plt.title(\"A colored bubble plot\")\n",
    "    '''\n",
    "    df = pd.DataFrame(dict(x=x, y=y, z=z))\n",
    "    sns.set_context(\"talk\")\n",
    "    #plt.figure(figsize=(10,6))\n",
    "    pp=sns.scatterplot(x=x, \n",
    "                    y=y,\n",
    "                    size=z,\n",
    "                    sizes=(20,500),\n",
    "                    alpha=0.5,\n",
    "                    data=df)\n",
    "    \n",
    "    for line in range(0,df.shape[0]):\n",
    "        pp.text(df.x[line]+0.2, df.y[line], df.z[line], horizontalalignment='left', size='medium', color='black')\n",
    "    # Put the legend out of the figure\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1),borderaxespad=0)\n",
    "                      \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simple Buy and Hold Strategy\n",
    "Thanks to https://github.com/samuel281/qu-ant/blob/master/lib/strategies/hold_all_strategy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class HSt(bt.Strategy):\n",
    "    params = dict(\n",
    "        buy_date=datetime.datetime.today().isoformat(),\n",
    "    )\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stocks = self.datas[2:] #must filter out bond and spy \n",
    "                  \n",
    "    def next(self):\n",
    "        for d in self.stocks:\n",
    "            if self.getposition(data=d).size:\n",
    "                return\n",
    "        \n",
    "        if self.data.datetime.date(0).isoformat() < self.params.buy_date.isoformat(): #buydate must be determined by the first strategy, since it is the date of the first trade?\n",
    "            return\n",
    "\n",
    "        target_ratio = 1.0 - globalparams[\"reserve\"]\n",
    "        target_ratio_per_sec = target_ratio / len(self.stocks)            \n",
    "        for d in self.stocks:\n",
    "            self.order_target_percent(data=d, target=target_ratio_per_sec)            \n",
    "    \n",
    "    def log(self, arg):\n",
    "        print('{} {}'.format(self.datetime.date(), arg))            \n",
    "            \n",
    "    def on_order_executed(self, order):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Accepted]:\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "        if order.status in [order.Submitted]:\n",
    "            if order.isbuy():\n",
    "\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Buy {} {} {} Price {:.2f} Value {:.2f} Size {} Cash {:.2f} Broker {:.2f}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price , order.created.size, self.broker.getcash(), self.broker.getvalue()))\n",
    "            if order.issell():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Sell {} {} {} Price {:.2f} Value {:.2f} Size {} Broker {:.2f}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price, order.created.size, self.broker.getvalue()))\n",
    "\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "\n",
    "        # Check if an order has been completed\n",
    "        # Attention: broker could reject order if not enough cash\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Buy {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "\n",
    "            if order.issell():# Sell\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Sell {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Survivor bias free momentum strategy\n",
    "Thanks to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Sur(bt.Strategy):\n",
    "    params = dict(\n",
    "            selcperc=0.50,  # percentage of stocks to select from the universe\n",
    "            rperiod=1,  # period for the returns calculation, default 1 period\n",
    "            vperiod=55,  # lookback period for volatility - default 36 periods\n",
    "            mperiod=155,  # lookback period for momentum - default 90 periods\n",
    "            momentum=Momentum, # parametrize the momentum and its period\n",
    "            reserve=globalparams[\"reserve\"],  # 5% reserve capital\n",
    "            monthdays=[1],\n",
    "            monthcarry=True,\n",
    "            when=bt.timer.SESSION_START,\n",
    "            benchmarkstop=False, # If true, no stocks will be bought and no rebalancing will be done if benchmark is below SMAperiod\n",
    "            SMAperiod=200,\n",
    "            benchmark_bond=True, # Sell all Stocks and buy Bonds\n",
    "            jump_momentum=True, # If true, after a time of jump_one (30 days x jump_one) in every month, all the money will be directed to the best performing stock. Rule for that:\n",
    "                                # In Excel, this is a 0.6 x month return of fund with best past 3 month return plus 0.4 x return of fund with best return, month to date.\n",
    "            jump_one=0.6,\n",
    "            printlog=True,\n",
    "        )\n",
    "\n",
    "    def __init__(self):\n",
    "        self.bench = self.data0\n",
    "        self.bond = self.data1\n",
    "        self.stocks = self.datas[2:]\n",
    "        # calculate 1st the amount of stocks that will be selected\n",
    "        self.selnum = int(len(self.stocks) * self.p.selcperc)\n",
    "\n",
    "        # allocation perc per stock\n",
    "        # reserve kept to make sure orders are not rejected due to\n",
    "        # margin. Prices are calculated when known (close), but orders can only\n",
    "        # be executed next day (opening price). Price can gap upwards\n",
    "        self.perctarget = (1.0 - self.p.reserve) / self.selnum\n",
    "        \n",
    "        # This is the set up of the timer that makes the strategy being executed at the given time\n",
    "        self.add_timer(\n",
    "            when=self.p.when,\n",
    "            monthdays=self.p.monthdays,\n",
    "            monthcarry=self.p.monthcarry\n",
    "        )\n",
    "        \n",
    "        self.stocks_len = []\n",
    "        \n",
    "        jump = True\n",
    "\n",
    "        # returns, volatilities and momentums\n",
    "        rs = [bt.ind.PctChange(d, period=self.p.rperiod) for d in self.stocks]\n",
    "        vs = [bt.ind.StdDev(ret, period=self.p.vperiod) for ret in rs]\n",
    "        #ms = [bt.ind.ROC(d, period=self.p.mperiod) for d in self.datas]\n",
    "        ms = [self.p.momentum(d, period=self.p.mperiod) for d in self.stocks]\n",
    "        \n",
    "        self.bench_sma = bt.ind.SMA(self.data0, period=self.p.SMAperiod)\n",
    "        \n",
    "        # simple rank formula: (momentum * net payout) / volatility\n",
    "        # the highest ranked: low vol, large momentum, large payout\n",
    "        self.ranks = {d: m / v for d, v, m in zip(self.stocks, vs, ms)}\n",
    "        #TODO: does it perform better without the volatility?\n",
    "\n",
    "        self.bench_filter = self.bench < self.bench_sma\n",
    "\n",
    "\n",
    "    def log(self, arg):\n",
    "        if self.p.printlog:\n",
    "            print('{} {}'.format(self.datetime.date(), arg))\n",
    "        \n",
    "    # This section is for logging of orders in greater detail to figure out whether the strategy is actually having no problem with orders\n",
    "    '''\n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Accepted]:\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "        if order.status in [order.Submitted]:\n",
    "            if order.isbuy():\n",
    "            \n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Buy {} {} {} Price {:.2f} Value {:.2f} Size {} Cash {:.2f}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price , order.created.size, self.broker.getcash()))\n",
    "            if order.issell():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Sell {} {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price, order.created.size))\n",
    "\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "\n",
    "        # Check if an order has been completed\n",
    "        # Attention: broker could reject order if not enough cash\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Buy {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "\n",
    "            if order.issell():# Sell\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                print('Sell {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "\n",
    "\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "    '''       \n",
    "    \n",
    "    # This is the function using the timer to execute the rebalance \n",
    "    def notify_timer(self, timer, when, *args, **kwargs):\n",
    "        print('strategy notify_timer with tid {}, when {} _getminperstatus {}'.\n",
    "              format(timer.p.tid, when, int(self._getminperstatus())))\n",
    "        print(\"timer\")\n",
    "        if self._getminperstatus() < 0:\n",
    "            self.rebalance()\n",
    "    \n",
    "    def nextstart(self):\n",
    "        self.ranks_filter = self.ranks\n",
    "        print(\"nextstart\")\n",
    "        self.next()\n",
    "        \n",
    "    def prenext(self):\n",
    "        self.stocks_len = [d for d in self.stocks if len(d)]\n",
    "        self.ranks_filter = dict(zip(self.stocks_len, [self.ranks[k] for k in self.stocks_len]))        \n",
    "        self.next()\n",
    "        \n",
    "    def next(self):\n",
    "        print(\"next\")\n",
    "        pass # must be filled with a pass\n",
    "\n",
    "    \n",
    "    # Actual order giving by a ranking takes place here\n",
    "    def rebalance(self):\n",
    "        print(\"rebalance\")\n",
    "        #if jump == True:\n",
    "        # Enter Jump Code here    \n",
    "        \n",
    "        # sort data and current rank\n",
    "        ranks = sorted(\n",
    "            self.ranks_filter.items(),  # get the (d, rank), pair\n",
    "            key=lambda x: x[1][0],  # use rank (elem 1) and current time \"0\"\n",
    "            reverse=True,  # highest ranked 1st ... please\n",
    "        )\n",
    "        \n",
    "        # put top ranked in dict with data as key to test for presence\n",
    "        rtop = dict(ranks[:self.selnum])\n",
    "\n",
    "        # For logging purposes of stocks leaving the portfolio\n",
    "        rbot = dict(ranks[self.selnum:])\n",
    "\n",
    "        # prepare quick lookup list of stocks currently holding a position\n",
    "        posdata = [d for d, pos in self.getpositions().items() if pos]\n",
    "        \n",
    "\n",
    "        if self.p.benchmarkstop:\n",
    "            for d in (d for d in posdata):\n",
    "                if \"Bond\" == d._name and self.bench_filter:\n",
    "                    return\n",
    "                else:\n",
    "                    if \"Bond\" == d._name and not self.bench_filter:\n",
    "                        self.order_target_percent(\"Bond\", target=0.0)\n",
    "                        self.log('Leave {} due to end of down period'.format(d._name))\n",
    "                        return\n",
    "        \n",
    "        # Triple Momentum: If Benchmark index is below SMA, nothing will be bought or rebalanced\n",
    "        if self.p.benchmarkstop:\n",
    "            if self.bench_filter:\n",
    "                #print('SMA {} - Bench {}'.format(self.bench_sma[0], self.bench[0]))\n",
    "                if self.p.benchmark_bond:\n",
    "                    for d in posdata:\n",
    "                        self.log('Leave {} due to switch to Bonds'.format(d._name))\n",
    "                        self.order_target_percent(d, target=0.0)\n",
    "                    self.order_target_percent(\"Bond\", target=0.95)\n",
    "                    self.log('Buy Bond')\n",
    "                    bond_flag = True\n",
    "                    return #Code stops here and skips rebalancing und buying\n",
    "\n",
    "        # remove those no longer top ranked\n",
    "        # do this first to issue sell orders and free cash\n",
    "        for d in (d for d in posdata if d not in rtop):\n",
    "            self.log('Leave {} - Rank {:.2f}'.format(d._name, rbot[d][0]))\n",
    "            self.order_target_percent(d, target=0.0)\n",
    "        \n",
    "        # rebalance those already top ranked and still there\n",
    "        for d in (d for d in posdata if d in rtop):\n",
    "            self.log('Rebal {} - Rank {:.2f}'.format(d._name, rtop[d][0]))\n",
    "            self.order_target_percent(d, target=self.perctarget)\n",
    "            del rtop[d]  # remove it, to simplify next iteration\n",
    "\n",
    "        # issue a target order for the newly top ranked stocks\n",
    "        # do this last, as this will generate buy orders consuming cash\n",
    "        for d in rtop:\n",
    "            self.log('Enter {} - Rank {:.2f}'.format(d._name, rtop[d][0]))\n",
    "            self.order_target_percent(d, target=self.perctarget)\n",
    "            \n",
    "    def stop(self):\n",
    "        pnl = round(self.broker.getvalue() - globalparams[\"cash\"],2)\n",
    "        print('Final PnL: {}'.format(\n",
    "            pnl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum Strategy\n",
    "Originally it is a combination of the momentum strategy example given on the official website:\n",
    "https://www.backtrader.com/blog/2019-05-20-momentum-strategy/momentum-strategy/\n",
    "and  https://teddykoker.com/2019/05/momentum-strategy-from-stocks-on-the-move-in-python/\n",
    "Changes have been made:\n",
    "* Triple momentum, i.e. if benmarkstop is True, benchmark index is below SMAperiod no stocks will be bought anymore. \n",
    "If benchmark_bond is True all stocks will be sold and bond of choice will be bought\n",
    "* Sizer has been adapted to equal distribution of free cash and not equal share among all stocks\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class St(bt.Strategy):\n",
    "    params = dict(\n",
    "        selcperc=globalparams[\"selcperc\"],  # percentage of stocks to select from the universe\n",
    "        rperiod=1,  # period for the returns calculation, default 1 period\n",
    "        vperiod=45,  # lookback period for volatility - default 36 periods\n",
    "        mperiod=190,  # lookback period for momentum - default 90 periods\n",
    "        rocperiod=30,   # rate of change to make sure stock is increasing\n",
    "        momentum=Momentum, # parametrize the momentum and its period\n",
    "        reserve=globalparams[\"reserve\"],  # 5% reserve capital\n",
    "        monthdays=[1],\n",
    "        monthcarry=True,\n",
    "        weekdays=[5],\n",
    "        weekcarry=True,\n",
    "        weeks_between=1,\n",
    "        when=bt.timer.SESSION_START,\n",
    "        benchmarkstop=False, # If true, no stocks will be bought and no rebalancing will be done if benchmark is below SMAperiod\n",
    "        SMAperiod=100,\n",
    "        benchmark_bond=True, # Sell all Stocks and buy Bonds\n",
    "        jump_momentum=True, # If true, after a time of jump_one (30 days x jump_one) in every month, all the money will be directed to the best performing stock. Rule for that:\n",
    "                            # In Excel, this is a 0.6 x month return of fund with best past 3 month return plus 0.4 x return of fund with best return, month to date.\n",
    "        jump_one=0.6,\n",
    "        printlog=globalparams[\"printlog\"],\n",
    "        WFA=False,          #Switch for the last \"putting the fragments together run\" of the Walk Forward Analysis\n",
    "        start_dates=None,  # Starting days for trading periods (a list)\n",
    "        end_dates=None,\n",
    "        rateofchange=True, #if True then stocks will only be bought if they they increased over the rocperiod\n",
    "        \n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        self.bench = self.data0\n",
    "        self.bond = self.data1\n",
    "        self.stocks = self.datas[2:]\n",
    "        # calculate 1st the amount of stocks that will be selected\n",
    "        self.selnum = int(len(self.stocks) * self.p.selcperc)\n",
    "        # allocation perc per stock\n",
    "        # reserve kept to make sure orders are not rejected due to\n",
    "        # margin. Prices are calculated when known (close), but orders can only\n",
    "        # be executed next day (opening price). Price can gap upwards\n",
    "        self.perctarget = (1.0 - self.p.reserve) / self.selnum\n",
    "        self.timer_i = 0\n",
    "        # This is the set up of the timer that makes the strategy being executed at the given time\n",
    "        self.add_timer(\n",
    "            when=self.p.when,\n",
    "            #weekdays=self.p.weekdays,\n",
    "            #weekcarry=self.p.weekcarry\n",
    "            monthdays=self.p.monthdays,\n",
    "            monthcarry=self.p.monthcarry\n",
    "        )\n",
    "        \n",
    "        jump = True\n",
    "\n",
    "        # preparation for Walk Forward Analysis\n",
    "        if self.p.WFA == True:\n",
    "            self.mperiod = dict()\n",
    "            self.vperiod = dict()\n",
    "            self.ms = dict()\n",
    "\n",
    "            self.date_combos = [c for c in zip(self.p.start_dates, self.p.end_dates)]\n",
    "\n",
    "            # Additional indexing, allowing for differing start/end dates\n",
    "            for sd, ed, f, s in zip(self.p.start_dates, self.p.end_dates, self.p.mperiod, self.p.rocperiod):\n",
    "\n",
    "                # returns, volatilities and momentums\n",
    "                #self.ms[(sd, ed)] = [bt.ind.ROC(d, period=f) for d in self.stocks] # alternative momentum indicator\n",
    "                self.ms[(sd, ed)] = [self.p.momentum(d, period=f) for d in self.stocks]\n",
    "                self.ms2[(sd, ed)] = [bt.ind.ROC(d, period=s) for d in self.stocks] # alternative momentum indicator\n",
    "                #self.bench_sma = bt.ind.SMA(self.data0, period=self.p.SMAperiod)\n",
    "\n",
    "                #self.bench_filter = self.bench < self.bench_sma\n",
    "        \n",
    "        #Non walk forward analysis\n",
    "        else:\n",
    "            # returns, volatilities and momentums\n",
    "            #rs = [bt.ind.PctChange(d, period=self.p.rperiod) for d in self.stocks]\n",
    "            #vs = [bt.ind.StdDev(ret, period=self.p.vperiod) for ret in rs]\n",
    "            ms2 = [bt.ind.ROC(d, period=self.p.rocperiod) for d in self.stocks] # alternative momentum indicator\n",
    "            ms = [self.p.momentum(d, period=self.p.mperiod) for d in self.stocks]\n",
    "\n",
    "            self.bench_sma = bt.ind.SMA(self.data0, period=self.p.SMAperiod)\n",
    "            \n",
    "            # simple rank formula: (momentum * net payout) / volatility\n",
    "            # the highest ranked: low vol, large momentum, large payout\n",
    "            self.ranks = {d: m for d, m in zip(self.stocks, ms)}\n",
    "            self.roc = {d: r for d, r in zip(self.stocks, ms2)}\n",
    "            \n",
    "            self.bench_filter = self.bench < self.bench_sma\n",
    "                \n",
    "    def log(self, arg):\n",
    "        if self.p.printlog:\n",
    "            print('{} {}'.format(self.datetime.date(), arg))\n",
    "        \n",
    "    # This section is for logging of orders in greater detail to figure out whether the strategy is actually having no problem with orders\n",
    "    \n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Accepted]:\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "        if order.status in [order.Submitted]:\n",
    "            if order.isbuy():\n",
    "            \n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                self.log('Buy {} {} {} Price {:.2f} Value {:.2f} Size {} Cash {:.2f}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price , order.created.size, self.broker.getcash()))\n",
    "            if order.issell():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                self.log('Sell {} {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                        order.getstatusname(), dt, dn, order.created.price, order.created.size * order.created.price, order.created.size))\n",
    "\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "\n",
    "        # Check if an order has been completed\n",
    "        # Attention: broker could reject order if not enough cash\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                self.log('Buy {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "\n",
    "            if order.issell():# Sell\n",
    "                dt, dn = self.datetime.date(), order.data._name\n",
    "                self.log('Sell {} {} Price {:.2f} Value {:.2f} Size {}'.format(\n",
    "                    dt, dn, order.executed.price, order.executed.value, order.executed.size))\n",
    "\n",
    "\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "           \n",
    "    \n",
    "    # This is the function using the timer to execute the rebalance \n",
    "    def notify_timer(self, timer, when, *args, **kwargs):\n",
    "        #print('strategy notify_timer with tid {}, when {} _getminperstatus {}'.\n",
    "        #      format(timer.p.tid, when, int(self._getminperstatus())))\n",
    "        if self._getminperstatus() < 0:\n",
    "            self.timer_i += 1\n",
    "            if self.timer_i == self.p.weeks_between:\n",
    "                self.timer_i = 0\n",
    "                self.rebalance()\n",
    "  \n",
    "    def next(self):\n",
    "        pass # must be filled with a pass\n",
    "\n",
    "    \n",
    "    # Actual order giving by a ranking takes place here\n",
    "    def rebalance(self):\n",
    "        \n",
    "        # Walkforward Analysis Section (no triple momentum possible)\n",
    "        if self.p.WFA == True:\n",
    "            # Determine which set of moving averages to use\n",
    "            curdate = self.datetime.date(0)\n",
    "            dtidx = None  # Will be index\n",
    "            # Determine which period (if any) we are in\n",
    "            for sd, ed in self.date_combos:\n",
    "                if sd <= curdate and curdate <= ed:\n",
    "                    dtidx = (sd, ed)\n",
    "                    self.ranks = {d: m for d, m in zip(self.stocks, self.ms[dtidx])}\n",
    "                    self.roc = {d: r for d, r in zip(self.stocks, self.ms2[dtidx])}\n",
    "                            # sort data and current rank\n",
    "                    ranks = sorted(\n",
    "                        self.ranks.items(),  # get the (d, rank), pair\n",
    "                        key=lambda x: x[1][0],  # use rank (elem 1) and current time \"0\"\n",
    "                        reverse=True,  # highest ranked 1st ... please\n",
    "                    )\n",
    "\n",
    "                    # put top ranked in dict with data as key to test for presence\n",
    "                    rtop = dict(ranks[:self.selnum])\n",
    "\n",
    "                    # For logging purposes of stocks leaving the portfolio\n",
    "                    rbot = dict(ranks[self.selnum:])\n",
    "\n",
    "                    # prepare quick lookup list of stocks currently holding a position\n",
    "                    posdata = [d for d, pos in self.getpositions().items() if pos]\n",
    "                    \n",
    "            if dtidx is None:  # Not in any window\n",
    "                pass # Don't engage in trades\n",
    "            else:\n",
    "                self.momentum_core(posdata, rtop, rbot)\n",
    "                \n",
    "                #test whether momentums differ over time\n",
    "                #print(self.ms[dtidx][0][0], dtidx, \" vs \", self.ms[datetime.date(2019, 8, 30), datetime.date(2020, 11, 10)][0][0])\n",
    "        \n",
    "        # Non walk forward section\n",
    "        else:\n",
    "            # sort data and current rank\n",
    "            ranks = sorted(\n",
    "                self.ranks.items(),  # get the (d, rank), pair\n",
    "                key=lambda x: x[1][0],  # use rank (elem 1) and current time \"0\"\n",
    "                reverse=True,  # highest ranked 1st ... please\n",
    "            )\n",
    "\n",
    "            # put top ranked in dict with data as key to test for presence\n",
    "            rtop = dict(ranks[:self.selnum])\n",
    "\n",
    "            # For logging purposes of stocks leaving the portfolio\n",
    "            rbot = dict(ranks[self.selnum:])\n",
    "\n",
    "            # prepare quick lookup list of stocks currently holding a position\n",
    "            posdata = [d for d, pos in self.getpositions().items() if pos]\n",
    "            #if jump == True:\n",
    "            # Enter Jump Code here    \n",
    "\n",
    "            \n",
    "            \n",
    "            if self.p.benchmarkstop:\n",
    "                for d in (d for d in posdata):\n",
    "                    if \"Bond\" == d._name and self.bench_filter:\n",
    "                        return\n",
    "                    else:\n",
    "                        if \"Bond\" == d._name and not self.bench_filter:\n",
    "                            self.order_target_percent(\"Bond\", target=0.0)\n",
    "                            self.log('Leave {} due to end of down period'.format(d._name))\n",
    "                            return\n",
    "\n",
    "            # Triple Momentum: If Benchmark index is below SMA, nothing will be bought or rebalanced\n",
    "            if self.p.benchmarkstop:\n",
    "                if self.bench_filter:\n",
    "                    #print('SMA {} - Bench {}'.format(self.bench_sma[0], self.bench[0]))\n",
    "                    if self.p.benchmark_bond:\n",
    "                        for d in posdata:\n",
    "                            self.log('Leave {} due to switch to Bonds'.format(d._name))\n",
    "                            self.order_target_percent(d, target=0.0)\n",
    "                        self.order_target_percent(\"Bond\", target=0.95)\n",
    "                        self.log('Buy Bond')\n",
    "                        bond_flag = True\n",
    "                    return #Code stops here and skips rebalancing und buying\n",
    "                \n",
    "            self.momentum_core(posdata, rtop, rbot)\n",
    "            \n",
    "    def momentum_core(self, posdata, rtop, rbot):\n",
    "        # remove those no longer top ranked\n",
    "        # do this first to issue sell orders and free cash\n",
    "        for d in (d for d in posdata if d not in rtop):\n",
    "            self.log('Leave {} - Rank {:.2f}'.format(d._name, rbot[d][0]))\n",
    "            self.order_target_percent(d, target=0.0)\n",
    "\n",
    "        sum_stocks = 0\n",
    "        # rebalance those already top ranked and still there\n",
    "        for d in (d for d in posdata if d in rtop):\n",
    "            #self.log('Rebal {} - Rank {:.2f}'.format(d._name, rtop[d][0]))\n",
    "            #self.order_target_percent(d, target=self.perctarget)\n",
    "            #Rebalances are just pricy operations which are needed for the buying part ... since it was based on equal weights...\n",
    "            del rtop[d]  # remove it, to simplify next iteration\n",
    "            sum_stocks += self.broker.getposition(d).size * self.broker.getposition(d).adjbase # Calulate the value of the stocks owned\n",
    "\n",
    "\n",
    "        if len(rtop):\n",
    "            sizer_perc = (0.95 - sum_stocks / self.broker.get_value()) / len(rtop) # Have a equal sizer for the cash (you want to invest in)\n",
    "            sum_stocks = 0\n",
    "\n",
    "        # issue a target order for the newly top ranked stocks\n",
    "        # do this last, as this will generate buy orders consuming cash\n",
    "        for d in rtop:\n",
    "            if self.p.rateofchange == True:\n",
    "                rate = min(1, max(0, int(math.ceil(self.roc[d][0]))))\n",
    "            else:\n",
    "                rate = 1\n",
    "            if  rate == 0: # new algorithm (positive rate of change)\n",
    "                pass\n",
    "            else:\n",
    "                self.log('Enter {} - Rank {:.2f}'.format(d._name, rtop[d][0]))\n",
    "                self.order_target_percent(d, target=sizer_perc)\n",
    "            \n",
    "    def stop(self):\n",
    "        pnl = round(self.broker.getvalue() - globalparams[\"cash\"],2)\n",
    "        self.log('Final PnL: {}'.format(\n",
    "            pnl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Walk forward analysis\n",
    "Thanks to https://ntguardian.wordpress.com/2017/06/19/walk-forward-analysis-demonstration-backtrader/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     23,
     140
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def walk_forward_analysis(datafeeds):\n",
    "\n",
    "    # display dataframes more orderly\n",
    "    pd.set_option('display.max_rows', 10)\n",
    "    pd.set_option('display.max_columns', 10)\n",
    "    pd.set_option('display.width', 1000)\n",
    "\n",
    "    globalparameters = dict(strategy=globalparams['strategy'],            # if a different strategy is used\n",
    "                        n_splits=6,                # how many chunks the data should have\n",
    "                        fixed_length=False,         # by setting it False the training data will will grow over time, otherwise it will keep the size given under train_splits\n",
    "                        train_splits=1,             # how many splits should be used to train the model (be aware of these two variables may not work with your strategy, i.e. SMA100 but two training splits are just 110 days or less than 100 days)\n",
    "                        test_splits=1,              # how many splits should the data be tested on?\n",
    "                        cash=globalparams[\"cash\"],\n",
    "                        commission=0.02,\n",
    "                        coc=True,\n",
    "                        num_evals=2,               # how often should the optimizer try to optimize\n",
    "                        var1range=[2, 200],        # reasonable range within the optimization should happen (variable 1)\n",
    "                        var2range=[2, 3],        # reasonable range within the optimization should happen (variable 2)\n",
    "                        )\n",
    "\n",
    "\n",
    "    class TimeSeriesSplitImproved(TimeSeriesSplit):\n",
    "        \"\"\"Time Series cross-validator\n",
    "        Provides train/test indices to split time series data samples\n",
    "        that are observed at fixed time intervals, in train/test sets.\n",
    "        In each split, test indices must be higher than before, and thus shuffling\n",
    "        in cross validator is inappropriate.\n",
    "        This cross-validation object is a variation of :class:`KFold`.\n",
    "        In the kth split, it returns first k folds as train set and the\n",
    "        (k+1)th fold as test set.\n",
    "        Note that unlike standard cross-validation methods, successive\n",
    "        training sets are supersets of those that come before them.\n",
    "        Read more in the :ref:`User Guide `.\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_splits : int, default=3\n",
    "            Number of splits. Must be at least 1.\n",
    "        Examples\n",
    "        --------\n",
    "        >>> from sklearn.model_selection import TimeSeriesSplit\n",
    "        >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "        >>> y = np.array([1, 2, 3, 4])\n",
    "        >>> tscv = TimeSeriesSplit(n_splits=3)\n",
    "        >>> print(tscv)  # doctest: +NORMALIZE_WHITESPACE\n",
    "        TimeSeriesSplit(n_splits=3)\n",
    "        >>> for train_index, test_index in tscv.split(X):\n",
    "        ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        ...    X_train, X_test = X[train_index], X[test_index]\n",
    "        ...    y_train, y_test = y[train_index], y[test_index]\n",
    "        TRAIN: [0] TEST: [1]\n",
    "        TRAIN: [0 1] TEST: [2]\n",
    "        TRAIN: [0 1 2] TEST: [3]\n",
    "        >>> for train_index, test_index in tscv.split(X, fixed_length=True):\n",
    "        ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        ...     X_train, X_test = X[train_index], X[test_index]\n",
    "        ...     y_train, y_test = y[train_index], y[test_index]\n",
    "        TRAIN: [0] TEST: [1]\n",
    "        TRAIN: [1] TEST: [2]\n",
    "        TRAIN: [2] TEST: [3]\n",
    "        >>> for train_index, test_index in tscv.split(X, fixed_length=True,\n",
    "        ...     train_splits=2):\n",
    "        ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        ...     X_train, X_test = X[train_index], X[test_index]\n",
    "        ...     y_train, y_test = y[train_index], y[test_index]\n",
    "        TRAIN: [0 1] TEST: [2]\n",
    "        TRAIN: [1 2] TEST: [3]\n",
    "        Notes\n",
    "        -----\n",
    "        When ``fixed_length`` is ``False``, the training set has size\n",
    "        ``i * train_splits * n_samples // (n_splits + 1) + n_samples %\n",
    "        (n_splits + 1)`` in the ``i``th split, with a test set of size\n",
    "        ``n_samples//(n_splits + 1) * test_splits``, where ``n_samples``\n",
    "        is the number of samples. If fixed_length is True, replace ``i``\n",
    "        in the above formulation with 1, and ignore ``n_samples %\n",
    "        (n_splits + 1)`` except for the first training set. The number\n",
    "        of test sets is ``n_splits + 2 - train_splits - test_splits``.\n",
    "        \"\"\"\n",
    "\n",
    "        def split(self, X, y=None, groups=None, fixed_length=False,\n",
    "                  train_splits=1, test_splits=1):\n",
    "            \"\"\"Generate indices to split data into training and test set.\n",
    "            Parameters\n",
    "            ----------\n",
    "            X : array-like, shape (n_samples, n_features)\n",
    "                Training data, where n_samples is the number of samples\n",
    "                and n_features is the number of features.\n",
    "            y : array-like, shape (n_samples,)\n",
    "                Always ignored, exists for compatibility.\n",
    "            groups : array-like, with shape (n_samples,), optional\n",
    "                Always ignored, exists for compatibility.\n",
    "            fixed_length : bool, hether training sets should always have\n",
    "                common length\n",
    "            train_splits : positive int, for the minimum number of\n",
    "                splits to include in training sets\n",
    "            test_splits : positive int, for the number of splits to\n",
    "                include in the test set\n",
    "            Returns\n",
    "            -------\n",
    "            train : ndarray\n",
    "                The training set indices for that split.\n",
    "            test : ndarray\n",
    "                The testing set indices for that split.\n",
    "            \"\"\"\n",
    "            X, y, groups = indexable(X, y, groups)\n",
    "            n_samples = _num_samples(X)\n",
    "            n_splits = self.n_splits\n",
    "            n_folds = n_splits + 1\n",
    "            train_splits, test_splits = int(train_splits), int(test_splits)\n",
    "            if n_folds > n_samples:\n",
    "                raise ValueError(\n",
    "                    (\"Cannot have number of folds ={0} greater\"\n",
    "                     \" than the number of samples: {1}.\").format(n_folds,\n",
    "                                                                 n_samples))\n",
    "            if ((n_folds - train_splits - test_splits) == 0 and test_splits > 0):\n",
    "                raise ValueError(\n",
    "                    (\"Both train_splits and test_splits must be positive\"\n",
    "                     \" integers.\"))\n",
    "            indices = np.arange(n_samples)\n",
    "            split_size = (n_samples // n_folds)\n",
    "            test_size = split_size * test_splits\n",
    "            train_size = split_size * train_splits\n",
    "            test_starts = range(train_size + n_samples % n_folds,\n",
    "                                n_samples - (test_size - split_size),\n",
    "                                split_size)\n",
    "\n",
    "            if fixed_length:\n",
    "                for i, test_start in zip(range(len(test_starts)),\n",
    "                                         test_starts):\n",
    "                    rem = 0\n",
    "                    if i == 0:\n",
    "                        rem = n_samples % n_folds\n",
    "                    yield (indices[(test_start - train_size - rem):test_start],\n",
    "                           indices[test_start:test_start + test_size])\n",
    "            else:\n",
    "                for test_start in test_starts:\n",
    "                    yield (indices[:test_start],\n",
    "                           indices[test_start:test_start + test_size])\n",
    "\n",
    "    class AcctStats(bt.Analyzer):\n",
    "        \"\"\"A simple analyzer that gets the gain in the value of the account; should be self-explanatory\"\"\"\n",
    "\n",
    "        def __init__(self):\n",
    "            self.start_val = self.strategy.broker.get_value()\n",
    "            self.end_val = None\n",
    "\n",
    "        def stop(self):\n",
    "            self.end_val = self.strategy.broker.get_value()\n",
    "\n",
    "        def get_analysis(self):\n",
    "            return {\"start\": self.start_val, \"end\": self.end_val,\n",
    "                    \"growth\": self.end_val - self.start_val, \"return\": self.end_val / self.start_val}\n",
    "\n",
    "    for df in datafeeds.values():\n",
    "        df[\"OpenInterest\"] = 0  # PandasData reader expects an OpenInterest column;\n",
    "\n",
    "    tscv = TimeSeriesSplitImproved(globalparameters['n_splits'])\n",
    "    split = tscv.split(datafeeds[list(datafeeds.keys())[2]], fixed_length=globalparameters['fixed_length'], train_splits=globalparameters['train_splits'], test_splits=globalparameters['test_splits'])\n",
    "    walk_forward_results = list()\n",
    "    \n",
    "    heatmap_data = []\n",
    "    # Be prepared: this will take a while\n",
    "    i = 0\n",
    "    for train, test in split:\n",
    "        i += 1\n",
    "        # TRAINING\n",
    "        # Optimize with optunity\n",
    "        def runstrat(var1, var2):\n",
    "            cerebro = bt.Cerebro(stdstats=False, maxcpus=None)\n",
    "            cerebro.addstrategy(eval(globalparameters['strategy']), mperiod=int(var1), vperiod=int(var2), printlog=False, WFA=False)  # toDO make the float int choice switchable\n",
    "            cerebro.broker.setcash(globalparameters['cash'])\n",
    "            cerebro.broker.setcommission(globalparameters['commission'])\n",
    "            for s, df in datafeeds.items():\n",
    "                data = bt.feeds.PandasData(dataname=df.iloc[train], name=s)  # Add a subset of data\n",
    "                cerebro.adddata(data)\n",
    "            cerebro.broker.set_coc(globalparameters['coc'])\n",
    "            cerebro.run()\n",
    "            \n",
    "            if globalparams[\"heatmap\"]:\n",
    "                heatmap_data.append([int(var1), i, 0,(cerebro.broker.getvalue()-globalparams[\"cash\"])/globalparams[\"cash\"]])\n",
    "                \n",
    "            return cerebro.broker.getvalue()  # ToDo make the variable that should be optimized flexible\n",
    "        \n",
    "        # Optunity if needed\n",
    "        #opt = optunity.maximize(runstrat, num_evals=globalparameters['num_evals'], var1=globalparameters['var1range'], var2=globalparameters['var2range'])\n",
    "        \n",
    "        if globalparams[\"heatmap\"]:\n",
    "            results_list = []\n",
    "            for j in np.arange(30, 210, 10):\n",
    "                    runstrat(var1=j, var2=2)\n",
    "        \n",
    "        # Optunity results\n",
    "        '''\n",
    "        optimal_pars, details, _ = opt\n",
    "        optimal_pars['var1'] = int(optimal_pars['var1'])\n",
    "        optimal_pars['var2'] = int(optimal_pars['var2'])\n",
    "        '''\n",
    "        \n",
    "        optimal_pars = {}\n",
    "        #best return from the heatmap loop\n",
    "        #print(max(heatmap_data, key=lambda x: x[3] if (x[1] == i) else 0), max(heatmap_data, key=lambda x: x[3] if (x[1] == i) else 0)[0], datafeeds[list(datafeeds.keys())[2]].iloc[test[0]].name)\n",
    "        optimal_pars['var1'] = max(heatmap_data, key=lambda x: x[3] if (x[1] == i) else 0)[0]\n",
    "        optimal_pars['var2'] = 2\n",
    "        \n",
    "        # TESTING\n",
    "        tester = bt.Cerebro(stdstats=False, maxcpus=None)\n",
    "        tester.broker.set_cash(globalparameters['cash'])\n",
    "        tester.broker.set_coc(globalparameters['coc'])\n",
    "        tester.broker.setcommission(globalparameters['commission'])\n",
    "        tester.addanalyzer(AcctStats)\n",
    "        tester.addanalyzer(bt.analyzers.SharpeRatio, riskfreerate=0.0)\n",
    "\n",
    "        tester.addstrategy(eval(globalparameters['strategy']), mperiod=optimal_pars['var1'],\n",
    "                           vperiod=optimal_pars['var2'], WFA=False, printlog=False)  # Test with optimal combination toDO like above int vs float\n",
    "        for s, df in datafeeds.items():\n",
    "            data = bt.feeds.PandasData(dataname=df.iloc[test], name=s)  # Add a subset of data\n",
    "            tester.adddata(data)\n",
    "\n",
    "        res = tester.run()\n",
    "        res_dict = res[0].analyzers.acctstats.get_analysis()\n",
    "        res_dict[\"var1\"] = optimal_pars['var1']\n",
    "        res_dict[\"var2\"] = optimal_pars['var2']\n",
    "        res_dict[\"sharpe\"] = res[0].analyzers.sharperatio.get_analysis()['sharperatio']\n",
    "        res_dict[\"start_date\"] = datafeeds[list(datafeeds.keys())[2]].iloc[test[0]].name\n",
    "        res_dict[\"end_date\"] = datafeeds[list(datafeeds.keys())[2]].iloc[test[-1]].name\n",
    "        walk_forward_results.append(res_dict)\n",
    "    \n",
    "    if globalparams[\"heatmap\"]:\n",
    "        my_heatmap(heatmap_data)\n",
    "        #my_scatter_plot(heatmap_data)\n",
    "    \n",
    "    wfdf = DataFrame(walk_forward_results)\n",
    "    print(wfdf.loc[:, wfdf.columns != 'start'])\n",
    "\n",
    "    cerebro_wf = bt.Cerebro(stdstats=False, maxcpus=None)\n",
    "\n",
    "    for s, df in datafeeds.items():\n",
    "        data = bt.feeds.PandasData(dataname=df, name=s, fromdate=wfdf.iloc[0, wfdf.columns.get_loc('start_date')], todate=wfdf.iloc[-1, wfdf.columns.get_loc('end_date')])\n",
    "        \n",
    "        cerebro_wf.adddata(data)  # Give the data to cerebro\n",
    "\n",
    "    cerebro_wf.broker.setcash(globalparameters['cash'])\n",
    "    cerebro_wf.broker.setcommission(globalparameters['commission'])\n",
    "    cerebro_wf.broker.set_coc(globalparameters['coc'])\n",
    "\n",
    "    cerebro_wf.addstrategy(eval(globalparams['strategy']),\n",
    "                           # Give the results of the above optimization to SMACWalkForward (NOT OPTIONAL)\n",
    "                           mperiod=[f for f in wfdf.var1],\n",
    "                           vperiod=[s for s in wfdf.var2],\n",
    "                           start_dates=[sd.date() for sd in wfdf.start_date],\n",
    "                           end_dates=[ed.date() for ed in wfdf.end_date],\n",
    "                           WFA=True,\n",
    "                           )\n",
    "\n",
    "    cerebro_wf.addobservermulti(bt.observers.BuySell)  # Plots up/down arrows\n",
    "    cerebro_wf.addanalyzer(bt.analyzers.SharpeRatio, riskfreerate=0.0)\n",
    "    cerebro_wf.addanalyzer(btanal.PyFolio)\n",
    "\n",
    "    results = cerebro_wf.run()\n",
    "    print(f\"Sharpe: {results[0].analyzers.sharperatio.get_analysis()['sharperatio']:.3f}\")\n",
    "    \n",
    "    # Quantstats thanks to https://algotrading101.com/learn/backtrader-for-backtesting/\n",
    "    returns, positions, transactions, gross_lev = results[0].analyzers.pyfolio.get_pf_items()\n",
    "    returns.index = returns.index.tz_convert(None)\n",
    "    qs.reports.html(returns, output='stats.html', title='Walkforward '+ globalparams[\"strategy\"] + \" \" + str(int(globalparams[\"selcperc\"] * 100)) + \"% stocks picked\")\n",
    "    webbrowser.open('stats.html')\n",
    "        \n",
    "    #cerebro_wf.plot(iplot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exection section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20.         30.         20.          0.55890997]\n",
      " [20.         40.         20.          5.28686283]\n",
      " [30.         30.         30.          0.74885664]\n",
      " [30.         40.         30.         12.79986691]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x936 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run(args=None):\n",
    "    #optreturn=False otherwise the heatmap doesn't work\n",
    "    cerebro = bt.Cerebro(maxcpus=1,\n",
    "                         preload=False,\n",
    "\t\t                 optdatas=False,\n",
    "\t\t                 optreturn=False,\n",
    "\t\t                 stdstats=True) \n",
    "\n",
    "    \n",
    "# <<<Data loading section>>>\n",
    "    \n",
    "    # Parse from/to-date\n",
    "    fromdate = globalparams[\"fromdate\"]\n",
    "    todate = globalparams[\"todate\"]\n",
    "    \n",
    "    datafeeds = {}\n",
    "    \n",
    "    # Add SPY/QQQ as \"Benchmark\"\n",
    "    df0 = pd.read_csv(r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\QQQ.csv', index_col=0, parse_dates=True)\n",
    "    benchdata = bt.feeds.PandasData(dataname=df0,name=\"QQQ\",fromdate=fromdate, todate=todate,  plot=False)\n",
    "    cerebro.adddata(benchdata)\n",
    "    datafeeds.update({\"QQQ\": df0})\n",
    "    \n",
    "    # Add TMF as \"Bond\"\n",
    "    df1 = pd.read_csv(r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\TLT.csv', index_col=0, parse_dates=True)\n",
    "    bonddata = bt.feeds.PandasData(dataname=df1,name=\"Bond\",fromdate=fromdate, todate=todate, plot=False)\n",
    "    cerebro.adddata(bonddata)\n",
    "    datafeeds.update({\"Bond\": df1})\n",
    "    \n",
    "    \n",
    "    # add all the data files available in the directory datadir\n",
    "    for fname in glob.glob(os.path.join(globalparams[\"path\"], '*')):\n",
    "        df = pd.read_csv(fname, index_col=0, parse_dates=True)\n",
    "        # Add dataframes to a dictionary for walkforward analysis\n",
    "        datafeeds.update({os.path.basename(fname).replace(\".csv\", \"\"): df})\n",
    "        if len(df)>200:\n",
    "            cerebro.adddata(bt.feeds.PandasData(dataname=df,name=os.path.basename(fname).replace(\".csv\", \"\"),fromdate=fromdate, todate=todate, plot=False))\n",
    "            #print(os.path.basename(fname).replace(\".csv\", \"\")) #prints the name of the added csv file\n",
    "            \n",
    "       \n",
    "    # <<<Cerebro loading section>>>\n",
    "    if globalparams[\"walk\"]:\n",
    "        walk_forward_analysis(datafeeds)\n",
    "    else:\n",
    "        # Optimization by Optunity (usually partical swarm if i remember correctly)\n",
    "        def runstrat(p1, p2):\n",
    "            cerebro = bt.Cerebro(maxcpus=0,stdstats=True)\n",
    "            cerebro.addstrategy(St, rocperiod=int(p1), mperiod=int(p2),printlog=False) #change the parameters that should be depicted in heatmap\n",
    "            cerebro.broker.setcash(globalparams[\"cash\"])\n",
    "            cerebro.broker.setcommission(commission=globalparams[\"commission\"])\n",
    "            cerebro.adddata(benchdata)\n",
    "            cerebro.adddata(bonddata)  \n",
    "            for fname in glob.glob(os.path.join(globalparams[\"path\"], '*')):\n",
    "                df = pd.read_csv(fname, index_col=0, parse_dates=True)\n",
    "                if len(df)>200:\n",
    "                    cerebro.adddata(bt.feeds.PandasData(dataname=df,name=os.path.basename(fname).replace(\".csv\", \"\"),fromdate=fromdate, todate=todate, plot=False))        \n",
    "\n",
    "            cerebro.broker.set_coc(True)\n",
    "            cerebro.run(maxcpus=0)\n",
    "            return cerebro.broker.getvalue() #can be switched to whatever should be maximized/minimized\n",
    "\n",
    "        #Either use Optunity for quick search of optimum\n",
    "        if globalparams[\"optunity\"]:\n",
    "            opt = optunity.maximize(runstrat, num_evals=200, p1 = [1, 300], p2=[2, 100])\n",
    "\n",
    "            optimal_pars, details, _ = opt\n",
    "            print('Optimal Parameters:')\n",
    "            print('maperiod1 = %.4f' % optimal_pars['p1'])\n",
    "            print('maperiod2 = %.4f' % optimal_pars['p2'])\n",
    "\n",
    "\n",
    "        # Heatmap showing how variables i = (y axis/ p1) and j = (x axis /p2) impact strategy outcome\n",
    "        if globalparams[\"heatmap\"]:\n",
    "            results_list = []\n",
    "            for i in np.arange(20, 40, 10):\n",
    "                for j in np.arange(30, 50, 10):\n",
    "                    PnL = runstrat(p1=i, p2=j)/globalparams[\"cash\"]\n",
    "                    results_list.append([i, j, i, PnL])\n",
    "            my_heatmap1(results_list)\n",
    "            return\n",
    "\n",
    "\n",
    "        # add strategy\n",
    "        if globalparams[\"optunity\"]:\n",
    "            cerebro.addstrategy(eval(globalparams[\"strategy\"]), mperiod=int(optimal_pars['p1']), vperiod=int(optimal_pars['p2']))\n",
    "        elif globalparams[\"strategy\"] == \"HSt\":\n",
    "            cerebro.addstrategy(HSt, buy_date=datetime.date(2005, 11, 31))\n",
    "        else:    \n",
    "            cerebro.addstrategy(eval(globalparams[\"strategy\"]))\n",
    "\n",
    "\n",
    "        # set the cash, cheat on close and commission\n",
    "        cerebro.broker.setcash(globalparams[\"cash\"])\n",
    "        cerebro.broker.set_coc(True)\n",
    "        cerebro.broker.setcommission(commission=globalparams[\"commission\"])\n",
    "\n",
    "        # Adding Analysers\n",
    "        #cerebro.addanalyzer(bt.analyzers.SharpeRatio, riskfreerate=0.0, _name='sharpe')\n",
    "        cerebro.addanalyzer(bt.analyzers.AnnualReturn, _name='annual_return')\n",
    "        cerebro.addanalyzer(btanal.PyFolio)                # Needed to use PyFolio & Quanstat\n",
    "        cerebro.addanalyzer(btanal.TradeAnalyzer)          # Analyzes individual trades\n",
    "\n",
    "        # If you want to have all data written into a log file\n",
    "        #cerebro.addwriter(bt.WriterFile, csv=True, out='log.csv')\n",
    "\n",
    "        cerebro.addobserver(bt.observers.Benchmark,\n",
    "                            data=benchdata,\n",
    "                            timeframe=bt.TimeFrame.NoTimeFrame)\n",
    "\n",
    "        results = cerebro.run(maxcpus=1)#maxcpu=1 otherwise pickling multiprocessing errors\n",
    "\n",
    "        # <<<Performance analysing section section>>>\n",
    "\n",
    "        cerebro.plot()\n",
    "\n",
    "        # Basic performance evaluation ... final value ... minus starting cash\n",
    "        pnl = cerebro.broker.get_value() - globalparams[\"cash\"]\n",
    "        print('Profit ... or Loss: {:.2f}'.format(pnl))\n",
    "\n",
    "        # Quantstats thanks to https://algotrading101.com/learn/backtrader-for-backtesting/\n",
    "        # Does not work with optstrategy\n",
    "        returns, positions, transactions, gross_lev = results[0].analyzers.pyfolio.get_pf_items()\n",
    "        returns.index = returns.index.tz_convert(None)\n",
    "        qs.reports.html(returns, output='stats.html', title='Momentum '+ globalparams[\"strategy\"] + \" \" + str(int(globalparams[\"selcperc\"] * 100)) + \"% stocks picked\")\n",
    "        webbrowser.open('stats.html')\n",
    "\n",
    "\n",
    "        # Pyfolio if needed\n",
    "        #returns, positions, transactions, gross_lev = results[0].analyzers.pyfolio.get_pf_items()\n",
    "        #benchmark_rets = pd.Series([0.00004] * len(returns.index), index=returns.index)     \n",
    "        #pf.create_full_tear_sheet(returns, positions, transactions, benchmark_rets=benchmark_rets)\n",
    "    \n",
    "# <<<Execute starting section>>>    \n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfdate = datetime.datetime(2015, 8, 31)\\ntdate = datetime.datetime(2020, 6, 18)\\nfor fname in glob.glob(os.path.join(r\\'C:\\\\Users\\\\MMD\\\\PycharmProjects\\\\Trading\\\\Data Mining\\\\Data\\\\DAX\\', \\'*\\')):\\n    df = pd.read_csv(fname, index_col=0, parse_dates=True)\\n    a = df.at[fdate,\"Close\"]\\n    b = df.at[tdate,\"Close\"]\\n    print(b/a-1)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how do the single stocks perform over the time frame\n",
    "r'''\n",
    "fdate = datetime.datetime(2015, 8, 31)\n",
    "tdate = datetime.datetime(2020, 6, 18)\n",
    "for fname in glob.glob(os.path.join(r'C:\\Users\\MMD\\PycharmProjects\\Trading\\Data Mining\\Data\\DAX', '*')):\n",
    "    df = pd.read_csv(fname, index_col=0, parse_dates=True)\n",
    "    a = df.at[fdate,\"Close\"]\n",
    "    b = df.at[tdate,\"Close\"]\n",
    "    print(b/a-1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
